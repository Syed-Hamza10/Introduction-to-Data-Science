{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab29875",
   "metadata": {},
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Tools and Techniques for Data Science</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Instructor: Muhammad Arif Butt, Ph.D.</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ffed4",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lecture 4.3 (Linear Algebra for Machine Learning)</h1><br>\n",
    "<a href=\"https://colab.research.google.com/github/arifpucit/data-science/blob/master/Section-3-Python-for-Data-Scientists/Lec-3.01(NumPy-01-ArrayCreation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fff9cb",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"350\" height=\"300\"  src=\"images/ds1.png\"  >\n",
    "<img align=\"center\" width=\"400\" height=\"250\"  src=\"images/mathsandstat.jpeg\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47900344",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"900\" height=\"250\"  src=\"images/mathimg1.png\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e996a5d6",
   "metadata": {},
   "source": [
    "## Learning agenda of this notebook\n",
    "\n",
    "**Section I: (Overview of Linear Alagebra: Vectors)**\n",
    "1. Overview of Vectors \n",
    "    - Scalars vs Vectors\n",
    "    - Mathematical and Graphical Representation of Vectors in $\\mathbb{R}^2$\n",
    "    - Mathematical and Graphical Representation of Vectors in $\\mathbb{R}^3$\n",
    "    - Hands on Implementation in Python    \n",
    "2. Magnitude of a Vector (Vector Norms)\n",
    "3. Direction of a Vector\n",
    "4. Components of a Vector\n",
    "    - Components of a Vector in $\\mathbb{R}^2$\n",
    "    - Components of a Vector in $\\mathbb{R}^3$\n",
    "5. Two Fundamental Vector Operations\n",
    "    - Vector Addition\n",
    "    - Multiplying a Vector with Scalar value\n",
    "6. Basis and Unit Vectors\n",
    "7. Linear combination and Span of Vectors\n",
    "8. Vector to Vector Multiplication\n",
    "    - Vector Dot Product\n",
    "    - Vector Cross Product\n",
    "\n",
    "**Section II: (Overview of Linear Alagebra: Matrices)**\n",
    "\n",
    "1. Matrices\n",
    "    - Overview of Matrices (Rank-2 Tensors)\n",
    "    - Types of Matrices\n",
    "        - Square Matrix\n",
    "        - Symmetric Matrix\n",
    "        - Triangular Matrix\n",
    "        - Diagonal Matrix\n",
    "        - Identity Matrix\n",
    "        - Orthogonal Matrrix\n",
    "        - Sparse Matrix\n",
    "        - Singular Matrix\n",
    "    - Matrices Operations\n",
    "        - Transposition\n",
    "        - Matrix Norms (L-1, L-inf, Frobenius) \n",
    "        - Arithmetic Operations\n",
    "        - Hamadard Product\n",
    "        - Reduction\n",
    "        - Matrix-by-Vector Multiplication\n",
    "        - Matrix-by-Matrix Multiplication\n",
    "        - Inverse\n",
    "        - Determinant\n",
    "    \n",
    "\n",
    "**Section 2: (Solving System of Linear Equations)**\n",
    "1. Overview of System of Linear Equations\n",
    "    - asf\n",
    "    - Types of Hypotheshis Tests.\n",
    "    - Reles\n",
    "\n",
    "\n",
    "2. Test vs Test\n",
    "\n",
    "\n",
    "3. Fitting a Line to given three points\n",
    "    - Using Pseudo inverse\n",
    "    - Using Least square\n",
    "        - Linear Least Square (with one feature)\n",
    "        - Ordinary Least Square (with multiple features)\n",
    "\n",
    "\n",
    "4. Regression Analysis\n",
    "\n",
    "\n",
    "\n",
    "**Section 3: (Decomposition)**\n",
    "1. Overview of Decomposition\n",
    "    - What is Decomposition?\n",
    "    - What it is used for?\n",
    "    - Types of Decomposition\n",
    "        - EigenValue Decomposition\n",
    "        - Singular Value Decomposition\n",
    "        - QR Decomposition\n",
    "\n",
    "\n",
    "2. Transformations via Matrix Applicstion\n",
    "    - 2-D Transformations (Translation, scaling, reflection, shear, rotation)\n",
    "    - 3-D Transformations (Translation, scaling, reflection, shear, rotation)\n",
    "    - Hierarchy of Transformations\n",
    "        - Class-I: Isometries\n",
    "        - Class-II: Similarity\n",
    "        - Class-III: Affine\n",
    "        - Class-IV: Projective\n",
    "3. Eigenvectors and Eigenvalues\n",
    "4. Matrix Determinants and Matrix Decomposition \n",
    "5.  Applications of Eigendecomposition\n",
    "\n",
    "**Section 4: (SVD and PCA)**\n",
    "* Singular Value Decomposition (SVD)\n",
    "* The Moore-Penrose Pseudoinverse\n",
    "* The Trace Operator\n",
    "* Principal Component Analysis (PCA): A Simple Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787763a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike the other modules, we have been working so far, you have to download and install...\n",
    "# To install this library in Jupyter notebook\n",
    "import sys\n",
    "!{sys.executable} -m pip install -q --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3587d30f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import math\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af6b34",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section 1: (Overview of Linear Alagebra: Vectors) </span>\n",
    "Some of the codes of this notebook are adapted from:\n",
    "- [Jon Krohn's](https://github.com/jonkrohn).\n",
    "- [Frank Cleary's](https://gist.github.com/frankcleary).\n",
    "- [Engineers Code](https://github.com/engineersCode/EngComp4_landlinear)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca56d7e",
   "metadata": {},
   "source": [
    "## 1. Overview of Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7deea4",
   "metadata": {},
   "source": [
    "### a. What is Linear Algebra\n",
    "    - History of Linear Algebra\n",
    "    - Applications of Linear Algebra\n",
    "\n",
    "- **Linear algebra is a branch of mathematics**, but the truth of it is that linear algebra is the **mathematics of data**. **Matrices** and **vectors** are the language of data. It is the domain of mathematics concerning linear equations and their representations in vector spaces and through matrices. \n",
    "\n",
    "<img align=\"center\" width=\"600\" height=\"600\"  src=\"images/la1.png\"  >\n",
    "\n",
    "\n",
    "- The application of linear algebra in computers is often called **Numerical linear algebra**. As linear algebra is the mathematics of data, the tools of linear algebra are used in many domains.\n",
    "    - Matrices in Engineering.\n",
    "    - Graphs and Networks, such as analyzing networks.\n",
    "    - Markov Matrices, Population, and Economics, such as population growth.\n",
    "    - Linear Programming, the simplex optimization method.\n",
    "    - Fourier Series: Linear Algebra for Functions, used widely in signal processing.\n",
    "    - Linear Algebra for Statistics and Probability, such as least squares for regression.\n",
    "    - Computer Graphics, such as the various translation, scaling and rotation of images.\n",
    "    - Modern statistics is described using the notation of linear algebra.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2874a4e8",
   "metadata": {},
   "source": [
    "### b. Linear Algebra for Machine Learning and Deep Learning\n",
    "1. Solving for unknowns in Machine Learning Algorithms (Regression) and Deep Learning Algorithms (...)\n",
    "2. Reducing Dimensionality (e.g., PCA to reduce a high dimensional space to a low dimensional space keepng the most important features.\n",
    "3. Ranking Results (e.g., Rank web pages using egienvecotr)\n",
    "4. Recommender Systems (e.g., Netflix movie recommender using SVD)\n",
    "5. Topic Modeling and Semantic Analysis in Natural Language Proessing (using SVD and MNAtrix factorization)\n",
    "\n",
    "\n",
    "- There is no doubt that linear algebra is important in **Machine learning** and **Deep Learning**. Computers are good at performing linear algebra calculations, and much of the dependence on Graphical Processing Units (GPUs) by modern machine learning methods such as deep learning is because of their ability to compute linear algebra operations fast.\n",
    "\n",
    "\n",
    "- Modern machine learning methods are described the same way, using the notations and tools drawn directly from linear algebra. Even some classical methods used in the field, such as **Linear regression** via linear least squares and **singular-value decomposition**, are linear algebra methods.\n",
    "\n",
    "\n",
    "- Linear algebra is a sub-field of mathematics concerned with vectors, matrices and linear transforms. It is a key foundation to the field of machine learning from notations used to describe the operation of algorithms, to the implementation of algorithms in code. Although linear algebra is integral to the field of machine learning, the tight relationship is often left unexplained or explained using abstract concepts such as vector spaces or specific matrix operations. \n",
    "\n",
    "\n",
    "- In machine learning, you fit a model on a dataset. This is the table like set of numbers where each row represents an observation and each column represents a feature of the observation. This data is in fact a `matrix`, a key data structure in linear algebra.\n",
    "\n",
    "\n",
    "- Further, when you split the data into inputs and outputs to fit a supervised machine learning model, such as the measurements and the flower species, you have a matrix (X) and a vector (y). The `vector` is another key data structure in linear algebra.\n",
    "\n",
    "\n",
    "- An image is yet another example of a matrix from linear algebra. Operations on the image, such as cropping, scaling, shearing and so on are all described using the notation and operations of linear algebra.\n",
    "\n",
    "\n",
    "- Artificial neural networks are nonlinear machine learning algorithms that are inspired by elements of the information processing in the brain and have proven effective at a range of problems not least predictive modeling. Deep learning is the recent resurged use of artificial neural networks with newer methods and faster hardware that allow for the development and training of larger and deeper (more layers) networks on very large datasets. Deep learning methods are routinely achieve state-of-the-art results on a range of challenging problems such as machine translation, photo captioning, speech recognition and much more.\n",
    "\n",
    "\n",
    "- At their core, the execution of neural networks involves linear algebra data structures multiplied and added together. Scaled up to multiple dimensions, deep learning methods work with vectors, matrices and even tensors of inputs and coefficients, where a tensor is a matrix with more than two dimensions. Linear algebra is central to the description of deep learning methods via matrix notation to the implementation of deep learning methods such as Google’s TensorFlow Python library that has the word \"tensor\" in its name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f6ff95",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"500\" height=\"400\"  src=\"images/LA/vectorin3d.png\"  >\n",
    "\n",
    "<img align=\"left\" width=\"450\" height=\"400\"  src=\"images/LA/vectorin2d.png\"  >\n",
    "\n",
    "Cartesian coordinates\n",
    " \n",
    "Cartesian coordinates allow one to specify the location of a point in the plane, or in three-dimensional space. The Cartesian coordinates (also called rectangular coordinates) of a point are a pair of numbers (in two-dimensions) or a triplet of numbers (in three-dimensions) that specified signed distances from the coordinate axis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82564da3",
   "metadata": {},
   "source": [
    "### c. Overview of Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed00afc5",
   "metadata": {},
   "source": [
    "- Most important data structure of Linear Algebra in relation to Machine Learning and Deep Learning are **Tensors**.\n",
    "- Python's Pytorch and Tensorflow libraries allows these tensors to flow through various mathematical operations.\n",
    "- Tensors are Machine Learning generalization of vectors and matrices to any number of dimensions.\n",
    "- In simple words, TensorFlow's Tensor objects are like NumPy's ndArray object\n",
    "    - Scalar Tensor is 0-Dimensional and has magnitude only\n",
    "    - Vector Tensor is 1-Dimensional and can be of R2, R3, R4, ....\n",
    "    - Matrix Tensor is 2-Dimensional and can be visualized as a flat table\n",
    "    - 3-Tensor is 3-Dimensional and can be visualized as a cube\n",
    "    - n-Tensor is difficult to visualize :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c198ff2e",
   "metadata": {},
   "source": [
    "Scalars, Vectors and Matrices\n",
    "Before we can move on to tensors, we must first be familiar with scalars, vectors and matrices. If you are comfortable with these concepts, you can move on to the next page.\n",
    "\n",
    "Scalars\n",
    "These are direction independent quantities that can be fully described by a single number, and are unaffected by rotations or changes in co-ordinate system. Examples of physical properties that are scalars: Energy, Temperature, Mass.\n",
    "For this TLP scalars will be written in italics.\n",
    "\n",
    "Vectors\n",
    "These are objects that possess a magnitude and a direction, and are referenced to a particular set of axes known as a basis. A basis is a set of unit vectors (vectors with a magnitude of 1) from which any other vector can be constructed by multiplication and addition.\n",
    "The vector is referenced to the basis by its components. If possible, the maths is simplified by using an orthonormal base with orthogonal (mutually perpendicular) unit vectors. Examples of physical properties that are described by vectors: Mechanical force, Heat flow, Electric field.\n",
    "Vectors will be written in bold and components of a vector, say x, will be written as xi\n",
    "image of matrix\n",
    "\n",
    "Matrices\n",
    "A matrix is a mathematical object that contains a rectangular array of numbers that can be added and multiplied (according to matrix multiplication rules). They are very useful in many applications, for example in reducing a set of linear equations into a single equation, storing the coefficients of linear transformations (e.g. rotations), and as we shall see, in describing tensors.\n",
    "The components of matrix A are written aij where i refers to the row element and j refers to the column element."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1feba2dc",
   "metadata": {},
   "source": [
    "## 1. Overview of Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a72e17",
   "metadata": {},
   "source": [
    "### a. Scalar vs Vectors\n",
    "\n",
    "- A quantity that has magnitude but no particular direction is called scalar. For example, length, speed, mass, density, pressure, work, power, temperature, area, volume.\n",
    "- A quantity that has magnitude as well as direction is called vector. For example, displacement, velocity, weight, force.\n",
    "- For example, to describe a body’s velocity completely, we will have to mention its magnitude and direction. This means that we will have to mention how fast it is going in terms of distance covered per unit time and describe what direction it is headed. So, if we say a car is moving at 40 km/hr. This statement only describes the speed of the body. If someone says a car is moving at 40 km/hr and is headed North. This statement is describing the velocity of the car. It tells us the magnitude by which the car is moving and the direction in which it is headed.\n",
    "\n",
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/LA/whatsavector.png\"  >\n",
    "\n",
    "- We come accross the concept of vectors in the domains of physics, engineering, mathematics, computer science and more. Each field's interpretation of what a vector is a bit different:\n",
    "     - In **physics**, we represent a vector as an arrow of specific length, representing its magnitude; and drawn at a specific angle, representing its direction. It can represent directional quantities like velocity, force, acceleration.\n",
    "     - In **computer science**, a vector is an ordered list of numbers, stored in order. For example the price, area and number of bedrooms in a house. Or may be the age, weight and blood pressure of a person.\n",
    "     - In **mathematics**, vectors are generic objects that behave in a certain way, when they are added or scaled:  $\\mathbf{u}+\\mathbf{v}$, $\\alpha\\mathbf{v}$.\n",
    "\n",
    "- Vectors can be 2-dimensional, 3-dimensional and so on to N-dimensional. The two and three dimensional vecgtors are pretty easy to visualize. If we are able to understand and visualize the vector operations in 2-dimensions, we can map the concepts to larger dimensions as well. For example, to model the age, weight, daily hours of sleep, weekly hours of exercise, and blood pressure of an individual, we need a five dimensional vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c5502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29bf5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae5c7095",
   "metadata": {},
   "source": [
    "### b. Mathematical and Graphical Representation of Vectors in $\\mathbb{R}^2$\n",
    "#### Algebraically\n",
    "- Algebraically, vectors are often represented using a lowercase character, having comma separated list of numbers written horizontally or may be numbers written from top to bottom. \n",
    "- The **length** of the vector is the number of scalar values in the vector, and is also called the `order/rank/degree/dimension of the vector`. \n",
    "- For example, in $\\mathbb{R}2$ space, algebraically a vector $\\overrightarrow{\\rm v}$ can be written as:<br>\n",
    "\n",
    "$\\hspace{2 cm}\\overrightarrow{\\rm v} = (a, b) = \\begin{bmatrix} a \\\\ b \\end{bmatrix} \\hspace{2 cm}\\overrightarrow{\\rm v} = (2, 5) = \\begin{bmatrix} 2 \\\\ 5 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm}\\overrightarrow{\\rm v} = a\\hat{i} +  b\\hat{j} \\hspace{3 cm} \\overrightarrow{\\rm v} = 2\\hat{i} +  5\\hat{j}$\n",
    "\n",
    "$\\hspace{2 cm}\\overrightarrow{\\rm v} = a\\begin{bmatrix} 1 \\\\ 0  \\end{bmatrix} +  b\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\hspace{1.5 cm} \\overrightarrow{\\rm v} = 2\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} +  5\\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} $\n",
    "\n",
    "\n",
    "\n",
    "#### Graphically/Geometrically\n",
    "- One can think of a vector as a point in space. Graphically/Geometrically, vectors can be represented by a directed line segment in cartesian coordniate system, whose length is the magnitude of the vector and the angle represents its direction.\n",
    "\n",
    "<img align=\"left\" width=\"300\" height=\"300\"  src=\"images/LA/2DCoordinates.png\"  >\n",
    "\n",
    "<img align=\"right\" width=\"500\" height=\"500\"  src=\"images/LA/translate.png\"  >\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dbbc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64aded7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d31de3ff",
   "metadata": {},
   "source": [
    "### c. Mathematical and Graphical Representation of Vectors in $\\mathbb{R}^3$\n",
    "\n",
    "#### Algebraically\n",
    "\n",
    "- Algebraically, vectors of rank 3 consists of three scalar values written as comma separated list of numbers horizontally or may be from top to bottom. \n",
    "- The **length** of the vector is the number of scalar values in the vector, and is also called the `order/rank/degree/dimension of the vector`, in this case it is three. \n",
    "\n",
    "- Algebraically, in $\\mathbb{R}3$ space, a vector $\\overrightarrow{\\rm v}$ can be written as:<br>\n",
    "\n",
    "$\\hspace{2 cm}\\overrightarrow{\\rm v} = (a, b, c) = \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} \\hspace{5 cm}\\overrightarrow{\\rm v} = (2, 5, 3) = \\begin{bmatrix} 2 \\\\ 5 \\\\ 3 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm}\\overrightarrow{\\rm v} = a\\hat{i} +  b\\hat{j} +  c\\hat{k} \\hspace{5 cm} \\overrightarrow{\\rm v} = 2\\hat{i} +  5\\hat{j} +  3\\hat{k}$\n",
    "\n",
    "$\\hspace{2 cm}\\overrightarrow{\\rm v} = a\\begin{bmatrix} 1 \\\\ 0 \\\\0 \\end{bmatrix} +  b\\begin{bmatrix} 0 \\\\ 1 \\\\0 \\end{bmatrix} +  c\\begin{bmatrix} 0 \\\\ 0 \\\\1 \\end{bmatrix} \\hspace{3 cm} \\overrightarrow{\\rm v} = 2\\begin{bmatrix} 1 \\\\ 0 \\\\0 \\end{bmatrix} +  5\\begin{bmatrix} 0 \\\\ 1 \\\\0 \\end{bmatrix} +  3\\begin{bmatrix} 0 \\\\ 0 \\\\1 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "<img align=\"right\" width=\"300\" height=\"300\"  src=\"images/LA/vectorin3d.png\"  >\n",
    "\n",
    "#### Graphically/Geometrically\n",
    "- A 3-D coordinate system has 3 dimensions or can be regarded as having 3 perpendicular axes: x, y, and z-axes. Such a system is called a 3-dimensional rectangular coordinate system.\n",
    "- Note, the third axis is the Z-axis, and all the three axis are perpedicular to each other.\n",
    "- The vector $\\overrightarrow{\\rm v}$ is shown in bold red having its three components a, b and c along the x, y and z axis respectively.\n",
    "- We can visualize vectors upto three dimensions, however, beyond three dimensions, we normally use algebraic notations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5e3581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07fe69d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5c1609d",
   "metadata": {},
   "source": [
    "### d. Hands on Implementation in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bbd2fb",
   "metadata": {},
   "source": [
    "**Example 1:** Creating Vector $[3,2]$ having tail at origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e03dde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To better visualize and plot, you need to import following module/script having three helper functions\n",
    "# plot_vector(), plot_linear_transformation, plot_linear_transformations\n",
    "from plot_helper import *\n",
    "v = [(3,2)]        # A list having a single tuple of two elements representing x and y component of vector\n",
    "plot_vector(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d7f2c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6d23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0bf4944",
   "metadata": {},
   "source": [
    "**Example 2:** Creating four vectors, one in each quadrant having their tails at origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0803a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [(3, 3), (-3, 1), (-3,-2),(3,-2)]  # A list having four tuples of two elements each\n",
    "plot_vector(v)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6416bda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b04b345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca3177e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40487e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b086a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013ac5c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930cb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214668e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a25e6cd6",
   "metadata": {},
   "source": [
    "**Example 3:** Creating a vector $[4,3]$ having its tail at $[2,2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b380e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [(4,3)]     # A list having a single tuple of two elements representing x and y component of vector\n",
    "tail = [(2,2)]   # A list having a single tuple of two elements representing tail of vector\n",
    "plot_vector(v, tail) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad3084f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a546bca2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f370fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ca7f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4bfb15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa759796",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f752bf36",
   "metadata": {},
   "source": [
    "**Example 4:** Three vectors with their tails at $[2,2]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed46f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [(1, 3), (3, 3), (4, 6)]   # A list having three tuples of two elements each\n",
    "tail = [(2, 2)]                # A list having a single tuple of two elements\n",
    "plot_vector(v, tail) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4f1f8",
   "metadata": {},
   "source": [
    "**Example 5:** Three vectors with different tails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651555b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [(1, 3), (4, 4), (4, 6)]\n",
    "tails = [(3, 2), (-6, -6), (-1, 2)]\n",
    "plot_vector(v, tails)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b365aa",
   "metadata": {},
   "source": [
    "**Example 6:** Translate above three vectors to origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b8fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = [(1, 3), (4, 4), (4, 6)]\n",
    "tails = [(0, 0), (0, 0), (0, 0)]\n",
    "plot_vector(v, tails)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fad88f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc71cee",
   "metadata": {},
   "source": [
    "## 2. Magnitude of a Vector (Vector Norms)\n",
    "- The length of a vector is a `non-negative` number that describes the extent of the vector in space, and is sometimes referred to as the vector’s magnitude or the norm.\n",
    "- We can compute the magnitude of a 2-dimensional, 3-dimensional and so on to a n-dimensional vector using two ways:\n",
    "    - By graphically drawing the vector in a coordinate system\n",
    "    - By using different Vector Norms.\n",
    "\n",
    "\n",
    "\n",
    "####  L<sup>2</sup> Norm\n",
    "- The most commonly used Norm that is used to calculate the magnitude of a vector is L<sup>2</sup> Norm.\n",
    "- The L<sup>2</sup> norm calculates the distance of the vector coordinate from the origin of the vector space. As such, it is also known as the `Euclidean norm` as it is calculated as the `Euclidean distance from the origin`. The result is a `positive` distance value. \n",
    "- The L<sup>2</sup> norm is calculated as the `square root` of the sum of the squared vector values.\n",
    "\n",
    "<h3 align=\"center\">      $\\left\\lVert  x \\right\\rVert_2$   $=$   $\\sqrt{\\sum_{i=1}^n x_i^2}$        </h3>\n",
    "\n",
    "\n",
    "#### Squared L<sup>2</sup> Norm\n",
    "- The squared L<sup>2</sup> Norm is computationally cheaper to use as compared to L<sup>2</sup> Norm.\n",
    "- The squared L<sup>2</sup> Norm equals to the dot product of a vector with its transpose.\n",
    "- The squared L<sup>2</sup> norm is calculated as the sum of the squared vector values.\n",
    "\n",
    "<h3 align=\"center\">      $\\left\\lVert  x \\right\\rVert_2$   $=$   $\\sum_{i=1}^n x_i^2$        </h3>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####  L<sup>1</sup> Norm\n",
    "- Another way to calculate the magnitude of a vector is using the L<sup>1</sup> Norm. \n",
    "- The L<sup>1</sup> norm is calculated as the sum of the absolute vector values. The L<sup>1</sup> norm  is also known as `taxicab norm` or the `Manhattan norm`.\n",
    "- In several machine learning applications, it is important to discriminate between elements that are exactly zero and elements that are small but nonzero. In such cases, we use the L<sup>1</sup> norm.\n",
    "\n",
    "<h3 align=\"center\">      $\\left\\lVert  x \\right\\rVert_1$   $=$   $\\sum_{i=1}^n |x_i|$        </h3>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####   Max Norm (L<sup>∞</sup>)\n",
    "- The length of a vector can be calculated using the maximum norm, also called max norm (L<sup>∞</sup>). Max norm of a vector is referred to as (L<sup>∞</sup>)\n",
    "- The max norm is calculated as returning the `maximum value` of the vector, hence the name.\n",
    "\n",
    "<h3 align=\"center\">      $\\left\\lVert  x \\right\\rVert_∞$   $=$   $\\max_{i=1}^n$ $|x_i|$        </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6720f730",
   "metadata": {},
   "source": [
    "###  Check your Concepts\n",
    "Determine the magnitude of following vectors:<br>\n",
    "- X = 20m, North\n",
    "- A = (-1, -2/3)\n",
    "- F = (4, 10)\n",
    "- V = (2, 5, 3)\n",
    "- T = (0, 2, -1)\n",
    "- $\\overrightarrow{\\rm AB}$ whose starting point is at A = (-1,0, 3) and ending point is B = (5,2,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e801198b",
   "metadata": {},
   "source": [
    "###  Hands on Implementation in Python\n",
    "**Example:** Determine the magnitude of vector $\\overrightarrow{\\rm AB}$ whose starting point is at $A = (-2, 2)$ and ending point is $B = (2, 8)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc512cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating the vector to origin\n",
    "a = np.array([-2, 2])\n",
    "b = np.array([2, 8]) \n",
    "v = np.array([b[0]-a[0], b[1]-a[1]])   # v = (4,6)\n",
    "\n",
    "# Plotting both the vectors\n",
    "vectors = [v, v ]        # A list having two vectors\n",
    "tails = [[-2,2], [0,0]]\n",
    "plot_vector(vectors, tails)  \n",
    "\n",
    "print(\"v = \", v)\n",
    "# calculating L1 norm\n",
    "l1 = numpy.linalg.norm(v, ord=1)\n",
    "l1 = np.abs(v[0]) + np.abs(v[1])\n",
    "print(\"L1 Norm = \",l1)\n",
    "\n",
    "# calculating L2 norm\n",
    "l2 = numpy.linalg.norm(v, ord=2)\n",
    "l2 = (v[0]**2 + v[1]**2 )**(1/2)\n",
    "print(\"L2 Norm = \",l2)\n",
    "\n",
    "# calculating Squared L2 norm\n",
    "sq_l2 = (numpy.linalg.norm(v, ord=2))**2\n",
    "sq_l2 = (v[0]**2 + v[1]**2 )\n",
    "print(\"Squared L2 Norm = \",sq_l2)\n",
    "\n",
    "# calculating Max norm\n",
    "maxnorm = numpy.linalg.norm(v, ord=np.inf)\n",
    "maxnorm = np.max([np.abs(v[0]), np.abs(v[1])])\n",
    "print(\"L∞ = \", maxnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1377732",
   "metadata": {},
   "source": [
    "> A vector having its tail at origin is called position vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b041b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f93617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac3a48d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41685ca8",
   "metadata": {},
   "source": [
    "## 3. Direction of a Vector\n",
    "- The direction of the vector v is the measure of the angle that it makes with the horizontal in the plane.\n",
    "- There are two commonly used units of measurement for angles. \n",
    "    - **Degrees:** A circle is divided into 360 equal degrees, and a degree is further divided into 60 equal parts called minutes. So seven and a half degrees can be called 7 degrees and 30 minutes, written 7° 30'. Each minute is further divided into 60 equal parts called seconds, and, for instance, 2 degrees 5 minutes 30 seconds is written 2° 5' 30\". \n",
    "    - **Radians:** The other common measurement for angles is radians. One radian is the angle made at the center of a circle by an arc whose length is equal to the radius of the circle. The circumference of a circle is 2π, so it follows that 360° equals 2π radians. \n",
    "    \n",
    "<img align=\"center\" width=\"900\" height=\"500\"  src=\"images/LA/angles.png\"  >\n",
    "\n",
    "\n",
    "- **Geometrically Measuring the Direction of a Vector**:\n",
    "    - The most common way is to measure the angle by the counterclockwise movement with the positive x-axis. This way the angle is always positive. \n",
    "    - Another way is to measure the smallest angle that a vector form along the horizontal axis. If it is measured clockwise the angle is written with a negative sign.\n",
    "    \n",
    "- **Mathematically Measuring the Direction of a Vector**:\n",
    "    - By using Inverse Tangent Formula:\n",
    "<h3 align=\"center\">      $\\theta = tan^{-1} (y/x)$        </h3>\n",
    "\n",
    "- **Note:** \n",
    "    - The inverse Tangent formula returns the angle in radians, which you can convert to degrees by multiplying it by 180/pi\n",
    "    - The inverse Tangent formula gives the shortest angle from either the positive or negative x-axis in either clock-wise or counter-clockwise direction. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1154b829",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f481d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5e4b6e0",
   "metadata": {},
   "source": [
    "**Example 1:** Find the direction of a vector whose coordinates are $(4, 6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d5dfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([4, 6])\n",
    "print(\"v = \", v)\n",
    "theta_rad = math.atan(v[1]/v[0])     # acos, asin, and atan take a ratio as input and return an angle in radians. \n",
    "theta_deg = theta_rad*(180/math.pi)  # so we need to convert it into degrees\n",
    "print(\"Angle in radians: \", theta_rad)\n",
    "print(\"Shortest angle from x-axis: \", theta_deg)\n",
    "# Since, both the coordinates are positive, that means the angle exists in the first quadrant\n",
    "# So the angle is already computed from positive x-axis\n",
    "theta_deg = theta_deg + 0\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "plot_vector([v]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23555bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39972c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443dcb0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddf08ef8",
   "metadata": {},
   "source": [
    "**Example 2:** Find the direction of a vector whose coordinates are $(-4, 6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75e5352",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([-4, 6])\n",
    "print(\"v = \", v)\n",
    "theta_rad = math.atan(v[1]/v[0])    # acos, asin, and atan take a ratio as input and return an angle in radians. \n",
    "theta_deg = theta_rad*(180/math.pi) # so we need to convert it into degrees\n",
    "print(\"Angle in radians: \", theta_rad)\n",
    "print(\"Shortest angle from x-axis: \", theta_deg)\n",
    "# Since, x-coordinate is negative and y-coordinate is positive, that means, the angle exists in the second \n",
    "# quadrant. Since, the angle is negative, that means, it is measured from negative x-axis in clock-wise direction\n",
    "# So we have to add 180 degree to get the angle from positive x-axis in counter-clockwise direction\n",
    "theta_deg = theta_deg + 180\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "plot_vector([v]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b8c51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8f475e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac130c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa61e44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc563c3f",
   "metadata": {},
   "source": [
    "**Example 3:** Find the direction of a vector whose coordinates are $(-4, -6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b693a152",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([-4, -6])\n",
    "print(\"v = \", v)\n",
    "theta_rad = math.atan(v[1]/v[0])     # acos, asin, and atan take a ratio as input and return an angle in radians. \n",
    "theta_deg = theta_rad*(180/math.pi)  # so we need to convert it into degrees\n",
    "print(\"Angle in radians: \", theta_rad)\n",
    "print(\"Angle in degrees: \", theta_deg)\n",
    "# Since, both the coordinates are negative, that means, the angle exists in the third quadrant\n",
    "# Since, the angle is positive, that means, it is measured from negative x-axis in counter-clockwise direction\n",
    "# So we have to add 180 degree to get the angle from positive x-axis in counter-clockwise direction\n",
    "theta_deg = theta_deg + 180\n",
    "print(\"Angle in degrees from x-axis: \", theta_deg)\n",
    "plot_vector([v]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfa83de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93368058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e95f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec04c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddfcbad0",
   "metadata": {},
   "source": [
    "**Example 4:** Find the direction of a vector whose coordinates are $(4, -6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28161dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array([4, -6])\n",
    "print(\"v = \", v)\n",
    "theta_rad = math.atan(v[1]/v[0])     # acos, asin, and atan take a ratio as input and return an angle in radians. \n",
    "theta_deg = theta_rad*(180/math.pi)  # so we need to convert it into degrees\n",
    "print(\"Angle in radians: \", theta_rad)\n",
    "print(\"Shortest angle from x-axis: \", theta_deg)\n",
    "#Since, x-coordinate is positive and y-coordinate is negative, that means, the angle exists in the fourth quadrant\n",
    "#Since, the angle is negative, that means, it is measured from positive x-axis in clockwise direction\n",
    "#So we have to add 360 degree to get the angle from positive x-axis in counter-clockwise direction\n",
    "theta_deg = theta_deg + 360\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "plot_vector([v]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c46d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09384f37",
   "metadata": {},
   "source": [
    "## 4. Components of a Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d29cb26",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" height=\"300\"  src=\"images/LA/vector-components.jpg\"  >\n",
    "\n",
    "### a. Components of a Vector in $\\mathbb{R}^2$\n",
    "\n",
    "- Splitting of an angled vector into two vectors directed towards the coordinate axes in a two-dimensional coordinate system are defined as vector components.\n",
    "- The two components of any vector can be found through the method of vector resolution. \n",
    "- This vector say $F$ is making an angle of 30 degrees with the positive x-axis in counter clockwise direction. The head of this vector is 5 units towards East and 2 units towards North. These two lines are the vector components of the vector $F$. Moreover, these two components are supposed to form a right-angled triangle. \n",
    "- We can use these two components are then used to find the resultant vector’s magnitude and direction, which is AB.\n",
    "\n",
    " $ cosθ = \\frac{F_x}{F} \\implies F_x = F.cosθ $ <br>\n",
    " $ sinθ = \\frac{F_y}{F} \\implies F_y = F.sinθ $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde96b01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ab5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4c93b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec594f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ccf40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b75c015",
   "metadata": {},
   "source": [
    "**Example 1:** A force $\\overrightarrow{\\rm F}$ of 10 N is applied at an angle of 30º along the horizontal surface. Resolve the vector into its components. Verify your answer by calculating its magnitude and direction from its components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833921f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating x and y components of vector F\n",
    "fx = 10*math.cos(30 * math.pi/180)      # sin, cos and tan take input angle in radians and return a real value. \n",
    "fy = 10*math.sin(30 * math.pi/180)      # sin, cos and tan take input angle in radians and return a real value. \n",
    "print(\"Fx: %.2f\" %fx, \"N\")\n",
    "print(\"Fy: %.2f\" %fy, \"N\")\n",
    "\n",
    "# calculating magnitude for verification\n",
    "f = numpy.linalg.norm([fx, fy], ord=2)\n",
    "print(\"|F| = \",f)\n",
    "\n",
    "# calculating angle for verification\n",
    "theta_rad = math.atan(fy/fx)     # returned angle is in radians. \n",
    "theta_deg = theta_rad*(180/math.pi)  # convert it into degrees\n",
    "# Since, x and y-components are both positive, that means the vector is in first quadrant\n",
    "print(\"Angle: %.2f\" % theta_deg, \"degrees\")\n",
    "\n",
    "# Plot the vector\n",
    "plot_vector([(fx,fy)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac4f66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4cf8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de64e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94263fe3",
   "metadata": {},
   "source": [
    "**Example 2:** Given a vector $\\mathbf{v}$ having magnitude of 4 and direction of 45 degrees in  $\\mathbb{R}^2$. Find out its x and y-components.\n",
    "Verify your answer by calculating its magnitude and direction from its components.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ed29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating x and y components of vector F\n",
    "vx = 4*math.cos(45 * math.pi/180)  # sin, cos and tan take input angle in radians and return a real value. \n",
    "vy = 4*math.sin(45 * math.pi/180)  # sin, cos and tan take input angle in radians and return a real value. \n",
    "print(\"vx: %.2f\" %vx)\n",
    "print(\"vy: %.2f\" %vy)\n",
    "\n",
    "# calculating magnitude for verification\n",
    "mag = numpy.linalg.norm([vx, vy], ord=2)\n",
    "print(\"|v| = \", mag)\n",
    "\n",
    "# calculating angle for verification\n",
    "theta_rad = math.atan(vy/vx)     # returned angle is in radians. \n",
    "theta_deg = theta_rad*(180/math.pi)  # convert it into degrees\n",
    "# Since, x and y-components are both positive, that means the vector is in first quadrant\n",
    "print(\"Angle: %.2f\" % theta_deg, \"degrees\")\n",
    "\n",
    "# Plot the vector\n",
    "plot_vector([(vx,vy)]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b444bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fc2129",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0df294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf6585a",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" height=\"300\"  src=\"images/LA/3dvectorcomponents.png\"  >\n",
    "\n",
    "### b. Components of a Vector in $\\mathbb{R}^3$\n",
    "- In contrast to a vector in 2-D space having an x-component and a y-component with one angle in between, a vector in 3-D space will have an x-component, a y-component and a z-component with three angles in between.\n",
    "- Given the three angles and the magnitude of a vector, we can calculate its components using following formulae: \n",
    "    - $ F_x = F.cos\\theta_x $, where, $\\theta_x$ is the angle between the vector and x-axis\n",
    "    - $ F_y = F.cos\\theta_y $, where, $\\theta_y$ is the angle between the vector and y-axis\n",
    "    - $ F_z = F.cos\\theta_z $, where, $\\theta_z$ is the angle between the vector and z-axis\n",
    "\n",
    "- Consider a vector: $\\overrightarrow{\\rm v} = (4,6,4) = 4\\hat{i} + 6\\hat{j} + 4\\hat{k}$\n",
    "    - Where $\\hat{i}$, $\\hat{j}$, and $\\hat{k}$ are the unit vectors in the x, y and z directions, being multiplied by scalars 4, 6, and 4 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e0b91",
   "metadata": {},
   "source": [
    "**Example 1:** Given a vector having magnitude of 8.2463 making angles of 60.98, 43.3, and 60.98 with x,y, and z-axis respectively in  $\\mathbb{R}^3$. Find out its x, y and z-components. Verify your answer by calculating the vector's magnitude from components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc888359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating x and y components of vector F\n",
    "fx = 8.2463*math.cos(60.98 * math.pi/180)       \n",
    "fy = 8.2463*math.cos(43.3 * math.pi/180)        \n",
    "fz = 8.2463*math.cos(60.98 * math.pi/180)   \n",
    "print(\"fx: %.2f\" %fx)\n",
    "print(\"fy: %.2f\" %fy)\n",
    "print(\"fx: %.2f\" %fz)\n",
    "\n",
    "# calculating magnitude for verification\n",
    "mag = numpy.linalg.norm([fx, fy, fz], ord=2)\n",
    "print(\"|f| = %.3f\" %mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479e8057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1f81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1e3805",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff2c2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e92e75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c0420b5",
   "metadata": {},
   "source": [
    "## 5. Two Fundamental Vector Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db4d8a9",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"400\" height=\"400\"  src=\"images/LA/vector_2d_add.png\"  >\n",
    "\n",
    "### a. Vectors Addition\n",
    "- Two vectors of equal length can be added together to create a new third vector, and is written as:\n",
    "\n",
    "$ \\hspace{5.0cm} \\overrightarrow{\\rm c} = \\overrightarrow{\\rm a} + \\overrightarrow{\\rm b} $\n",
    "- Vector addition can be performed graphically, using the head-to-tail as shown in this figure. (First, the two vectors `a` and `b` are placed together such that the head of vector `a` connects the tail of vector `b`. Next, to find the sum, a resultant vector `c` is drawn such that it connects the tail of `a` to the head of `b`.)\n",
    "\n",
    "- Vection addition can also be done by simply performing an element by elementt addition.\n",
    "\n",
    "$ \\hspace{3.0cm} \\overrightarrow{\\rm c} = (a1 + b1, a2 + b2, a3 + b3) $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d273bf72",
   "metadata": {},
   "source": [
    "**Example 1:** Consider a vector $\\overrightarrow{\\rm a}$, having its tail at point $(-1, 3)$ and head at point $(5,2)$. Consider another vector $\\overrightarrow{\\rm b}$, having its tail at point $(1, -2)$ and head at point $(-2,2)$. Determine the resultant sum vector \\overrightarrow{\\rm c}. Also, give the magnitude and angle of the resultant vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf65a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating the two vectors to origin\n",
    "u = np.array([5-(-1), 2-3])  \n",
    "v = np.array([-2-1, 2-(-2)]) \n",
    "print(\"U = \", u)\n",
    "print(\"V = \", v)\n",
    "\n",
    "# calculate the resultant vector R\n",
    "r = u + v\n",
    "print(\"R = \", r)\n",
    "\n",
    "# calculating magnitude of R from its components using L2 norm\n",
    "mag = numpy.linalg.norm([r[0], r[1]], ord=2)\n",
    "mag = (r[0]**2 + r[1]**2)**(1/2)\n",
    "print(\"|R| = \", mag)\n",
    "\n",
    "# calculating angle of resultant vector R\n",
    "theta_rad = math.atan(r[1]/r[0])      # acos, asin, and atan take a ratio as input and return an angle in radians\n",
    "theta_deg = theta_rad*(180/math.pi)   # so we need to convert it into degrees\n",
    "# Since, both x and y coordinates are positive, that means the angle exists in the first quadrant\n",
    "# So no need to add anything\n",
    "theta_deg = theta_deg + 0\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "\n",
    "vectors = [u, v, r]\n",
    "tails   = [(0,0), u, (0,0)]\n",
    "plot_vector(vectors, tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1009254",
   "metadata": {},
   "source": [
    "**Example 2:** Given two vectors, U = 10 m, Φ  = 30 degrees and  V = 20m, Φ  = 60 degrees, determine their sum. Then, calculate the magnitude and the angle of the resultant vector using the component method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c61f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "# calculating x and y components of vector U\n",
    "ux = 10*math.cos(30*math.pi/180)       # sin, cos and tan take input angle in radians and return the ratio. \n",
    "uy = 10*math.sin(30*math.pi/180)       \n",
    "print(\"Ux: %.2f\" %ux, \"m\")\n",
    "print(\"Uy: %.2f\" %uy, \"m\")\n",
    "\n",
    "# calculating x and y components of vector V\n",
    "vx = 20*m.cos(60*math.pi/180)\n",
    "vy = 20*m.sin(60*math.pi/180)\n",
    "print(\"Vx: %.2f\" %vx, \"m\")\n",
    "print(\"Vy: %.2f\" %vy, \"m\")\n",
    "\n",
    "# calculate the sum of the two vectors R = U + V\n",
    "rx = ux + vx\n",
    "ry = uy + vy\n",
    "r = np.array([rx, ry])\n",
    "print(\"Resultant vector R: \", r)\n",
    "\n",
    "# calculating magnitude of R from its components using L2 norm\n",
    "mag = numpy.linalg.norm([rx, ry], ord=2)\n",
    "mag = (rx**2 + ry**2)**(1/2)\n",
    "print(\"|R| = \", mag)\n",
    "\n",
    "# calculating angle of resultant vector R\n",
    "theta_rad = math.atan(r[1]/r[0])    # acos, asin, and atan take a ratio as input and return an angle in radians\n",
    "theta_deg = theta_rad*(180/math.pi)   # so we need to convert it into degrees\n",
    "# Since, both the coordinates are positive, that means the angle exists in the first quadrant\n",
    "# So the angle is already computed from positive x-axis\n",
    "theta_deg = math.degrees(theta_rad)\n",
    "theta_deg = theta_deg + 0\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "\n",
    "vectors = [(ux,uy), (vx,vy), (rx,ry)]\n",
    "tails   = [(0,0), (ux,uy), (0,0)]\n",
    "plot_vector(vectors, tails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8c94cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e0cd04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb2bc06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "365ed74d",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" height=\"300\"  src=\"images/LA/mul1.png\"  >\n",
    "\n",
    "### b. Multiplying a Vector with a Scalar Value (Scaling)\n",
    "- Multiplication by a scalar is a way of changing the magnitude and/or direction of a vector. \n",
    "- The multiplication of a scalar value with a vector A will yield another vector.\n",
    "\n",
    "\n",
    "- **Example 1:** Given the vector a = (-4, -6). If you multiply this vector by $-1/2$, its length (magnitude) halves and direction is reversed. \n",
    "\n",
    "$$\n",
    "   \\mathbf{-0.5a} = -0.5\\left[ \\begin{array}{c} -4 \\\\ -6  \\end{array} \\right] =\n",
    "      \\left[ \\begin{array}{c} 2 \\\\ 3  \\end{array} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d91f4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([-4, -6])\n",
    "print (\"Vector A: \", a)\n",
    "mag = numpy.linalg.norm(a, ord=2) # calculate magnitude using L2 norm\n",
    "print(\"|A| = \",mag)\n",
    "# calculating angle of vector A\n",
    "theta_rad = math.atan(a[1]/a[0])  \n",
    "theta_deg = theta_rad*(180/math.pi)\n",
    "# Since, both the coordinates are negative, that means, the angle exists in the third quadrant\n",
    "# Since, the angle is positive, that means, it is measured from negative x-axis in counter-clockwise direction\n",
    "# So we have to add 180 degree to get the angle from positive x-axis in counter-clockwise direction\n",
    "theta_deg = theta_deg + 180\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "\n",
    "# Multiplying the vector A  by -0.5 will give a new vector B\n",
    "b = a * -0.5\n",
    "print (\"\\nVector B: \", b)\n",
    "# To calculate magnitude using L2 norm\n",
    "mag = numpy.linalg.norm(b, ord=2)\n",
    "mag = (b[0]**2 + b[1]**2) **(1/2)\n",
    "print(\"|-A| = \",mag)\n",
    "\n",
    "# calculating angle of vector B\n",
    "theta_rad = m.atan(b[1]/b[0])    \n",
    "theta_deg = theta_rad*(180/m.pi) \n",
    "# Since, both the coordinates are positive, that means, the angle exists in the first quadrant\n",
    "# Since, the angle is positive, that means, it is measured from negative x-axis in counter-clockwise direction\n",
    "# So need not to add anything\n",
    "theta_deg = theta_deg + 0\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "\n",
    "vectors = [a, b]\n",
    "plot_vector(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50c9795",
   "metadata": {},
   "source": [
    "**Example 2:** Given the vector a = (1, 1). If you multiply this vector by $3$, its length (magnitude) is trippled and direction remains the same.\n",
    "\n",
    "$$\n",
    "   \\mathbf{3a} = 3\\left[ \\begin{array}{c} 1 \\\\ 1  \\end{array} \\right] =\n",
    "      \\left[ \\begin{array}{c} 3 \\\\ 3  \\end{array} \\right]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427a3c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given vector A\n",
    "a = np.array([1, 1])\n",
    "print (\"Vector A: \", a)\n",
    "# calculate magnitude using L2 norm\n",
    "mag = numpy.linalg.norm(a, ord=2)\n",
    "mag = (a[0]**2 + a[1]**2) **(1/2)\n",
    "print(\"|A| = \",mag)\n",
    "# calculating angle of vector A\n",
    "theta_rad = math.atan(a[1]/a[0])    # acos, asin, and atan take a ratio as input and return an angle in radians\n",
    "theta_deg = theta_rad*(180/math.pi)   # so we need to convert it into degrees\n",
    "# Since, both the coordinates are positive, that means, the angle exists in the first quadrant\n",
    "# So we need not to add anything\n",
    "theta_deg = theta_deg + 0\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "\n",
    "\n",
    "\n",
    "# Multiplying the vector A  by 3 will give a new vector\n",
    "b = a * 3\n",
    "print (\"\\nVector B: \", b)\n",
    "# To calculate magnitude using L2 norm\n",
    "mag = numpy.linalg.norm(b, ord=2)\n",
    "mag = (b[0]**2 + b[1]**2) **(1/2)\n",
    "print(\"|-A| = \",mag)\n",
    "\n",
    "# calculating angle of vector B\n",
    "theta_rad = m.atan(b[1]/b[0])    # acos, asin, and atan take a ratio as input and return an angle in radians\n",
    "theta_deg = theta_rad*(180/m.pi)   # so we need to convert it into degrees\n",
    "# Since, both the coordinates are positive, that means, the angle exists in the first quadrant\n",
    "# So we need not to add anything\n",
    "theta_deg = theta_deg + 0\n",
    "print(\"Counter-Clockwise angle in degrees from positive x-axis: \", theta_deg)\n",
    "\n",
    "vectors = [a, b]\n",
    "plot_vector(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7717eff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd656936",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196f1d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b8692",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afce88d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b77b382",
   "metadata": {},
   "source": [
    "## 6.  Unit Vectors and Unit Basis Vectors\n",
    "\n",
    "### a. Unit Vector\n",
    "- Every vector $\\overrightarrow{\\rm v}$ in $\\mathbb{R}^2$, $\\mathbb{R}^3$,..., $\\mathbb{R}^n$ will have a corresponding unit vector, which points in exactly the same direction as  $\\overrightarrow{\\rm v}$, but has a magnitude of one.\n",
    "- A unit vector of a vector $\\overrightarrow{\\rm v}$ is represented as $\\hat{\\rm v}$ and can be calculated as:\n",
    "$$\\hat{\\rm v} = \\frac{\\overrightarrow{\\rm v}}{|\\rm v|}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11663053",
   "metadata": {},
   "source": [
    "**Example 1:**  Find the unit vector of $\\overrightarrow{\\rm v} =\\begin{bmatrix} 3 \\\\2 \\end{bmatrix}$\n",
    "\n",
    "$$\\hat{\\rm v_1} = \\frac{1}{3.6}\\begin{bmatrix} 3 \\\\2 \\end{bmatrix}=\\begin{bmatrix} 0.832 \\\\0.554 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbe1389",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array((3,2))\n",
    "mag_v = numpy.linalg.norm(v, ord=2)\n",
    "\n",
    "vhat = (v[0]/mag_v, v[1]/mag_v)\n",
    "mag_vhat = numpy.linalg.norm(vhat,ord=2)\n",
    "\n",
    "print(\"vector v = \", v, \" magnitude =\", mag_v)\n",
    "print(\"Unit vector of v = \", vhat, \" magnitude =\", mag_vhat)\n",
    "\n",
    "vectors = [v, vhat]\n",
    "plot_vector(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ee0684",
   "metadata": {},
   "source": [
    "> Note: The unit vector $\\overrightarrow{\\rm u}$ of the given vector $\\overrightarrow{\\rm v} =(3,2)$ is one unit long, and sits right on top of $\\overrightarrow{\\rm v}$, pointing in the same direction as $\\overrightarrow{\\rm v}$. \n",
    "\n",
    "> The smaller triangle formed by the unit vector $\\overrightarrow{\\rm u}$ is similar to the larger triangle formed by the vector $\\overrightarrow{\\rm v}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acedc97d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff69c4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa9344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "adbb6bcf",
   "metadata": {},
   "source": [
    "**Example 2:**  Find the unit vector of $\\overrightarrow{\\rm v} =\\begin{bmatrix} 12 \\\\3 \\\\-4 \\end{bmatrix}$\n",
    "\n",
    "$$\\hat{\\rm v_1} = \\frac{1}{13}\\begin{bmatrix} 12 \\\\3\\\\-4 \\end{bmatrix}=\\begin{bmatrix} 0.92 \\\\0.23 \\\\-0.3\\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46c612a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = np.array((12, 3, -4))\n",
    "mag_v = numpy.linalg.norm(v, ord=2)\n",
    "\n",
    "vhat = (v[0]/mag_v, v[1]/mag_v, v[2]/mag_v)\n",
    "mag_vhat = numpy.linalg.norm(vhat,ord=2)\n",
    "\n",
    "print(\"vector v = \", v, \" magnitude =\", mag_v)\n",
    "print(\"Unit vector of v = \", vhat, \" magnitude =\", mag_vhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b07d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8cab26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a586c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce3c32c0",
   "metadata": {},
   "source": [
    "### b. Basis Vectors\n",
    "- Basis vectors are special unit vectors pointing along the x, y or the z-axis.\n",
    "- In two-dimensional space $\\mathbb{R}2$, we define two specific basis vectors, $\\hat{i} = (1,0)$ and $\\hat{j} = (0,1)$ and in three-dimensional space $\\mathbb{R}3$, we define three specific basis vectors $\\hat{i} = (1,0,0)$, $\\hat{j} = (0,1,0)$, and $\\hat{k} = (0,0,1)$.\n",
    "- A vector can be represented as a linear combination of its basis vectors.\n",
    "- Let me express the vector $\\overrightarrow{\\rm v}$  in two-dimensional space $\\mathbb{R}2$ as its basis vectors:\n",
    "<h4 align=\"center\"> $\\overrightarrow{\\rm v} \\quad=\\quad(6,4)\\quad=\\quad 6\\hat{i} + 4\\hat{j}\\quad=\\quad6 \\left[ \\begin{array}{c} 1 \\\\ 0  \\end{array} \\right] +    4 \\left[ \\begin{array}{c} 0 \\\\ 1  \\end{array} \\right] $ </h4>\n",
    "\n",
    "\n",
    "- Let me express the vector $\\overrightarrow{\\rm v}$  in three-dimensional space $\\mathbb{R}3$ as its basis vectors:\n",
    "<h4 align=\"center\"> $\\overrightarrow{\\rm v} \\quad=\\quad(-3,2,-1)\\quad=\\quad -3\\hat{i} + 2\\hat{j} - \\hat{k}\\quad=\\quad -3 \\left[ \\begin{array}{c} 1 \\\\ 0 \\\\0  \\end{array} \\right] +    2 \\left[ \\begin{array}{c} 0 \\\\ 1 \\\\ 0  \\end{array} \\right] -    \\left[ \\begin{array}{c} 0 \\\\ 0 \\\\ 0  \\end{array} \\right]  $ </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d82523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a2253c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604bb4b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411761d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6682e64a",
   "metadata": {},
   "source": [
    "**Example 1:**  Write down the vector $\\overrightarrow{\\rm v} =(3,2)$, as linear combination of its unit vectors and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58f8ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two basis vectors\n",
    "i = numpy.array((1,0))\n",
    "j = numpy.array((0,1))\n",
    "\n",
    "# create a new vector, that is a scaled version of these two basis vectors\n",
    "vec = 3*i + 2*j\n",
    "vectors = [i, j, 3*i, 2*j, vec]\n",
    "plot_vector(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4137ccb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896350f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b01e19b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5de6e2eb",
   "metadata": {},
   "source": [
    "### c. Linear combination and Span\n",
    "- Linear combination is adding together two scaled vectors.\n",
    "- Span is the set of all possible linear combinations, that we can create from two vectors.\n",
    "- Using the basis vectors for example in $\\mathbb{R}2$, we can actually build every vector in two-dimensional space, simply by adding scaled combinations of $\\hat{i}$ and $\\hat{j}$. \n",
    "- A span just describes the space reachable by linear combinations of some given vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07cb706f",
   "metadata": {},
   "source": [
    "**Example 1:**  Generate hundred random vectors from linear combinations of basis vectors, $ \\hat{i}=(1,0)$ and $\\hat{j}=(0,1)$. The scalar multiples $m$ and $n$ range from random values $-8$ to $+8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f413ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import randint\n",
    "i = numpy.array((1,0))\n",
    "j = numpy.array((0,1))\n",
    "\n",
    "vectors = []\n",
    "for _ in range(1000):\n",
    "    m = randint(-8,8)\n",
    "    n = randint(-8,8)\n",
    "    vectors.append(m*i + n*j)\n",
    "    \n",
    "plot_vector(vectors)\n",
    "pyplot.title(\"Hundred random vectors, created from the basis vectors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943446d",
   "metadata": {},
   "source": [
    "> You can imagine that we can fill up the whole plane with infinite linear combinations, eventually filling up the entire 2D plane. **Indeed, the *span* of the basis vectors is the whole 2D space.**\n",
    "> Remember, we are not forced to use the unit vectors  $\\mathbf{i}$ and $\\mathbf{j}$ as our basis vectors: other pairs of vectors could form a basis.\n",
    "\n",
    ">- **Question:** Can we use another pair of vectors as basis and generates linear combinations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b193987b",
   "metadata": {},
   "source": [
    "**Example 2:**  Generate hundred random vectors from linear combinations of two vectors, $a=(-2,1)$ and $b=(1,-3)$. The scalar multiples $m$ and $n$ range from random values $-8$ to $+8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8229d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = numpy.array((-2,1))\n",
    "b = numpy.array((1,-3))\n",
    "\n",
    "vectors = []\n",
    "for _ in range(100):\n",
    "    m = randint(-8,8)\n",
    "    n = randint(-8,8)\n",
    "    vectors.append(m*a + n*b)\n",
    "    \n",
    "plot_vector(vectors)\n",
    "pyplot.title(\"Hundred random vectors, created from the basis vectors\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6c7000",
   "metadata": {},
   "source": [
    "**Example 3:**  Generate fifty random vectors from linear combinations of two vectors, $ \\hat{c}=(-2,-1)$ and $\\hat{d}=(1,0.5)$. The scalar multiples $m$ and $n$ range from random values $-8$ to $+8$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564b029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = numpy.array((-2,-1))\n",
    "d = numpy.array((1,0.5))\n",
    "vectors = []\n",
    "for _ in range(50):\n",
    "    m = randint(-8,8)\n",
    "    n = randint(-8,8)\n",
    "    vectors.append(m*c + n*d)\n",
    "    \n",
    "plot_vector(vectors)\n",
    "pyplot.title(\"Fifty linear combinations of the vectors $\\mathbf{c}$ and $\\mathbf{d}$.\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f811be3e",
   "metadata": {},
   "source": [
    "**What's going on?**\n",
    "\n",
    "- The vector $\\mathbf{d}$ is a scaled version of vector $\\mathbf{c}$, so we say that the two vectors are colinear. \n",
    "- Thus, all linear combinations of $\\mathbf{c}$ and $\\mathbf{d}$ end up on one line, which is their span. Their combinations are not able to travel all over the plane!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b54fd2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d04fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdab34f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c49a70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d3472d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fc6123",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69265e4e",
   "metadata": {},
   "source": [
    "## 8.  Vector to Vector Multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c387cb2a",
   "metadata": {},
   "source": [
    "### a. Dot Product\n",
    "- The multiplication of vectors is conducted through dot product such that the two vectors (same size) being multiplied produce a scalar value.\n",
    "- This is the most commonly used operation in machine learning.\n",
    "- **Mathematically:**\n",
    "    - The dot product of two vectors (when their components are known) is obtained by the summation of product of respective components:\n",
    "$$u \\cdot v = \\sum_{i=1}^{n} u_i v_i$$\n",
    "\n",
    "- **Geomatrically:**\n",
    "    - The dot product of two vectors (when their magnitude and angle between the two vectors are known) is the product of the magnitude of the vectors and the cosine of the angle between them:\n",
    "\n",
    "$$ \n",
    "\\hspace{3.0cm} u.v \\hspace{.3 cm}=\\hspace{.3 cm} |u| \\hspace{.3 cm} |v| \\hspace{.3 cm} Cos \\theta \n",
    "$$\n",
    "    \n",
    " - The formula to compute the **angle between two vectors** using Dot Product is:\n",
    "\n",
    "$$\n",
    "\\hspace{3.0cm} \\theta \\hspace{.3 cm}=\\hspace{.3 cm} cos^{-1} \\hspace{0.1 cm} \\frac{u.v}{|u| |v|} \n",
    "$$\n",
    "\n",
    "- The vector dot product is commutative in nature, i.e., $ u.v = v.u $ \n",
    "- The vector dot product can be to **determine orthogonality**, i.e., to check whether or not the two vectors are perpendicular to each other. If the vectors are perpendicular to each other then their dot product is zero\n",
    "- The dot product is the key tool for calculating **vector projections** and **vector decompositions** as well\n",
    "- The dot product is ubiquitous in deep learning: It is performed at every artificial neuron in a deep neural network, which may be made up of millions (or orders of magnitude more) of these neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f755ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df478eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a3a87ac",
   "metadata": {},
   "source": [
    "**Example 1:** Find the dot product of the two vectors A(2, 2, -1) and B(5, -3, 2), and also calculate the angle between them.\n",
    "$\\hspace{8 cm}u \\cdot v = \\sum_{i=1}^{n} u_i v_i\\hspace{2 cm}$ OR $\\hspace{2 cm}  u.v \\hspace{.3 cm}=\\hspace{.3 cm} |u| \\hspace{.3 cm} |v| \\hspace{.3 cm} Cos \\theta $\n",
    "\n",
    "\n",
    "$$ \\theta \\hspace{.3 cm}=\\hspace{.3 cm} cos^{-1} \\hspace{0.1 cm} \\frac{u.v}{|u| |v|} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab02cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4e23f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 2, -1])\n",
    "b = np.array([5, -3, 2])\n",
    "print(\"a = \", a)\n",
    "print(\"b = \", b)\n",
    "\n",
    "#calculate magnitude of vector A and B\n",
    "mag1 = numpy.linalg.norm(a, ord=2)\n",
    "mag2 = numpy.linalg.norm(b, ord=2)\n",
    "print(\"|a| = \", mag1)\n",
    "print(\"|b| = \", mag2)\n",
    "\n",
    "# Calculate Dot Product mathematically\n",
    "ab = np.dot(a,b)\n",
    "ab = a[0]*b[0] + a[1]*b[1]+a[2]*b[2]\n",
    "print(\"\\na.dot(b) = \", ab)\n",
    "\n",
    "\n",
    "theta_rad = math.acos(ab/(mag1*mag2))\n",
    "theta_deg = theta_rad*(180/math.pi)  \n",
    "print(\"Angle: \", theta_deg)\n",
    "\n",
    "\n",
    "# Calculate Dot Product geometrically\n",
    "print(\"a.b = |a| |b| cos(𝜃) = \", mag1*mag2*math.cos(theta_rad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fed969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d5718",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24ade632",
   "metadata": {},
   "source": [
    "**Example 2:** Find out the angle between the given two vectors using dot product: <br>\n",
    "$a = 2i + 2j + 3k$<br>\n",
    "$b = 6i + 3j + 1k$\n",
    "\n",
    "\n",
    "$\\hspace{8 cm}u \\cdot v = \\sum_{i=1}^{n} u_i v_i\\hspace{2 cm}$ OR $\\hspace{2 cm}  u.v \\hspace{.3 cm}=\\hspace{.3 cm} |u| \\hspace{.3 cm} |v| \\hspace{.3 cm} Cos \\theta $\n",
    "\n",
    "\n",
    "$$ \\theta \\hspace{.3 cm}=\\hspace{.3 cm} cos^{-1} \\hspace{0.1 cm} \\frac{u.v}{|u| |v|} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad290a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([2, 2, 3])\n",
    "b = np.array([6, 3, 1])\n",
    "\n",
    "# printing original vectors\n",
    "print(\"a = \", a)\n",
    "print(\"b = \", b)\n",
    "\n",
    "#calculate magnitude of vector A and B\n",
    "mag1 = numpy.linalg.norm(a, ord=2)\n",
    "mag2 = numpy.linalg.norm(b, ord=2)\n",
    "print(\"|a| = \", mag1)\n",
    "print(\"|b| = \", mag2)\n",
    "\n",
    "# Calculate Dot Product mathematically\n",
    "ab = np.dot(a,b)\n",
    "ab = a[0]*b[0] + a[1]*b[1]+a[2]*b[2]\n",
    "print(\"\\na.dot(b) = \", ab)\n",
    "\n",
    "\n",
    "theta_rad = math.acos(ab/(mag1*mag2))\n",
    "theta_deg = theta_rad*(180/math.pi)  \n",
    "print(\"Angle: \", theta_deg)\n",
    "\n",
    "\n",
    "# Calculate Dot Product geometrically\n",
    "print(\"a.b = |a| |b| cos(𝜃) = \", mag1*mag2*math.cos(theta_rad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c95c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ffea22c",
   "metadata": {},
   "source": [
    "### b. Vector Cross Product\n",
    "<img align=\"right\" width=\"200\" height=\"200\"  src=\"images/cross-product.png\"  >\n",
    "\n",
    "- Unlike dot product, the cross product of two vectors produce a new vector and the direction of the resultant vector is given by the right-hand rule.\n",
    "\n",
    "- **Mathematically:**\n",
    "    - The cross product of two vectors (when their components are known) is obtained by using the determinant of the matrix as given below:\n",
    "\n",
    "$$\n",
    "\\vec{a}\\times\\vec{b} = \\begin{pmatrix}\n",
    "      \\hat{i} & \\hat{j} & \\hat{k}\\\\ \n",
    "       a_1      &   a_2     &  a_3 \\\\ \n",
    "       b_1      &   b_2    &  b_3\n",
    "   \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\vec{a}\\times\\vec{b} = (a_2b_3 - b_2a_3)\\hat{i} - (a_1b_3 - b_1a_3)\\hat{j} +(a_1b_2 - b_1a_2)\\hat{k} \n",
    "$$\n",
    "\n",
    "- **Geomatrically:**\n",
    "    - The cross product of two vectors (when their magnitude and angle between the two vectors are known) is the product of the magnitude of the vectors and the sine of the angle between them:\n",
    "\n",
    "$$\\hspace{3 cm} \\vec{a} \\times \\vec{b} \\hspace{.3 cm}=\\hspace{.3 cm} |a| \\hspace{.3 cm} |b| \\hspace{.3 cm} sin (\\theta) \\hspace{.3 cm} \\hat{n}$$\n",
    "\n",
    "- Where $\\hat{n}$ is the unit vector perpendicular to the plane containing the given two vectors, in the direction given by the right-hand rule.\n",
    "\n",
    "- The formula to compute the **angle between two vectors** using Cross Product is:\n",
    "\n",
    "$$ \\theta \\hspace{.3 cm}=\\hspace{.3 cm} sin^{-1} \\hspace{0.1 cm} \\frac{|\\vec{a}\\times\\vec{b}|}{|a| |b|} \n",
    "$$\n",
    "\n",
    "\n",
    "- **Properties:**\n",
    "    - The cross product is zero in length when vectors  A and B point in the same, or opposite, direction.\n",
    "    - The cross product is maximum in length when vectors A and B are at right angles.\n",
    "    - The vector cross product is NOT commutative in nature, i.e., $ a$ x $b \\neq b$ x $a $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c99ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4508e0ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4e263c6",
   "metadata": {},
   "source": [
    "**Example 1:** Find the cross product of two vectors A(3,5,-7) and B(2,-6,4). Later prove that the resultant vector is perpendicular to both A and B.\n",
    "\n",
    "$$\n",
    "\\vec{a}\\times\\vec{b} = \\begin{pmatrix}\n",
    "      \\hat{i} & \\hat{j} & \\hat{k}\\\\ \n",
    "       3      &   5     &  -7 \\\\ \n",
    "       2      &   -6    &  4\n",
    "   \\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "= (20-42)\\hat{i} - (12+14)\\hat{j} +(-18-10)\\hat{k} \n",
    "$$\n",
    "$$\n",
    "= -22\\hat{i}-26\\hat{j}-28\\hat{k}\n",
    "$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96101512",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([3, 5, -7])   \n",
    "b = np.array([2, -6, 4])   \n",
    "\n",
    "# printing original vectors\n",
    "print(\"a = \", a)\n",
    "print(\"b = \", b)\n",
    "\n",
    "# Calculate Cross Product mathematically\n",
    "ab = np.cross(a,b)\n",
    "print(\"a x b = \", ab)\n",
    "\n",
    "\n",
    "#calculate magnitude of vector a and b\n",
    "mag1 = numpy.linalg.norm(a, ord=2)\n",
    "mag2 = numpy.linalg.norm(b, ord=2)\n",
    "mag3 = numpy.linalg.norm(ab, ord=2)\n",
    "print(\"\\n|a| = \", mag1)\n",
    "print(\"|b| = \", mag2)\n",
    "print(\"|axb| = \", mag2)\n",
    "\n",
    "# Calculate the angle between two vectors\n",
    "mag3 = numpy.linalg.norm(ab, ord=2)\n",
    "theta_rad = math.asin(mag3/(mag1*mag2))\n",
    "theta_deg = math.degrees(theta_rad) #theta_rad*(180/m.pi)  \n",
    "print(\"Angle: \", theta_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bb9e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5c6123",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" height=\"300\"  src=\"images/LA/normal-vector.jpg\"  >\n",
    "\n",
    "### c. Orthogonal  and Orthonormal Vectors: \n",
    "**Orthogonal Vector:**\n",
    "- A normal vector is a vector that makes an angle of 90° with another surface, vector, or axis.\n",
    "- Two vectors are said to be orthogonal, if their dot product is equal to zero.\n",
    "\n",
    "$\\hspace{3 cm}\\vec{a}.\\vec{b} \\hspace{.3 cm}=\\hspace{.3 cm} |a| \\hspace{.1 cm} |b| \\hspace{.3 cm} cos(90) = 0$\n",
    "\n",
    "\n",
    "- Two vectors are said to be orthogonal, if their cross product is equal to $|a| \\hspace{.1 cm} |b|$.\n",
    "\n",
    "$\\hspace{3 cm} \\vec{a}$ x $\\vec{b} \\hspace{.3 cm}=\\hspace{.3 cm} |a| \\hspace{.1 cm} |b| \\hspace{.3 cm} sin (90) \\hspace{.3 cm} =  |a| \\hspace{.1 cm} |b|$\n",
    "\n",
    "\n",
    "**Orthonormal Vector:**\n",
    "- Orthonormal vectors are special type of orthogonal vectors having a magnitude of one.\n",
    "- So basis vectors are an example of orthonormal vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3fd722",
   "metadata": {},
   "source": [
    "**Example 1:** Determine if  the two vectors A(6, -2, -1) and B(2, 5, 2) are perpendicular to eachother. (If the vectors are perpendicular to each other then their dot product is zero)\n",
    "$$\n",
    "u \\cdot v = \\sum_{i=1}^{n} u_i v_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([6, -2, -1])\n",
    "b = np.array([2, 5, 2])\n",
    "\n",
    "# printing original vectors\n",
    "print(\"a = \", a)\n",
    "print(\"b = \", b)\n",
    "\n",
    "# Calculating Dot Product of Two Vectors\n",
    "ab = a.dot(b)\n",
    "ab = a[0]*b[0] + a[1]*b[1]+a[2]*b[2]\n",
    "print(\"a.b = \", ab)\n",
    "\n",
    "\n",
    "mag1 = numpy.linalg.norm(a, ord=2)\n",
    "mag2 = numpy.linalg.norm(b, ord=2)\n",
    "theta_rad = math.acos(ab/(mag1*mag2))\n",
    "theta_deg = math.degrees(theta_rad) #theta_rad*(180/m.pi)  \n",
    "print(\"Angle: \", theta_deg)\n",
    "\n",
    "\n",
    "lhs = mag1*mag2*math.sin(90*(math.pi/180))\n",
    "rhs = mag1*mag2\n",
    "print (\"|a| |b| sin(90) = \", lhs)\n",
    "print (\"|a| |b| = \", rhs)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca48c43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9785f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02990122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af83802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702058d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3a68da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252c3d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "659c3666",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section II: (Overview of Linear Alagebra: Matrices) </span>\n",
    "<h2 align=\"center\">\"Unfortunately, no one can be told what the Matrix is. You have to see it for yourself.\"</h2>\n",
    "<h4 align=\"right\">-Morpheus-</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66448eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import math\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef01726",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c92892",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5f079c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2064123e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8676273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db926a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7ffaa9b",
   "metadata": {},
   "source": [
    "## 1. Overview of Matrix\n",
    "- A matrix is a **two-dimensional array** of scalar values with one or more columns and one or more rows. They are also known as arrays.\n",
    "- The numbers, variables, or expressions inside the matrix are called the entries or elements of a matrix.\n",
    "$$\n",
    "A_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3}& \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}& \\cdots & a_{2,n} \\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}&\\cdots & a_{3,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "a_{m,1} & a_{m,2} & a_{m,3}& \\cdots & a_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "- The notation for a matrix is often an uppercase letter, such as **A**, and dimensions of a matrix is denoted as `m × n` for the number of rows and the number of columns respectively. \n",
    "- The elements of a matrix are referred to by the row and the column subscript, such as **a<sub>i</sub>,<sub>j</sub>**. \n",
    "- Matrices are a foundational element of linear algebra. Matrices are used throughout the field of machine learning in the description of **algorithms** and **processes** such as the input data variable (X) when training an algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0c6905",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c332c32d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7beb006b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d70ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fc063f1",
   "metadata": {},
   "source": [
    "## 2. Matrices and its Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092249b7",
   "metadata": {},
   "source": [
    "**Example:** Defining a 3x3 matrix using NumPy, $A =$ \n",
    "$\\begin{bmatrix} \n",
    "       -2 & 1 & 3\\\\ \n",
    "       1 & -3 & 5\\\\\n",
    "       -3 & 2 & 1\n",
    " \\end{bmatrix} $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2811c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-2, 1, 3], [1, -3, 2], [-3, 2, 1]])\n",
    "print(\"Matrix A = \\n\", A)\n",
    "\n",
    "print(\"A.ndim: \", A.ndim)   \n",
    "print(\"A.shape: \", A.shape) \n",
    "print(\"A.size: \", A.size)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075cab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f22274",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a43a2d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7244e43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b54414e",
   "metadata": {},
   "source": [
    "### a. Row Vector\n",
    "- A row vector is a matrix with exactly one row and one or many columns.\n",
    "- A row vector with one row and n columns is shown below:\n",
    "\n",
    "$\\begin{bmatrix} \n",
    "       b_1 & b_2 & b_3 & \\cdots & b_n\\\\ \n",
    " \\end{bmatrix} $  \n",
    " \n",
    "- Let us create a row vector having one row and three columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a8c3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([-2, 1, 3])\n",
    "print(\"Matrix B = \\n\", B)\n",
    "print(\"A.ndim: \", B.ndim)   \n",
    "print(\"A.shape: \", B.shape) \n",
    "\n",
    "# Taking the transpose of a matrix means to interchange the rows with columns. \n",
    "# The rows become columns and the columns become rows.\n",
    "Bt = B.T\n",
    "print(\"\\nTranspose of Matrix B = \\n\", Bt)\n",
    "print(\"A.ndim: \", Bt.ndim)   \n",
    "print(\"A.shape: \", Bt.shape) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7baa6d6",
   "metadata": {},
   "source": [
    "### b. Column Vector\n",
    "- A column vector is a matrix with exactly one column and one or many rows.\n",
    "- A column vector with one column and n rows is shown below:\n",
    "\n",
    "$\\begin{bmatrix} \n",
    "       b_1 \\\\ b_2 \\\\ b_3 \\\\ \\vdots \\\\ b_n\\\\ \n",
    " \\end{bmatrix} $  \n",
    " \n",
    "- Let us create a column vector having one column and three rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed52e6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[-2], [1], [3]])\n",
    "print(\"Matrix B = \\n\", B)\n",
    "print(\"A.ndim: \", B.ndim)   \n",
    "print(\"A.shape: \", B.shape) \n",
    "\n",
    "# Taking the transpose of a matrix means to interchange the rows with columns. \n",
    "# The rows become columns and the columns become rows.\n",
    "Bt = B.T\n",
    "print(\"\\nTranspose of Matrix B = \\n\", Bt)\n",
    "print(\"A.ndim: \", Bt.ndim)   \n",
    "print(\"A.shape: \", Bt.shape) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39eeb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6d580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3936bd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da44d51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f30b107f",
   "metadata": {},
   "source": [
    "### c. Zero Matrix\n",
    "- A matrix having all its elements as zero is a zero matrix $A =$ \n",
    "$\\begin{bmatrix} \n",
    "       0 & 0 & 0\\\\ \n",
    "       0 & 0 & 0\n",
    " \\end{bmatrix} $  \n",
    " \n",
    "- We can create a zero matrix using the `numpy.zeros()` method as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757ef4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.zeros((2,3), dtype=np.int16)\n",
    "print(\"Matrix A = \\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6b8a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f14504",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd044255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcee330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb561a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "639e7732",
   "metadata": {},
   "source": [
    "### d. Ones Matrix\n",
    "- A matrix having all its elements as ones is a ones matrix $A =$ \n",
    "$\\begin{bmatrix} \n",
    "       1 & 1\\\\ \n",
    "       1 & 1\\\\\n",
    "       1 & 1\n",
    " \\end{bmatrix} $  \n",
    " \n",
    "- We can create a ones matrix using the `numpy.ones()` method as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1ea268",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.ones((2, 3), dtype=int)\n",
    "print(\"Matrix A = \\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59a8e57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9ac60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6377432a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc12e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "952c721e",
   "metadata": {},
   "source": [
    "### e. Random Integer Matrix\n",
    "- To create a Matrix of any size, with random values of low inclusive and high exclusive and size size, we can use the  numpy.random.randint(low, high, size) method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb71875",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(0, 10, size =(5, 3))\n",
    "print (\"Matrix A = \\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e3c9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a1820e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c9aa863",
   "metadata": {},
   "source": [
    "### f. Square Matrix\n",
    "- An `n × n` matrix is said to be a square matrix of order `n`. \n",
    "- In simple words, when the number of rows and the number of columns in the matrix are equal then the matrix is called square matrix.\n",
    "\n",
    "$A =$ \n",
    "$\\begin{bmatrix} \n",
    "       6 & 3 & 8\\\\ \n",
    "       2 & 1 & 9\\\\\n",
    "       8 & 2 & 7\n",
    " \\end{bmatrix} $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ea6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 10, size =(3, 3))\n",
    "np.random.seed(54)\n",
    "print (\"Matrix A = \\n\", A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73c7cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ad6169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af382af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e2e89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ae44fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba1cfc47",
   "metadata": {},
   "source": [
    "### g. Symmetric Matrix\n",
    "- A symmetric matrix is a type of square matrix where the `top-right triangle` is the same as the `bottom-left` triangle.\n",
    "- Matrix A is a   3 × 3 symmetric matrix: \n",
    "$A =$ \n",
    "$\\begin{bmatrix} \n",
    "       4 & 1 & 7\\\\ \n",
    "       1 & -3 & 5\\\\\n",
    "       7 & 5 & 2\n",
    " \\end{bmatrix} $  \n",
    "\n",
    "\n",
    "- In the above 3 × 3 square matrix A the diagonal 4, -3, 2 is the principal diagonal and 4, -3 and 2 are said to be the diagonal elements.\n",
    "-  The transpose of a symmetric matrix is the matrix itself. $A = A^T$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6e7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 1, 7], [1, -3, 5], [7, 5, 2]])\n",
    "print(\"Matrix A = \\n\", A)\n",
    "\n",
    "# taking transpose of the matrix\n",
    "print('\\nTranspose of A = \\n', A.T)\n",
    "np.transpose(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ac407",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ac78d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0cd9b034",
   "metadata": {},
   "source": [
    "### h. Triangular Matrix\n",
    "- Given a matrix A, having `m` rows and `n` columns. \n",
    "$$\n",
    "A_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3}& \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}& \\cdots & a_{2,n} \\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}&\\cdots & a_{3,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "a_{m,1} & a_{m,2} & a_{m,3}& \\cdots & a_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    " \n",
    "- The `Upper triangular matrix` of matrix $A$ has values only above the main diagonal, while the remaining elements are filled with zeros. <br>\n",
    "\n",
    "$\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3}& \\cdots & a_{1,n} \\\\\n",
    "0 & a_{2,2} & a_{2,3}& \\cdots & a_{2,n} \\\\\n",
    "0 & 0 & a_{3,3}&\\cdots & a_{3,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "0 & 0 & 0& \\cdots & a_{m,n} \n",
    "\\end{pmatrix}\n",
    "$\n",
    "\n",
    "- The `Lower triangular matrix` of matrix $A$ has values only below the main diagonal, while the remaining elements are filled with zeros. <br>\n",
    "$\n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & 0 & 0& \\cdots & 0 \\\\\n",
    "a_{2,1} & a_{2,2} & 0& \\cdots & 0 \\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}&\\cdots & 0 \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "a_{m,1} & a_{m,2} & a_{m,3}& \\cdots & a_{m,n} \n",
    "\\end{pmatrix}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdee3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[6, 3, 8, 5], [2, 1, 9, 7], [8, 2, 4, 7], [3, 1, 5, 8]])\n",
    "print(\"Matrix A: \\n\", A)\n",
    "\n",
    "# Lower triangular matrix of matrix A\n",
    "lower = np.tril(A)\n",
    "print(\"Lower Triangular Matrix of A:\\n\", lower)\n",
    "\n",
    "# Upper triangular matrix of matrix A\n",
    "upper = np.triu(A)\n",
    "print(\"Upper Triangular Matrix of A: \\n\", upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c316820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9687e3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541a0bde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55fa4ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bd4f052",
   "metadata": {},
   "source": [
    "### i. Diagonal Matrix\n",
    "- A diagonal matrix is a square matrix in which all entries that are not on the main diagonal are zero.\n",
    "- A diagonal matrix is a special square matrix that is BOTH upper and lower triangular since all elements, whether above or below the principal diagonal, are 0.\n",
    "- A diagonal matrix is often denoted with the variable `D`\n",
    "\n",
    "$$\n",
    "A_{n,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & 0 & 0& \\cdots & 0 \\\\\n",
    "0 & a_{2,2} & 0&\\cdots & 0 \\\\\n",
    "0 & 0 & a_{3,3}&\\cdots & 0 \\\\\n",
    "\\vdots  & \\vdots  & \\vdots & \\ddots & \\vdots  \\\\\n",
    "0 & 0 & 0 & \\cdots & a_{n,n} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "- There are two ways to represent a diagonal matrix:\n",
    "    - As a full matrix.\n",
    "    - As a vector of values on the main diagonal. \n",
    "    \n",
    "- NumPy provides the function `np.diag()` that can create a diagonal matrix from an existing matrix, or transform a vector into a diagonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b53e086",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 10, size =(4, 4))\n",
    "print(\"Matrix A : \\n\", A)\n",
    "\n",
    "# Extract a diagonal vector from a matrix\n",
    "d = np.diag(A)\n",
    "print(\"\\nDiagonal Vector = \", d)\n",
    "\n",
    "# create diagonal matrix from diognal vector\n",
    "D = np.diag(d)\n",
    "print(\"\\nDiagonal Matrix : \\n\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38acc8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30c113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6858db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258a9af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a9906d0",
   "metadata": {},
   "source": [
    "### j. Identity Matrix\n",
    "- An identity matrix $I_n$, is a square matrix in which all the entries in the principal diagonal are 1 and all other elements are 0. \n",
    "\n",
    "$$I_2 =\\begin{bmatrix} \n",
    "       1 & 0\\\\ \n",
    "       0 & 1\n",
    " \\end{bmatrix} $$\n",
    "\n",
    "\n",
    "$$I_3 =\\begin{bmatrix} \n",
    "       1 & 0 & 0\\\\ \n",
    "       0 & 1 & 0\\\\\n",
    "       0 & 0 & 1\n",
    " \\end{bmatrix} $$  \n",
    " \n",
    "- **Properties of Identity Matrix:**\n",
    "    - A vector of length `n` remains unchanged when multiplied with $I_n$.\n",
    "    - Multiplying a matrix or vector by its compatible identity matrix, will result the matrix itself. $AI = A$\n",
    "    - Multiplying a matrix by its inverse will result in an identity matrix of the same order. $AA^{-1} = I$\n",
    "    - The `trace` (sum of elements in principal diagonal) of an identity matrix is equal to identity matrix’s order.\n",
    "    - The determinant of an identity matrix is always equal to 1.\n",
    "\n",
    "\n",
    "- The `numpy.eye(rows, cols, k, dtype)` function is used to create an identigy matrix.\n",
    "    - Where, default value of `k` is zero, means main diagonal,  a positive value refers to an upper diagonal, and a negative value refers to a lower diagonal.\n",
    "    - Default `dtype` is float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96936e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "I3 = np.eye(4, 4)\n",
    "print(\"3x3 Identiy Matrix:\\n\", I3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3e56f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "I3 = np.eye(4, 4, 1,dtype=np.uint8)\n",
    "print(\"3x3 Identiy Matrix:\\n\", I3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de7b14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "I3 = np.eye(4, 4, -1,dtype=np.uint8)\n",
    "print(\"3x3 Identiy Matrix:\\n\", I3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd351eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b16c87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3288cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2db238",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d973bea6",
   "metadata": {},
   "source": [
    "### k. Scalar Matrix\n",
    "- A scalar matrix is a type of square matrix in which its principal diagonal elements are all equal  and off-diagonal elements are all 0. \n",
    "- It is a multiplicative constant of an identity matrix.\n",
    "- Some examples of 2x2 scalar matrices are given below:<br><br>\n",
    "$\\begin{bmatrix} \n",
    "       2 & 0\\\\ \n",
    "       0 & 2\n",
    " \\end{bmatrix}\n",
    "\\hspace{2 cm}\\begin{bmatrix} \n",
    "       -3 & 0\\\\ \n",
    "       0 & -3\n",
    " \\end{bmatrix} \n",
    " \\hspace{2 cm}\\begin{bmatrix} \n",
    "       4 & 0\\\\ \n",
    "       0 & 4\n",
    " \\end{bmatrix} $  \n",
    "  \n",
    "\n",
    "\n",
    "- Some examples of 3x3 scalar matrices are given below:<br><br>\n",
    "$\\begin{bmatrix} \n",
    "       4 & 0 & 0\\\\ \n",
    "       0 & 4 & 0\\\\\n",
    "       0 & 0 & 4\n",
    " \\end{bmatrix} \n",
    "\\hspace{2 cm}\\begin{bmatrix} \n",
    "       -3 & 0 & 0\\\\ \n",
    "       0 & -3 & 0\\\\\n",
    "       0 & 0 & -3\n",
    " \\end{bmatrix} \n",
    " \\hspace{2 cm}\\begin{bmatrix} \n",
    "       2 & 0 & 0\\\\ \n",
    "       0 & 2 & 0\\\\\n",
    "       0 & 0 & 2\n",
    " \\end{bmatrix} $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12dfb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.eye(3, 3, dtype=np.uint8)\n",
    "print(\"Scalar Matrix A:\\n\", 2*A)\n",
    "B = np.eye(4, 4, dtype=np.uint8)\n",
    "print(\"Scalar Matrix B:\\n\", -3*B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1e76c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75335a73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf39b703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5064d0eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fd598ab8",
   "metadata": {},
   "source": [
    "### l. Orthogonal Matrix\n",
    "- An **orthogonal/orthonormal matrix** is a type of square matrix whose column vectors and row vectors are orthonormal vectors, i.e., are mutually perpendicular and have magnitude equal to 1. \n",
    "- An Orthogonal matrix is often denoted as uppercase $Q_{n,n}$. \n",
    "\n",
    "$\\hspace{3 cm} Q_{2,2} = \\begin{bmatrix} \n",
    "       1 & 0\\\\ \n",
    "       0 & -1\n",
    " \\end{bmatrix}$\n",
    "$\\hspace{3 cm}Q_{3,3} = \\begin{bmatrix} \n",
    "       1 & 0 & 0\\\\ \n",
    "       0 & -1 & 0 \\\\\n",
    "       0 & 0 & 1\n",
    "\\end{bmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "- **Properties:**\n",
    "    - An orthogonal matrix is always a symmetric matrix, all identity matrices are hence orthogonal matrices.\n",
    "    - The product of two orthogonal matrices will also be an orthogonal matrix.$\\hspace{.5 cm} Q_1.Q_2 = Q_3$    \n",
    "    - The transpose of the orthogonal matrix will also be an orthogonal matrix.$\\hspace{.5 cm} Q_1^T = Q_2$    \n",
    "    - When an Orthogonal matrix is multiplied with its transpose, it will return an identity matrix.$\\hspace{.5 cm} Q.Q^T = Q^T.Q = I$\n",
    "    - A matrix is orthogonal if its transpose is equal to its inverse.\n",
    "    - The determinant of the orthogonal matrix will always be +1 or -1.\n",
    "    - The eigenvalues of the orthogonal matrix will always be ±1\n",
    "- Orthogonal matrices are mostly used a lot for `linear transformations`, such as `reflections` and `permutations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8cff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = np.array([ [1, 0, 0],[0, -1, 0], [0,0,1]])\n",
    "Q2 = np.array([ [-1, 0, 0],[0, 1, 0], [0,0,1]])\n",
    "print(\"Q1: \\n\", Q1)\n",
    "print(\"Q2: \\n\", Q1)\n",
    "\n",
    "# Product of two orthogonal matrices will also be an orthogonal matrix\n",
    "print(\"\\nQ1.Q2 = \\n\", np.dot(Q1,Q2))\n",
    "\n",
    "# Transpose of the orthogonal matrix will also be an orthogonal matrix\n",
    "print(\"\\nQ1.T = \\n\", Q1.T)\n",
    "\n",
    "# When an Orthogonal matrix is multiplied with its transpose, it will return an identity matrix\n",
    "print(\"\\nnp.dot(Q1, Q1.T) = \\n\", np.dot(Q1,(Q1.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df77784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cae3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407a0195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe753a15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57f3caa5",
   "metadata": {},
   "source": [
    "## 2. Matrix Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513e372c",
   "metadata": {},
   "source": [
    "### a. Matrix Addition\n",
    "- Two matrices with the same order can be added together to create a third matrix of same order.\n",
    "- It is element by element addition and can be performed in Python using the plus operator on two NumPy arrays as shown:\n",
    "$$\n",
    "C_{m,n} = A_{m,n} + B_{m,n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = A_{m,n} + B_{m,n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{m,1} & a_{m,2} & \\cdots & a_{m,n} \n",
    "\\end{pmatrix} +\n",
    "\\begin{pmatrix}\n",
    "b_{1,1} & b_{1,2} & \\cdots & b_{1,n} \\\\\n",
    "b_{2,1} & b_{2,2} & \\cdots & b_{2,n} \\\\\n",
    "\\vdots  & \\vdots   & \\ddots  & \\vdots\\\\\n",
    "b_{m,1} & b_{m,2} & \\cdots & b_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1}+b_{1,1} & a_{1,2}+b_{1,2} & \\cdots & a_{1,n}+b_{1,n} \\\\\n",
    "a_{2,1}+b_{2,1} & a_{2,2}+b_{2,2} & \\cdots & a_{2,n}+b_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{m,1}+b_{m,1} & a_{m,2}+b_{m,2} & \\cdots & a_{m,n}+b_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c6da9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(-5, 6, size =(3, 3))\n",
    "B = np.random.randint(-5, 6, size =(3, 3))\n",
    "print(\"Matrix A : \\n\", A)\n",
    "print(\"Matrix B : \\n\", B)\n",
    "\n",
    "# adding two matrices\n",
    "C = A + B\n",
    "print(\"\\nA + B = \\n\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e79567a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318bf0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00004210",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bfe25e96",
   "metadata": {},
   "source": [
    "### b. Matrix-Scalar Multiplication\n",
    "- A matrix can be multiplied by a scalar. This can be represented using the dot notation between the matrix and the scalar.\n",
    "- The result is a matrix with the same size as the parent matrix where each element of the matrix is multiplied by the scalar value.\n",
    "\n",
    "\n",
    "$$\n",
    "C_{m,n} = b.A_{m,n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = \n",
    "b.\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{m,1} & a_{m,2} & \\cdots & a_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "b.a_{1,1} & b.a_{1,2} & \\cdots & b.a_{1,n} \\\\\n",
    "b.a_{2,1} & b.a_{2,2} & \\cdots & b.a_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "b.a_{m,1}& b.a_{m,2} & \\cdots & b.a_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 6, size =(3, 3))\n",
    "print(\"Matrix A : \\n\", A)\n",
    "\n",
    "b = 2\n",
    "C = b*A\n",
    "print(\"\\n b*A: \\n\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebd2c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f4f75e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bd930d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d76af124",
   "metadata": {},
   "source": [
    "### c. Matrix Multiplication (Matrix Hadamard Product)\n",
    "- Two matrices with the same size can be multiplied together, and this is often called `element-wise matrix multiplication` or the `Hadamard product`. \n",
    "- It is not the typical operation meant when referring to matrix multiplication, therefore a different operator is often used, which is a circle $\\odot$.\n",
    "- As with element-wise subtraction and addition, element-wise multiplication involves the multiplication of elements from each parent matrix to calculate the values in the new matrix.\n",
    "- We can implement this in Python using the `asterik *` operator directly on the two NumPy arrays.\n",
    "\n",
    "\n",
    "$$\n",
    "C_{m,n} = A_{m,n}\\odot B_{m,n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{m,1} & a_{m,2} & \\cdots & a_{m,n} \n",
    "\\end{pmatrix} \\odot\n",
    "\\begin{pmatrix}\n",
    "b_{1,1} & b_{1,2} & \\cdots & b_{1,n} \\\\\n",
    "b_{2,1} & b_{2,2} & \\cdots & b_{2,n} \\\\\n",
    "\\vdots  & \\vdots   & \\ddots  & \\vdots\\\\\n",
    "b_{m,1} & b_{m,2} & \\cdots & b_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{m,n} = \n",
    "\\begin{pmatrix}\n",
    "a_{1,1}.b_{1,1} & a_{1,2}.b_{1,2} & \\cdots & a_{1,n}.b_{1,n} \\\\\n",
    "a_{2,1}.b_{2,1} & a_{2,2}.b_{2,2} & \\cdots & a_{2,n}.b_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{m,1}.b_{m,1} & a_{m,2}.b_{m,2} & \\cdots & a_{m,n}.b_{m,n} \n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944b6b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.random.randint(1, 6, size =(2, 3))\n",
    "B = np.random.randint(1, 6, size =(2, 3))\n",
    "print(\"Matrix A : \\n\", A)\n",
    "print(\"Matrix B : \\n\", B)\n",
    "\n",
    "# Matrices Hadamard product\n",
    "C = A * B\n",
    "# printing product of two matrices\n",
    "print(\"\\n A * B = \\n\", C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440e119e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90762d2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8cec02e",
   "metadata": {},
   "source": [
    "### d. Matrix Multiplication (Matrix Dot Product)\n",
    "- Matrix multiplication, also called the `matrix dot product` is more complicated than the previous operations and involves a rule as not all matrices can be multiplied together. \n",
    "- The rule for matrix multiplication is \"the number of `columns` in the first matrix must equal the number of `rows` in the second matrix\". The result is a new matrix with m rows and k columns.\n",
    "- The intuition for the matrix multiplication is that we are calculating the dot product between each row in matrix A with each column in matrix B. \n",
    "\n",
    "$$\n",
    "C_{m,k} = A_{m,n} @ B_{n,k}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{3,2} = A_{3,2} @ B_{2,2}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "C_{3,2} = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2} \\\\\n",
    "a_{3,1} & a_{3,2} \n",
    "\\end{bmatrix} @\n",
    "\\begin{bmatrix}\n",
    "b_{1,1} & b_{1,2} \\\\\n",
    "b_{2,1} & b_{2,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{3,2} = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1}.b_{1,1}+a_{1,2}.b_{2,1} &\\hspace{.7 cm} a_{1,1}.b_{1,2}+a_{1,2}.b_{2,2} \\\\\n",
    "a_{2,1}.b_{1,1}+a_{2,2}.b_{2,1} &\\hspace{.7 cm} a_{2,1}.b_{1,2}+a_{2,2}.b_{2,2} \\\\\n",
    "a_{3,1}.b_{1,1}+a_{3,2}.b_{2,1} &\\hspace{.7 cm} a_{3,1}.b_{1,2}+a_{3,2}.b_{2,2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- In Python, matrix multiplication operation can be performed the `numpy.dot()` function or using the `newer @ operator`, since Python version 3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [1, 2],[3, 4], [5, 6]])\n",
    "B = np.array([ [1, 2],[3, 4]])\n",
    "print(\"Matrix A = \\n\", A)\n",
    "print(\"\\nMatrix B = \\n\", B)\n",
    "\n",
    "\n",
    "# multiply matrices using dot function\n",
    "C = np.dot(A,B)\n",
    "# print dot product matrix\n",
    "print(\"\\n A.dot(B) = \\n\", C)\n",
    "\n",
    "# multiply matrices with @ operator\n",
    "D = A @ B\n",
    "\n",
    "# print dot product matrix\n",
    "print(\"\\nA @ B = \\n\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7763d48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54a0ed5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab39dcca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "859cb7c6",
   "metadata": {},
   "source": [
    "### e. Matrix-Vector Multiplication\n",
    "- A matrix and a vector can be multiplied together as long as the rule of matrix multiplication is observed. Specifically, that the number of columns in the matrix must equal the number of items in the vector. \n",
    "- As with matrix multiplication, the operation can be written using the dot notation. \n",
    "- Because the vector only has one column, the result is always a **vector**.\n",
    "\n",
    "$$\n",
    "C_{n} = A_{m,n} @ V_{n}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{2} = A_{3,2} @ V_{2}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "C_{2} = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} \\\\\n",
    "a_{2,1} & a_{2,2} \\\\\n",
    "a_{3,1} & a_{3,2} \n",
    "\\end{bmatrix} @\n",
    "\\begin{bmatrix}\n",
    "v_{1}  \\\\\n",
    "v_{2}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "C_{n} = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1}.v_1+a_{1,2}.v_2  \\\\\n",
    "a_{2,1}.v_1+a_{2,2}.v_2  \\\\\n",
    "a_{3,1}.v_1+a_{3,2}.v_2 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- In Python a matrix can be multiplied with a vector using the `numpy.dot()` function or using the `newer @ operator`, since Python version 3.5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [1, 2],[3, 4], [5, 6]])\n",
    "v = np.array([2, 3])\n",
    "print(\"Matrix A = \\n\", A)\n",
    "print(\"\\nMatrix v = \\n\", v)\n",
    "\n",
    "\n",
    "C = A.dot(v)\n",
    "print(\"\\n A.dot(v) = \\n\", C)\n",
    "\n",
    "D = A @ v\n",
    "\n",
    "# print dot product matrix\n",
    "print(\"\\nA @ v = \\n\", D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fe812a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9059399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1cc8059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a33951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3f7f41d",
   "metadata": {},
   "source": [
    "### f. Frobenius Norm\n",
    "- We have already talked about Norms with respect to vectors and we saw how they are used to calculate their magnitude from origin.\n",
    "- Similar to L<sup>2</sup> norm of a vector, the Frobenius norm of a matrix is calculated as the square root of the sum of the absolute squares of its elements.\n",
    "- In simple words, Frobenius norm of a matrix is the sum of the magnitude of all vectors in a matrix.\n",
    "\n",
    "<h3 align=\"center\">      $\\left\\lVert  x \\right\\rVert_F$   $=$   $\\sqrt{\\sum_{i,j} x_{i,j}^2}$        </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b52929",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [0, 2, 1],[2, 0, 0]])\n",
    "print(\"Matrix A = \\n\", A)\n",
    "\n",
    "f = np.linalg.norm(A, ord=None)\n",
    "print(\"\\n Frobenius Norm =\", f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec0b503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd49512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860bb38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d69175",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68146673",
   "metadata": {},
   "source": [
    "### g. Transpose of a Matrix\n",
    "- A defined matrix can be transposed, which creates a new matrix with the number of `columns and rows flipped`. This is denoted by the superscript T next to the matrix A<sup>T</sup>.\n",
    "\n",
    "\n",
    "$$\n",
    "A_{m,n} = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & \\cdots & a_{2,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{m,1} & a_{m,2} & \\cdots & a_{m,n} \n",
    "\\end{bmatrix}  \\hspace{3 cm}  {A^T}_{n,m} = \n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{2,1} & \\cdots & a_{m,1} \\\\\n",
    "a_{1,2} & a_{2,2} & \\cdots & a_{m,2} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "a_{1,n} & a_{2,n} & \\cdots & a_{m,n} \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "A_{3,2} = \n",
    "\\begin{bmatrix}\n",
    "1 & 2  \\\\\n",
    "3 & 4 \\\\\n",
    "5 & 6 \n",
    "\\end{bmatrix} \\hspace{3 cm} {A^T}_{2,3} = \n",
    "\\begin{bmatrix}\n",
    "1 & 3 & 5 \\\\\n",
    "2 & 4 & 6\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- The operation has no effect if the matrix is symmetrical, e.g. has the same number of columns and rows and the same values at the same locations on both sides of the invisible diagonal line (The columns of AT are the rows of A).\n",
    "\n",
    "$$\n",
    "A_{3,3} =\\begin{bmatrix} \n",
    "       4 & 1 & 7\\\\ \n",
    "       1 & -3 & 5\\\\\n",
    "       7 & 5 & 2\n",
    " \\end{bmatrix}\\hspace{3 cm} {A^T}_{3,3} = \n",
    "\\begin{bmatrix}\n",
    "4 & 1 & 7 \\\\\n",
    "1 & -3 & 5 \\\\\n",
    "7 & 5 & 2 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    " \n",
    " \n",
    "\n",
    "- We can transpose a matrix in NumPy by calling the T attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b00f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [1, 2],\n",
    "           [3, 4],\n",
    "           [5, 6]])\n",
    "print(\"Original Matrix A: \\n\", A)\n",
    "\n",
    "# computing transpose of Matrix A using T attribute\n",
    "C = A.T\n",
    "C = np.transpose(A)\n",
    "print(\"\\nTranspose Matrix: \\n\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05627a0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df4fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac97a32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9877283",
   "metadata": {},
   "source": [
    "### h. Determinant of a Matrix\n",
    "\n",
    "- Matrix determinant can be thought of as a function whose input is a square matrix and output is a scalar value.\n",
    "- The determinant of a matrrix is used to compute the inverse of a matrix.\n",
    "- If the determinant of a matrix is zero, that means it is a singular matrix, is non-invertable and having linearly dependent columns.\n",
    "- Moreover, determinant is used in solving linear equations and it also caputures the notions of how linear transformation change area or volume.\n",
    "- The determinant also describes the way a matrix will scale another matrix when they are multiplied together. For example, if the determinant of a matrix is one, it preserves the space of other matrix.\n",
    "- To calculate the determinant of a 2x2 matrix, we multiply the component `a` by the determinant of the “submatrix” formed by ignoring `a's` row and column. In this case, this submatrix is the 1×1 matrix consisting of `d`, and its determinant is just `d`. So the first term of the determinant is `ad`. Next, we proceed to the second component of the first row, which is the upper right component `b`. We multiply `b` by the determinant of the submatrix formed by ignoring `b's` row and column, which is `c`. So, the next term of the determinant is `bc`. The total determinant is simply the first term ad minus the second term. :<br>\n",
    "$\\hspace{2 cm}A = \\begin{bmatrix} \n",
    "       a & b\\\\ \n",
    "       c & d\n",
    " \\end{bmatrix} $  \n",
    "\n",
    "$\\hspace{2 cm}det(A) = |A| = ad - cb$\n",
    "\n",
    "- Now that we know how to calculate determinant of a 2x2 matrix, we can generalize this technique to compute determinant of larger matrices using recursion.\n",
    "- Let us calculate the determinant of a 3x3 matrix:<br>\n",
    "$\\hspace{2 cm}B =$ \n",
    "$\\begin{bmatrix} \n",
    "       a & b & c\\\\ \n",
    "       d & e & f\\\\\n",
    "       g & h & i\n",
    " \\end{bmatrix} $  \n",
    " \n",
    "$\\hspace{2 cm}det(B) = |B| = a\\begin{vmatrix} e & f\\\\h & i \\end{vmatrix} b\\begin{vmatrix} d & f\\\\g & i \\end{vmatrix} c\\begin{vmatrix} d & e\\\\g & h \\end{vmatrix} = a(ef-hf) - b(di-gf) + c(dh-ge)$\n",
    "\n",
    "- In NumPy, the determinant of a matrix can be calculated using the `det()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dabbb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-3, 1],[6, -4]])\n",
    "print(\"Matrix A: \\n\", A)\n",
    "det1 = numpy.linalg.det(A)\n",
    "print(\"det(A): \", det1)\n",
    "\n",
    "\n",
    "B = np.array([[1, 2, 4],[2, -1, 3],[0, 5, 1]])\n",
    "print(\"\\nMatrix B: \\n\", B)\n",
    "det2 = numpy.linalg.det(B)\n",
    "print(\"det(B): \", det2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0912b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[6, -3],[4, -2]])\n",
    "print(\"Matrix A: \\n\", A)\n",
    "det1 = numpy.linalg.det(A)\n",
    "print(\"det(A): \", det1)\n",
    "\n",
    "B = np.array([[1, 1, 1],[2, 3, 1],[0, -1, 1]])\n",
    "print(\"\\nMatrix B: \\n\", B)\n",
    "det2 = numpy.linalg.det(B)\n",
    "print(\"det(B): \", det2)\n",
    "\n",
    "C = np.array([[2, 1, 2],[1, 0, 1],[4, 1, 4]])\n",
    "print(\"\\nMatrix C: \\n\", C)\n",
    "det3 = numpy.linalg.det(C)\n",
    "print(\"det(C): \", det3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f55565",
   "metadata": {},
   "source": [
    "> Note the determinant of matrix A is zero, that means matrix A is not invertable. This can be observed that the two columns of matrix A are not independent, or we can say that the two columns of matrix A are dependent. So the first column is a multiple of the second column, i.e., you can multiply the second column by -2 to get the first column. So that means the matrix A represent two parallel lines and it is impossible to solve this matrix for unknowns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f2a67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2c0548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81864c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0bc386",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c88bdf68",
   "metadata": {},
   "source": [
    "### i. Inverse of a Matrix\n",
    "- The way numbers has reciprocals, and when we multiply a number by its reciprocal we get a 1.\n",
    "- Similarly a matrix can have an inverse, and when we multiply a matrix by its inverse, we get the identity matrix.\n",
    "- The inverse of matrix is used of find the solution of linear equations through the matrix inversion method. \n",
    "\n",
    "$\\hspace{2 cm}AA^{-1} = A^{-1}A = I_n$\n",
    "- For a matrix to have an inverse, it has to satisfy two conditions:\n",
    "    - The matrix needs to be a square matrix.\n",
    "    - The determinant of the matrix must not be zero.\n",
    "- Almost all of us know the shortcut way to calculate the Inverse of a 2x2 matrix. \n",
    "    - Interchange the main diagonal elements (`a` and `d`).\n",
    "    - Negate the remaining two elements (`b` and `c`).\n",
    "    - Devide the resulting matrix with the determinant of the original matrix.\n",
    ":<br>\n",
    "$\\hspace{2 cm}A = \\begin{bmatrix} \n",
    "       a & b\\\\ \n",
    "       c & d\n",
    " \\end{bmatrix} $  \n",
    "\n",
    "\n",
    "$\\hspace{2 cm}A = \\frac{1}{det(A)}\\begin{bmatrix} \n",
    "       d & -b\\\\ \n",
    "       -c & a\n",
    " \\end{bmatrix} $  \n",
    "\n",
    "\n",
    "- Formal steps to compute the inverse of a matrix are:\n",
    "    - Step 1: Find the `matrix of minors` for the given matrix.\n",
    "    - Step 2: Turn that matrix into the `matrix of cofactors`.\n",
    "    - Step 3: Find the adjugate or `adjoint of matrix`.\n",
    "    - Step 4: Divide adjugate matrix by `determinant` of given matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c44db3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a704b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1468ea",
   "metadata": {},
   "source": [
    "**Example:** Perform step by step calculations to calculate the Inverse of\n",
    "$\\hspace{1 cm}A_{3,3} = \\begin{bmatrix} 3 & 0 & 2\\\\ 2 & 0 & -2\\\\0 & 1 & 1\\end{bmatrix} $  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f8b855",
   "metadata": {},
   "source": [
    "**Step 1:** Find the `matrix of minors` for the given matrix.\n",
    "- For each element of the matrix:\n",
    "    - Ignore the values on the current row and column\n",
    "    - Calculate the determinant of the remaining values\n",
    "- Put those determinants into a matrix and you get the `matrix of minors`, as shown below:\n",
    "$$\\begin{bmatrix} 2 & 2 & 2\\\\ -2 & 3 & 3\\\\0 & -10 & 0\\end{bmatrix} $$ \n",
    "\n",
    "\n",
    "\n",
    "**Step 2:** Turn that matrix into the `matrix of cofactors`.\n",
    "- Multiply each element of matrix of minors with alternate +1 and -1.\n",
    "- Start from first row (left to right), then second row and so on.\n",
    "$$\\begin{bmatrix} 2 & -2 & 2\\\\ 2 & 3 & -3\\\\0 & 10 & 0\\end{bmatrix} $$ \n",
    "\n",
    "\n",
    "**Step 3:** Find the adjugate or `adjoint of matrix`.\n",
    "- Take transpose of matrix of cofactors and you get the adjugate or adjoint matrix as shown below:\n",
    "$$\\begin{bmatrix} 2 & 2 & 0\\\\ -2 & 3 & 10\\\\2 & -3 & 0\\end{bmatrix} $$ \n",
    "\n",
    "\n",
    "**Step 4:** Divide adjugate matrix by `determinant` of given matrix.\n",
    "- Find the determinant of given matrix, which is 10.\n",
    "- Divide each element of adjugate matrix by 10 to get the inverse of matrix as shown below:\n",
    "$$\\begin{bmatrix} 1/5 & 1/5 & 0\\\\ -1/5 & 3/10 & 1\\\\1/5 & -3/10 & 0\\end{bmatrix} $$ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535a9897",
   "metadata": {},
   "source": [
    ">- To rescue us from all this labour, Python gives us `numpy.linalg.inv()` method to compute the inverse of a non-singular matrix (a square matrix having non-zero dterminant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [3,0,2],[2,0,-2],[0,1,1]])\n",
    "print(\"Matrix A: \\n\", A)\n",
    "print(\"det(A): \", numpy.linalg.det(A))\n",
    "\n",
    "AI = numpy.linalg.inv(A)\n",
    "print(\"\\nInverse of Matrix A: \\n\", AI)\n",
    "\n",
    "# Verify\n",
    "I = np.dot(A,AI)\n",
    "print(\"\\nnp.dot(A,AI): \\n\", I.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b30d25e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70266f48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85872e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "32ea9ab3",
   "metadata": {},
   "source": [
    "### j. Trace of a Matrix\n",
    "- The trace of a matrix is the **sum** of all of the **diagonal entries** of a matrix.\n",
    "$$\\sum_i A_{i,i}$$\n",
    "\n",
    "- We can calculate the trace of a matrix in NumPy using the `trace()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b2feca",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "print(\"Original Matrix = \\n\", A)\n",
    "print(\"\\nTrace value = \", np.trace(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c95306",
   "metadata": {},
   "source": [
    "- Properties of Trace of a Matrix:\n",
    "    - Tr($A$) = Tr($A^T$): The trace of a matrix is equal to the trace of its transpose, because the main diagonal remains the same after transpose.\n",
    "    - Tr($ABC$) = Tr($CAB$) = Tr($BCA$): If we multiply three matrices in different combinations, their trace remains the same\n",
    "- You can use trace to calculate a matrix's Frobenius norm: $$||A||_F = \\sqrt{\\sum_{i,j} x_{i,j}^2} = \\sqrt{\\mathrm{Tr}(AA^\\mathrm{T})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e640c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [0, 2, 1],[2, 0, 0]])\n",
    "print(\"Matrix A = \\n\", A)\n",
    "\n",
    "f1 = np.linalg.norm(A, ord=None)\n",
    "print(\"\\n Frobenius Norm =\", f1)\n",
    "\n",
    "AT = A.T\n",
    "AAT = np.dot(A, AT)\n",
    "tr_AAT = np.trace(AAT)\n",
    "f2 = (tr_AAT)**.5\n",
    "print(\"\\nnp.trace(np.dot(A,A.T))**.5 = \", f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ddab15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638568d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1d344e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ddb62cf0",
   "metadata": {},
   "source": [
    "### k. Rank of a Matrix\n",
    "- The maximum number of `linearly independent` columns (or rows ) of a matrix is called its rank. (Two columns are linearly dependent if you can add+scale one column to make the other)\n",
    "- The rank of a $m \\times n$ matrix is less than equal to the minimum of its rows and columns.\n",
    "- The rank of a matrix would be zero only if the matrix had no elements. If a matrix had even one element, its minimum rank would be one.\n",
    "- To calculate the rank of a matrix, we need to convert the matrix into its row-echlon form (which we will study iun the next section). \n",
    "- In Python, we can calculate the rank of a matrkx using `np.linalg.matrix_rank()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81869dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = np.array([])\n",
    "print(\"Rank of matrix having zero elements = \", np.linalg.matrix_rank(mat))\n",
    "\n",
    "A = np.array([[1,2,3]])\n",
    "print(\"\\nA:\\n\", A)\n",
    "print(\"Rank of A = \", np.linalg.matrix_rank(A))\n",
    "\n",
    "B = np.array([[1,2,3], [3, 2, 0]])\n",
    "print(\"\\nB:\\n\",B)\n",
    "print(\"Rank of B = \", np.linalg.matrix_rank(B))\n",
    "\n",
    "C = np.array([[1,2,3], [5,6,9], [3, 2, 0]])\n",
    "print(\"\\nC:\\n\",C)\n",
    "print(\"Rank of C = \", np.linalg.matrix_rank(C))\n",
    "\n",
    "C = np.array([[1,2, 3, 4], [9, 6, 2, 4]])\n",
    "print(\"\\nC:\\n\", C)\n",
    "print(\"Rank of C = \", np.linalg.matrix_rank(C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10972cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all columns are linearly dependent on each other\n",
    "# 2nd = 3 times 1st col and 3rd col = 2 times 1st column\n",
    "A = np.array([[1,3, 2], [2, 6, 4],[3, 9, 6]]) # all columns are dependent \n",
    "print(\"A:\\n\", A)\n",
    "print(\"Rank of A = \", np.linalg.matrix_rank(A))\n",
    "\n",
    "\n",
    "# 1st and 2nd col are independent, but 3rd column = 1st col + 2nd col\n",
    "B = np.array([[1,0, 1], [2, 2, 4],[3, 2, 5]]) \n",
    "print(\"B:\\n\", B)\n",
    "print(\"Rank of B = \", np.linalg.matrix_rank(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6aa356",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44c5251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0c7950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c503be81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1018041",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "761fac21",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section III: (Solving System of Linear Equations) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "840450fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg\n",
    "import math\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03a3cf3",
   "metadata": {},
   "source": [
    "## 1. Linear Equations and Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81044337",
   "metadata": {},
   "source": [
    "### a. What is a Linear Equation\n",
    "- An equation in which the variable's highest power is one is called a linear equation. A linear equation can have one, two, three and so on to `n` variables. A linear equation having two variables can be written as:\n",
    "$$ax + by +c = 0$$\n",
    "- A linear equation of two variables when plotted on a graph gives a straight line. A straight line equation is shown below: \n",
    "<h3> $$ y = c + mx$$ </h3>\n",
    "- Where, \n",
    "    - $y$ is the dependent variable.\n",
    "    - $x$ is the independent variable.\n",
    "    - $c$ is the y-intercept or the value of $y$ when $x$ is zero.\n",
    "    - $m$ is the slope/gradient of the line, which tells us two things\n",
    "        - The line is rising or falling (Positive or negative relationship between the two variables)\n",
    "        - Steepness of line (how closely related the two variables are)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2edb146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182572ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589b541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73ab5816",
   "metadata": {},
   "source": [
    "**Example 1:** Let us first see how we can draw a line from a linear equation of two variables using Matplotlib. \n",
    "$$ 2x - y = -4 $$\n",
    "$$ y = 4 + 2x $$\n",
    "\n",
    "We need to calculate at least two (x,y) pair of points that statisfies this equation, and then we can draw a line connecting those points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91b6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.array([0, 5])\n",
    "y = 4 + 2 * x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title(\"Line representing equation: y = 4 + 2x\")\n",
    "ax.set_xlim([0, 5])\n",
    "ax.set_ylim([1, 14])\n",
    "ax.plot(x, y)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d9e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ada2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aabc579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62893c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "52278afb",
   "metadata": {},
   "source": [
    ">**Let us change the y-intercept, without changing the slope, and draw these three lines:**\n",
    "$$y=4+2x$$\n",
    "$$y=9+2x$$\n",
    "$$y=-2+2x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d8de4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 20, 5) # start, finish, n points\n",
    "y1 = -2 + 2*x\n",
    "y2 = 4 + 2*x\n",
    "y3 = 9 + 2*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_xlim([0, 6])\n",
    "ax.set_ylim([-2, 16])\n",
    "plt.title(\"Line representing three equations\")\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "ax.plot(x, y3, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84d7adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c3b13f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e26c24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ef32076",
   "metadata": {},
   "source": [
    ">**Let us change the slope, without changing the y-intercept, and draw these three lines:**\n",
    "$$y=4+2x$$\n",
    "$$y=4+0x$$\n",
    "$$y=4-2x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 20, 5) # start, finish, n points\n",
    "y1 = 4 + 2*x\n",
    "y2 = 4 + 0*x\n",
    "y3 = 4 - 2*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_xlim([0, 6])\n",
    "ax.set_ylim([-4, 12])\n",
    "plt.title(\"Line representing three equations\")\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='purple')\n",
    "ax.plot(x, y3, c='red')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3f7889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495dcbe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef34dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab53375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44141d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a45c50",
   "metadata": {},
   "source": [
    "**Example 2:**\n",
    "- You went to a Rent-a-Car company to rant a car for few hours. The company representative told you that the base payment that you have to give is Rs5000/ and then for every hour you have to pay Rs2000/ additional price.\n",
    "- Can you write a linear equation keeping in view of the dependent variable `rent price` and independent variable `time`<br>\n",
    "\n",
    "$$ y = 5000 + 2000x$$\n",
    "- Where, \n",
    "    - $y$ is the dependent/outcome/response variable `rent`.\n",
    "    - Value 5000 is is the minimum/base value (y-intercept).\n",
    "    - $x$ is the independent/feature/predictor variable `time`.\n",
    "    - Value 2000 is the coefficient of $x$, which is the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8c8be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(0, 10, 5) # start, finish, n points\n",
    "y = 5 + 2*x # values are in thousands\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Time in Hours')\n",
    "plt.ylabel('Rent in thousands')\n",
    "ax.plot(x, y, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee942d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac68730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85178983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f5b35bf",
   "metadata": {},
   "source": [
    "**Example 3:**\n",
    "- Given the following linear equation which describes the relationship between the years of education, a person has achieved and the salary in thousands per month. Plot the linear equation to understand the relationship.<br>\n",
    "\n",
    "$$ y = 20 + 5x$$\n",
    "- Where, \n",
    "    - $y$ is the dependent/outcome/response variable `salary in thousands`.\n",
    "    - Value 20 means Rs20K, which is the minimum/base salary, that one gets even if he/she is uneducated (y-intercept).\n",
    "    - $x$ is the independent/feature/predictor variable `education in years`.\n",
    "    - Value 5 means Rs5K, is the coefficient of $x$, which is the slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8c0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(0, 20, 5) # start, finish, n points\n",
    "y = 20 + 5*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Education in Years')\n",
    "plt.ylabel('Salary in thousands')\n",
    "ax.plot(x, y, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36330739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd0911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61745ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3b4a26e6",
   "metadata": {},
   "source": [
    "**Example 4:**\n",
    "- Given the following linear equation which describes the relationship between the drug dosage and forgetness level.<br>\n",
    "\n",
    "$$ y = 10 - 1.5x$$\n",
    "- Where, \n",
    "    - $y$ is the dependent/outcome/response variable `forgetness level`.\n",
    "    - Value 10 is the forgetness level if no drug is given to the patient (y-intercept).\n",
    "    - $x$ is the independent/feature/predictor variable `drug dosage`.\n",
    "    - Value 1.5 is the coefficient of $x$, which is the slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ea33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(0, 20, 5) # start, finish, n points\n",
    "y = 10 - 1.5*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([0, 9])\n",
    "ax.set_ylim([-5, 15])\n",
    "plt.xlabel('Drug Dosage in ml')\n",
    "plt.ylabel('Forgetness Level')\n",
    "ax.plot(x, y, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f053f7a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811ffad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a7eb5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d336a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f56e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7500a760",
   "metadata": {},
   "source": [
    "### b. What is a System of Linear Equations\n",
    "- A system of linear equations consists of two or more linear equations, that you deal with all together at once.\n",
    "- An example system of linear equations having `two equations` and `two variables` is shown below:\n",
    "$$2𝑥 + 5𝑦 = 1$$\n",
    "$$3𝑥 - 𝑦  = 2$$\n",
    "- An example system of linear equations having `three equations` and `three variables` is shown below:\n",
    "$$𝑥 + 𝑦 + 𝑧 = 3$$\n",
    "$$𝑥 + 2𝑦 +3z= 0$$\n",
    "$$𝑥 + 3𝑦 + 2𝑧 = 3$$    \n",
    "\n",
    "**Solution(s) to a System of Linear Equations:**\n",
    "- The solution to a system of linear equations are the values of variable that when put in the equation satisfies them all.\n",
    "- The unique solution to a system of linear equations having two variables is a 2-D point $(x,y)$, where the two `lines` intersect.\n",
    "- The unique solution to a system of linear equations having three variables is a 3-D point $(x,y,z)$, where the three `planes` intersect.\n",
    "- The three scenarios that you may come across while trying to solve a system of linear equations are:\n",
    "    - **Unique Solution:** You get exactly one value of every variable, that satisfies all the equations.\n",
    "    - **Infinite Solution:** You get infinite many values for every variable, that satisfies all the equations.\n",
    "    - **No Solution:** You get no value for every bariable, that satisfies all the equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25423816",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36945e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d24638",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c257ce72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "210c0d11",
   "metadata": {},
   "source": [
    "## 2. How to Solve a System of Linear Equations\n",
    "- There are different ways to solve a set of linear equations:\n",
    "    - Substitution method\n",
    "    - Elimination method\n",
    "    - Graphing method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d752a626",
   "metadata": {},
   "source": [
    "### a. Using Substitution Strategy:\n",
    "- We substitute the value of a variable from one equation to the other.\n",
    "- Use this strategy, whenever there is a variable in the system with a coefficient of 1.\n",
    "- For example:<br>\n",
    "$\\hspace{1 cm}y = 3x$ and $-5x + 2y = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d04ad21",
   "metadata": {},
   "source": [
    "### b. Using Elimination Strategy:\n",
    "- Typically best option if no variable in system has coefficient of one.\n",
    "- Use addition property of equations to eliminate variables and if necessary, multiply one or both equations to make elimination of a variable possible.\n",
    "- For example:<br>\n",
    "$\\hspace{1 cm}4x - 3y = 35$ and $-3x + 8y = 10$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5e75a",
   "metadata": {},
   "source": [
    "### c. Using Graphing Strategy:\n",
    "- We can take a graph paper and draw the lines corresponding to the linear equations, which will of course make a straight line.\n",
    "- If the two lines intersect, the point of intersection gives us the solution of the two unknowns.\n",
    "- If the two lines are parallel to eachother, that means there is no solution to the set of two linear equations.\n",
    "- If the two lines overlap, then we say that there are infinite solutions to the set of two linear equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560e76c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8657e77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed33d6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104177a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a447f680",
   "metadata": {},
   "source": [
    "**Example 5:**\n",
    "Solve the following set of two linear equations with two unknowns using substitution strategy, or elimination strategy (at your own). Use Matplotlib and see if two lines representing the two equations intersect.<br>\n",
    "$$ y = 1 + 2x$$\n",
    "$$ y = 3 -\\frac{1}{2}x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6ad8013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 10, 1000) # start, finish, n points\n",
    "y1 = 1 + 2*x\n",
    "y2 = 3 - 0.5*x\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-1, 5])\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27840394",
   "metadata": {},
   "source": [
    ">- The above graph represents the two equations as straight lines and the solution of these two set of linear equations with two unknowns is the point where both the equations are intersecting with each other, and that is $(\\frac{4}{5},\\frac{13}{5})$ or  $(0.8, 2.6)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f9d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2766a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafac820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fed10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26a6231c",
   "metadata": {},
   "source": [
    "**Example 6:**\n",
    "Solve the following set of two linear equations with two unknowns using substitution strategy, or elimination strategy (at your own). Use Matplotlib and see if two lines representing the two equations intersect.<br>\n",
    "$$ y = 1 + 2x$$\n",
    "$$ y = 3 + 2x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c7f9f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEKCAYAAAASByJ7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAArcElEQVR4nO3dd3QV5Rfu8e9Lr1IDUkWqIIiIIioqqAlJgAABCS0UkaJSVH4oRbEhdkRRKSICSQi9lxQgISCKNAWpIiIgTToRAiTnvX9MvHi9Sk/2OZn9WSsLAufkPGvIycPMvLPHWGtRSimlskkHUEop5R20EJRSSgFaCEoppdJpISillAK0EJRSSqXTQlBKKQVADskXN8bsAc4AaUCqtfZeyTxKKeVmooWQrpG19qh0CKWUcjs9ZKSUUgoAI3mlsjHmV+AEYIGx1tpx//KYHkAPgDx58tQtX7585ob0Uh6Ph2zZtM9BtwVAjjNnyHvwIBfz5SOlTBkwRjqSmNMXT3Mo5RD5c+SnTN4y0nG8ws6dO49aa/2u+EBrrdgHUCb91xLAj8Ajl3t81apVrXIkJCRIR/Aart8WMTHW5sxpbYMGdsWSJdJpRM3bPs9mfyO7fWLyEzZ2Wax0HK8BrLNX8TNZ9L9V1trf0389AswB6knmUcrnfPcdhIZCjRqwYAGePHmkE4lZsWcFbWa0oW7puswJm0OubLmkI/kcsUIwxuQ3xhT86/dAAPCTVB6lfM5PP0FwMJQqBTExULiwdCIxGw5uoFl0MyoWqcji9ospkKuAdCSfJLnKqCQwxzjHOnMAU6y1MYJ5lPIdv/4KAQGQJw/Ex8Ott0onErPz2E4CIwMpkrcIceFxFMtXTDqSzxIrBGvtbqC21Osr5bMOH3bKICUFkpLg9tulE4nZf3o//hH+AMSHx1P2lrLCiXybN1yHoJS6WidPQuPGcOAALF0KNWtKJxJz7OwxAiICOHHuBIldEqlarKp0JJ+nhaCUrzh7FkJCYOtWWLAAHnhAOpGYM+fPEDwlmN0ndhPbMZZ7St0jHSlL0EJQyhdcvAhhYbBqFURHO3sJLnU+9Tyh00NZf2A9s8Nm82iFR6UjZRlaCEp5O48HnnoKFi6E0aOdYnCpNE8aHed0ZOnupUxsPpGQaiHSkbIUd1/eqZS3sxZeeAEiI2HYMOjVSzqRGGstzyx6hplbZzIiYASd7+4sHSnL0UJQypsNGwaffgrPPw+DB0unETV42WC+3PAlgxsM5oUHXpCOkyVpISjlrb74AoYOhU6d4KOPXD2f6MPVH/LuN+/Ss25Phj02TDpOlqWFoJQ3io6G3r2hWTMYPx5cPLzv641fMyB+AG3ubMPnwZ9jXFyMGc2932VKeauYGGev4OGHYdo0yJlTOpGYudvn8vSCpwmoFEBEywiyZ8suHSlL00JQypusXu0Mq6tVC+bPh7x5pROJSfg1gbCZYdQrU49ZbWaRK7sOq8toWghKeYvNm6FJEyhb1tlLKFRIOpGYdQfWETI1hCpFq7Co/SIdVpdJtBCU8ga7dzvzifLnh7g4KFFCOpGY7Ue3ExQVRPF8xYntGEvRvEWlI7mGXpimlLRDh8DfHy5cgJUroUIF6URi9p3aR0BEANlMNuI6xlHmFr3jWWbSQlBK0l/D6g4fhmXLnBvduNTRs0cJiAzg1PlTJHZOpEqxKtKRXEcLQSkpZ89C06awbRssWgT33y+dSMyZ82cIigpiz8k9xHaMpU6pOtKRXEkLQSkJFy/Ck086q4qmTXMOGblUSmoKLaa1YOPBjcwJm8Mjtz0iHcm1tBCUymweD3TpAosXw9ixTjG4VKonlfaz2rP81+VMbjGZZtWaSUdyNV1lpFRmshb69YMpU2D4cOjRQzqRGGstvRb2Ys72OYxsPJLw2uHSkVxPC0GpzPTmm/DZZ9C/PwwcKJ1G1MClA/lq41e8+sir9KvfTzqOQgtBqcwzahS8/rpzuOiDD1w9rO79b97n/dXv8+y9z/JGwzek46h0WghKZYaoKOjbF5o3hy+/dHUZjN8wnpeXvkzbmm0ZFTxKh9V5ES0EpTLa4sXOXkHDhjB1KuRw71qO2dtm03NhTwIrBzKpxSSyGf0R5E30X0OpjLRqFbRqBXfdBfPmQZ480onELNu9jHaz2nF/mfuZ+eRMHVbnhbQQlMooP/7oXHhWvjwsWQK33CKdSMza39fSYloLqharysL2C8mfK790JPUvtBCUygi//OKMpChYEOLjXT2sbtsf2wiKCsIvn58Oq/Ny7j2YqVRGOXDAufI4NRUSEpw9BJfae2ovAZEB5MiWg7jwOEoXLC0dSV2GFoJSN9OJE86ewZEjThlUry6dSMwff/6Bf4Q/Z86fYUWXFVQuWlk6kroC8UNGxpjsxpiNxpiF0lmUuiF//unc4GbnTucE8n33SScSc/r8aQKjAtl3ah8L2y+k9q21pSOpq+ANewj9gG2Ae8+4Kd934QK0bg1r1sCMGfD449KJxKSkptB8anM2Hd7EvLbzaFC+gXQkdZVE9xCMMWWBJsB4yRxK3ZC0NOjc2bnt5dixzj2RXSrVk0rbmW1J3JPIxOYTCa4SLB1JXQPpQ0YjgZcAj3AOpa6Ptc4VyFOnwnvvwdNPSycSY62l+4LuzNsxj08DP6XDXR2kI6lrJHbIyBjTFDhirV1vjGl4mcf1AHoA+Pn5kZiYmCn5vF1ycrJui3SS26LChAlUiIhgb1gYu+vVA+F/E6ltYa1lzO4xTN8/nc63dabWuVri35/6HrkO1lqRD+AdYD+wBzgEnAUiL/ecqlWrWuVISEiQjuA1xLbFyJHWgrXdulnr8chk+AepbfHOyncsr2N7L+ptPS7fFt4IWGev4uey2CEja+0ga21Za20FoC2w3FrbUSqPUtckIgKefx5atoQxY1w9rG7c+nEMWjaI9rXa80nQJzqszodJn0NQyvcsWABdu8Jjjzk3unHxsLqZW2fSa2EvgioHMbH5RB1W5+O84jvZWpsIJArHUOrKkpKgTRuoUwfmznX1sLr4X+JpP6s9D5Z7kJltZpIze07pSOoGaZ0rdbV++AGaNYPbbnOG1RUsKJ1IzJr9a2g5rSXV/aqzsP1C8uXMJx1J3QRaCEpdjZ9/dkZSFCrkDKsrXlw6kZgtR7YQPCWYkgVKEtMhhsJ5CktHUjeJFoJSV/L7786wOo8H4uKgXDnpRGL2nNxDQGQAubLnIj48nlIFS0lHUjeRV5xDUMprHT/u7BkcO+YMq7vjDulEYg4nHyYgIoCzF8+S1CWJikUqSkdSN5kWglL/JTkZgoOdw0UxMXDvvdKJxJxKOUVQVBD7T+9naael1CpZSzqSygBaCEr9m/PnnVtfrl0Ls2ZBo0bSicScu3iOkKkhbD6ymQXtFvBguQelI6kMooWg1D+lpUGnTs75ggkToEUL6URiUj2phM0MY+VvK4kKjSKwcqB0JJWBtBCU+jtr4bnnYPp0+OAD5wI0l/JYD93md2PBzgV8Hvw57Wq1k46kMpiuMlLq71591RlhPXAg/O9/0mnEWGvpH9ufyT9O5s2Gb/Lsfc9KR1KZQAtBqb98/DG8/TZ07w7Dh0unETV85XBGrhlJ33p9eeWRV6TjqEyihaAUwKRJ8OKLzonk0aNdPaxuzLoxvJLwCh3v6sjHgR/rsDoX0UJQav586NYNnngCoqIge3bpRGKm/TSNZxc9S9OqTZkQMkGH1bmM/msrd1uxwhlWV7cuzJkDuXNLJxITuyuW8DnhNCjfgOmtp+uwOhfSQlDutWGDM6yuYkVYvBgKFJBOJObbfd8SOj2UGn41mN9uPnlz5pWOpARoISh32rkTAgOhSBHneoNixaQTifnpyE80mdKE0gVLE9sxVofVuZgWgnKf/fudYXXgTC4tW1Y2j6BfT/xKQEQAeXPmJa5jHCULlJSOpATphWnKXY4dg4AAOHECEhOhalXpRGIOJx/GP8KflNQUkromcXuR26UjKWFaCMo9zpxxhtXt3g2xsXDPPdKJxJxMOUnjyMYcTD7I0vCl1CxRUzqS8gJaCModzp+H0FBYvx5mz4ZHH5VOJObsxbM0i27G1j+2sqDdAh4o94B0JOUltBBU1peWBh07wtKlMHEihIRIJxJzMe0ibWa04Zu93xDdKprGlRtLR1JeRAtBZW3WwjPPwMyZMGIEdO4snUiMx3p4av5TLPp5EaObjCasZph0JOVldJWRytoGD4Yvv3R+feEF6TRirLW8EPMCkZsiGdZoGL3u7SUdSXkhLQSVdX34Ibz7LvTsCcOGSacRNSxpGJ9+/ykv1H+BwQ8Plo6jvJQWgsqavv4aBgxwxlJ8/rmrh9V9sfYLhiYOpXPtznwY8KEOq1P/SQtBZT1z58LTTzvXG0REuHpYXfTmaHov7k1ItRDGh4zXYXXqsvS7Q2UtCQkQFgb16jn3Qs6VSzqRmCU/L6HT3E48fNvDTG01lRzZdA2JujwtBJV1rFvnLCmtUgUWLXL1sLrV+1bTanorapWoxfy2OqxOXR0tBJU1bN8OQUFQvLhzFXLRotKJxGw6vIkmU5pQ9payxHSMoVCeQtKRlI8QKwRjTB5jzPfGmB+NMVuMMW9IZVG+LfeRI875gmzZnMmlZcpIRxJz4NwBGkc2Jn/O/MSHx1MifwnpSMqHSB5UPA88Zq1NNsbkBFYZY5ZYa78TzKR8zdGj3DVgAJw65Qyrq1JFOpGYg2cOMmDTAC6YC6zsupLbCt8mHUn5GLFCsNZaIDn905zpH1Yqj/JBZ85AUBB5Dh1yxljXqSOdSMyJcydoHNmY4xeOk9g1kRp+NaQjKR8kuuzAGJMdWA9UBj631q75l8f0AHoA+Pn5kZiYmKkZvVVycrKrt0W2CxeoNXAghX/8kfVDhnDW43H2EFwoJS2FAZsGsP3MdoZWHsq5XedI3JUoHUuc298j10O0EKy1acDdxpjCwBxjTE1r7U//eMw4YBxAtWrVbMOGDTM9pzdKTEzEtdsiNdW54GzjRpg8mbPlyrl2W1xMu0jzqc3ZcnoL05+cTvEjxV27Lf7J1e+R6+QVq4ystSeBBCBQOIrydtZCr14wZw6MHAnh4dKJxHishy7zurBk1xLGNh1L6xqtpSMpHye5ysgvfc8AY0xewB/YLpVH+YiBA+Grr+DVV6FfP+k0Yqy19FvSjymbp/DO4+/QvW536UgqC5A8ZFQKmJR+HiEbMN1au1Awj/J277/vfDz7LLzh7lXKb6x4g8/Wfkb/B/rz8kMvS8dRWYTkKqNNgHuXhahrM348vPwytG0Lo0a5eljdqDWjeGPFG3S9uysf+H+gw+rUTeMV5xCUuqzZs50R1oGBMGmScwGaS0VtiqJvTF9a3NGCcc3GaRmom8q97yzlG5Ytg3bt4P77nbueuXhY3aKdi+gyrwsNKzQkulW0DqtTN50WgvJea9dCixZQtSosXAj580snErNq7ypaz2hN7ZK1mdd2Hnly5JGOpLIgLQTlnbZtc4bV+fm5fljdj4d+pOmUppQvVJ4lHZZwS+5bpCOpLEoLQXmfvXudYXU5cjjD6kqXlk4kZtfxXTSObEzB3AWJD4/HL7+fdCSVhelBSOVd/vgD/P2dOUUrVkDlytKJxBw4cwD/CH9SPakkdE6gfKHy0pFUFqeFoLzH6dPOSqJ9+5w9g9q1pROJOX7uOI0jG3P07FGWd1pOdb/q0pGUC2ghKO+QkgLNm8OmTTBvHjRoIJ1IzJ8X/qTplKbsPLaTxe0Xc1+Z+6QjKZfQQlDyUlOdC84SEyEyEoKDpROJuZB2gVbTW7Hm9zXMeHIGj1d8XDqSchEtBCXLWuje3dkr+PRT6NBBOpGYNE8aneZ0IvaXWMY3G09o9VDpSMpldJWRkmMtDBgAEyfCa69Bnz7SicRYa+mzpA/TtkzjvSfeo9s93aQjKRfSQlBy3nsPPvoIevd2CsHFXkt8jdHrRvPSgy/x0kMvScdRLqWFoGSMGweDBkH79vDJJ64eVvfJd5/wVtJbdKvTjXefeFc6jnIxLQSV+WbOdG5yExTkHC5y8bC6iB8jeD72eUKrhzKm6RgdVqdEufedqGTExzt7BQ8+6BRDzpzSicQs2LGArvO68tjtjxEVGqXD6pQ4LQSVedasgZYtoXp1Z1hdvnzSicQk/ZZEm5ltqFOqDnPD5uqwOuUVtBBU5tiyxbm+oGRJiImBwoWlE4nZeHAjzaKbUaFwBZZ0WELB3AWlIykFaCGozLBnjzOsLlcu55BRqVLSicT8fOxnAqMCKZS7EHEd4yier7h0JKX+Lz1oqTLW4cNOGZw9C0lJULGidCIxv5/+Hf8IfzzWQ3x4POUKlZOOpNT/QwtBZZxTp5yVRPv3w9KlUKuWdCIxx88dJyAygGPnjpHYOZFqxatJR1Lq/6OFoDLGuXMQEgKbN8OCBc6qIpdKvpBMcFQwvxz/hSUdllC3dF3pSEr9Ky0EdfOlpkJYGKxcCVFRzkhrlzqfep7QaaGsPbCWWW1m0ej2RtKRlPpPWgjq5vJ4oFs3Z6/g88+hXTvpRGLSPGmEzwknfnc8E0Im0OKOFtKRlLosXWWkbh5roX9/mDwZ3nwTnn1WOpEYay3PLX6OGVtn8KH/h3St01U6klJXpIWgbp7hw2HkSOjbF155RTqNqFeWv8LY9WMZ+NBA+j/YXzqOUldFC0HdHGPGOCXQsSN8/LGrh9WN+HYEw1cNp/s93Rn++HDpOEpdNS0EdeOmTXMODzVtChMmuHpY3aQfJtE/rj+ta7RmdJPROqxO+RSxd64xppwxJsEYs9UYs8UY008qi7oBsbEQHu7cA3n6dFcPq5u3fR7d5nfjiYpPENkykuzZsktHUuqaSK4ySgX6W2s3GGMKAuuNMfHW2q2CmdS1+PZbCA2FGjVg/nzIm1c6kZjEPYmEzQyjbum6zAmbQ+4cuaUjKXXNrriHYIzpY4wpcrNf2Fp70Fq7If33Z4BtQJmb/Toqg/z0EzRpAqVLO3sJLh5Wt+HgBkKiQ6hYpCKL2y+mQK4C0pGUui7GWnv5BxgzDGgLbAAmALH2Sk+61hDGVACSgJrW2tP/+LseQA8APz+/utOnT7+ZL+2zkpOTKVBA5gdPnoMHqdOnDxjDxk8/JUV4WJ3ktth3dh99f+hL7my5GVVnFH65/URy/EVyW3gb3RaXNGrUaL219t4rPtBae8UPwACNganALmA4UOlqnnsVX7sAsB4IvdJjq1atapUjISFB5oUPHbK2UiVrixSxdvNmmQz/ILUt9p7ca8t/XN76ve9ndxzdIZLhn8S+L7yQbotLgHX2Kn4eX9VJ5fQveCj9IxUoAsw0xrx/rU31d8aYnMAsIMpaO/tGvpbKBCdPQuPGcPAgLF4MNWtKJxJz9OxRAiIDOJlyktiOsVQtVlU6klI37IonldNX/3QCjgLjgQHW2ovGmGzAz8BL1/PCxlmP9xWwzVo74nq+hspEZ89Cs2awdatzt7P69aUTiTlz/gzBUcHsObmHmA4x1ClVRzqSUjfF1awyKopzOOe3v/+htdZjjGl6A6/9EBAObDbG/JD+Z4OttYtv4GuqjHDxIrRpA998A1OnOvc3cKnzqedpOa0lGw5uYHbYbB6t8Kh0JKVumisWgrX2tcv83bbrfWFr7SqccxPKm3k88NRTsGiRczVymzbSicSkedLoMLsDy35dxqQWkwipFiIdSambyr2XlKorsxZeeAEiI+Htt6FnT+lEYqy19FrYi1nbZvFx44/pVLuTdCSlbjotBPXfhg2DTz91SmHQIOk0ogYtG8T4jeMZ8vAQnq//vHQcpTKEFoL6d198AUOHQufO8OGHrh5W98E3H/DeN+/Rq24v3mr0lnQcpTKMFoL6/0VHQ+/ezi0wx4939bC6CRsn8NLSlwi7M4zPgj/TYXUqS3PvO139uyVLoFMneOQRZ0VRDvfeVG/Otjl0X9CdgEoBTG45WYfVqSxPC0Fdsno1tGoFtWrBvHmuHla3/NfltJ3Vlnpl6jG7zWxyZc8lHUmpDKeFoBybNjnD6sqWhZgYKFRIOpGYdQfW0Xxqc6oUrcKi9ovInyu/dCSlMoUWgoLdu52RFPnzQ3w8lCghnUjM9qPbCYoKoni+4sSFx1E0b1HpSEplGvceIFaOgwfB3x8uXICVK+G226QTidl7ai/+Ef5kM9mID4+ndMHS0pGUylRaCG524oSzZ3D4MCxf7tzoxqX++PMPAiICOH3+NCu6rKBy0crSkZTKdFoIbvXXsLrt253JpfXqSScSc+b8GYKigvjt1G/EdYzj7lvvlo6klAgtBDe6eBFat3ZugTltGjzxhHQiMSmpKTSf2pwfDv3A3LZzefi2h6UjKSVGC8FtPB7o0sW53mDcOKcYXCrVk0q7We1I2JNARMsImla9keG9Svk+XWXkJtZCv34wZQq88w507y6dSIy1lp4LejJ3+1w+CfyEjnd1lI6klDgtBDd54w347DP43//g5Zel04h6eenLTPhhAkMfGUrf+/tKx1HKK2ghuMWoUU4hdO0K77/v6mF17616jw9Wf8Bz9z3H6w1fl46jlNfQQnCDqCjo2xdatHDOG7i4DL5c/yUDlw2kXc12fBr0qQ6rU+pvtBCyukWLnJPIjRo5U0xdPKxu1tZZ9FrUi8DKgUxsMZFsRr/9lfo7fUdkZatWOauIateGuXMhTx7pRGKW7l5K+9ntqV+2PrPazNJhdUr9Cy2ErOrHH6FpU2cUxZIlcMst0onEfP/797SY2oJqxaqxsN1C8uXMJx1JKa+khZAV7drljKQoWBDi4sDPTzqRmG1/bCMoKogS+UsQ2zGWInmLSEdSymu594ByVnXggDOsLjUVEhKgfHnpRGJ+O/kb/hH+5Mqei/jweEoVLCUdSSmvpoWQlRw/7uwZHD3qDKurXl06kZgjfx4hIDKA5AvJJHVNolLRStKRlPJ6WghZxZ9/OucMdu50htXdd590IjGnz58mKCqIfaf2ER8ez10l75KOpJRP0ELICi5ccG59uWYNzJgBjz8unUhMSmoKIdEhbDq8iXlt5/FQ+YekIynlM7QQfF1aGnTqBLGxMH48hIZKJxKT6kklbGYYSb8lERkaSXCVYOlISvkULQRfZi306eOMsH7/fejWTTqRGI/18PT8p5m/Yz6jgkbRvlZ76UhK+RzRZafGmAnGmCPGmJ8kc/is116D0aPhpZdgwADpNGKstQyIG8CkHyfx+qOv07teb+lISvkk6esQJgKBwhl8UpmZM+Gtt5y9gnfflY4jasq+KYz4bgR96vVh6KNDpeMo5bNEC8FamwQcl8zgkyIiqPL55875gjFjXD2sbuy6sYz/dTwdanVgZOBIHVan1A3w+nMIxpgeQA8APz8/EhMTZQMJK7Z6NTVffZWjtWuztWdP7KpV0pHEJP6RyJtb3+TeQvfSpXAXklYkSUcSl5yc7Pr3yF90W1w7Y62VDWBMBWChtbbmlR5brVo1u2PHjowP5a2SkpwLz2rVYuXrr/NwsHtX0cT9EkfTKU25v+z9DCk/hMDH9cgjQGJiIg0bNpSO4RV0W1xijFlvrb33So+TPoegrtbGjdCsGVSoAIsXk5bPvQPavtv/HS2ntaS6X3UWtFtAnuzuneKq1M2kheALfv4ZAgOhUCFnWF3x4tKJxGw5soXgqGBKFShFbMdYCucpLB1JqSxDetlpNPAtUM0Ys98Y496F9P/l99+dYXUeD8THQ7ly0onE7Dm5h4DIAPLkyEN8eDy3FrhVOpJSWYroSWVrbTvJ1/d6x49DQIDza0ICVKsmnUjM4eTD+Ef4c/biWZK6JHF7kdulIymV5Xj9KiPXSk6G4GD45ReIiYG6daUTiTmVcorAqEAOnDnA0vCl1CpZSzqSUlmSFoI3On/eucZg7VqYNQtcvFLi3MVzNItuxpYjW5jfbj4PlHtAOpJSWZYWgrdJS4PwcOd8wYQJ0KKFdCIxF9MuEjYzjFV7VzGl1RQCK+vSUqUykhaCN7EWnnvOGWH94YfQtat0IjEe66Hb/G4s2LmAL4K/oG3NttKRlMrydNmpN3nlFRg7FgYNgv79pdOIsdbyYuyLRGyK4K1Gb/HMfc9IR1LKFbQQvMWIETB8OPToAW+/LZ1G1Nsr3+aTNZ/Q7/5+DHl4iHQcpVxDC8EbTJrk7BG0bg1ffOHqYXWj147m1YRXCb8rnBGNR+iwOqUykRaCtHnznBHW/v4QGQnZs0snEjP1p6k8t/g5mlVtxlchX5HN6LenUplJ33GSEhMhLMy5xmD2bMidWzqRmJhdMYTPCadB+QZMaz2NnNlzSkdSynW0EKRs2AAhIVCpEixeDAUKSCcSs3rfalpNb0XNEjVZ0G4BeXPmlY6klCtpIUjYudMZVle0qDOsrlgx6URiNh/eTJMpTShdsDQxHWIolKeQdCSlXEsLIbPt3++cLwCnDMqUkc0jaPeJ3TSObEy+nPmID4+nZIGS0pGUcjW9MC0zHT3qDKs7edI5f1C1qnQiMYeSDxEQEUBKagoru66kQuEK0pGUcj0thMxy5owzrO7XX51hdXXqSCcSczLlJIGRgRxKPsTSTku5s8Sd0pGUUmghZI7z56FlS+dE8uzZ8Oij0onEnL14lmbRzdj6x1YWtl9I/bL1pSMppdJpIWS0tDTo0AGWLXMuQAsJkU4k5mLaRdrMaMM3e79hauupBFQKkI6klPobLYSMZC306uWMsP74Y+jUSTqRGI/10HVeVxb9vIgxTcbQ5s420pGUUv+gq4wy0uDBMH48DBkCzz8vnUaMtZbnY54nanMUbz/2Nj3v7SkdSSn1L7QQMsqHH8K77zp7CG+9JZ1G1FtJbzHq+1G8WP9FBjUYJB1HKfUftBAywoQJMGCAM5bis89cPazus+8/47XE1+hcuzMfBHygw+qU8mJaCDfbnDnQvbtzvcHkya4eVjdl8xT6LOlDSLUQxoeM12F1Snk5fYfeTAkJ0LYt1KvnLC/NlUs6kZjFPy+m89zOPHrbo0xrPY0c2XT9glLeTgvhZlm3zllSWqUKLFoE+fNLJxLzzd5vaD29NXeVvIv57eaTJ0ce6UhKqaughXAzbN8OQUFQvLgzn6hoUelEYjYd3kTT6KaUK1SOJR2WcEvuW6QjKaWukhbCjdq71zlfkC0bxMdD6dLSicT8cvwXGkc2Jn/O/MR1jKNE/hLSkZRS10AP7N6IP/5wyuDUKVixAipXlk4k5uCZgwREBnAh7QIru67ktsK3SUdSSl0jLYTr9dewut9+cw4T3X23dCIxJ86doHFkYw4nH2Z55+XU8KshHUkpdR1EDxkZYwKNMTuMMbuMMQMls1yTlBRo0QI2boQZM+Dhh6UTifnzwp80jW7KjmM7mNt2LvXK1JOOpJS6TmKFYIzJDnwOBAE1gHbGGO//r2VqKrRvD8uXw8SJ0LSpdCIxF9Iu0HpGa77b/x1TQqfwRMUnpCMppW6A5B5CPWCXtXa3tfYCMBVoLpjnyqyFnj2di88++QQ6dpROJMZjPXSZ24WYXTGMaTKGVjVaSUdSSt0gyUIoA+z72+f70//Me738sjOWYuhQ6NtXOo0Yay19l/Ql+qdo3n38XbrX7S4dSSl1E3j9SWVjTA+gB4Cfnx+JiYkiOcpFR1Np3Dh+b9GCnxs2dG6BKSg5OVlsW3y952sm/zaZsLJh1LtYTyzHXyS3hbfRbXGJbovrYK0V+QAeAGL/9vkgYNDlnlO1alUr4ssvrQVr27WzNi1NJsM/JCQkiLzuJ999Ynkd+9Tcp6zH4xHJ8E9S28Ib6ba4RLfFJcA6exU/lyUPGa0FqhhjbjfG5ALaAvMF8/y7WbOc8waBgc5J5GzuvZYvclMk/WL60eKOFoxtNlYnlyqVxYgdMrLWphpjegOxQHZggrV2i1Sef7V0qbOiqH59pxhcPKxu0c5FdJnbhUYVGhHdKlqH1SmVBYm+q621i4HFkhn+0/ffO9caVKsGCxdCvnzSicSs/G0lrWe05u5b72Zu27k6rE6pLMq9xz8uZ9s25yrkEiUgNhaKFJFOJOaHQz/QNLoptxW6TYfVKZXFaSH802+/gb8/5MzpDKsrVUo6kZhdx3cRGBnILblvIS48Dr/8ftKRlFIZSA8E/92RI86wuuRkSEqCSpWkE4k5cOYA/hH+pHpSSeySSPlC5aUjKaUymBbCX06fdu5psG+fs2dw113SicQcP3ecgIgAjp49SkLnBO4ofod0JKVUJtBCAGdYXfPmsGkTzJsHDz0knUjMnxf+pMmUJvx8/GeWdFjCvaXvlY6klMokWgipqc59kFesgMhI52SyS11Iu0Do9FC+//17Zj45k8duf0w6klIqE7m7EDwe6N7d2SsYNcq55sCl0jxpdJrTibhf4vgq5CtaVm8pHUkplcncu8rIWhgwwLn6+PXXoXdv6URirLX0XtybaVum8f4T7/NUnaekIymlBLi3EN59F0aMgD59nOmlLjY0YShj1o/h5YdeZsBDA6TjKKWEuLMQxo2DwYOhQwcYORJcPJNn5HcjGbZyGE/XeZp3Hn9HOo5SSpD7CmHGDOjVC5o0ga+/dvWwusk/TuaF2BcIrR7KmKZjdFidUi7nrp+G8fHOXsFDD8H06c7VyC41f8d8npr3FI/f/jhTQqeQPVt26UhKKWHuKYQ1a6BlS6heHRYscPWwuhV7VtBmRhvuKXUPc8LmkDtHbulISikv4I5C2LLFub7g1ludYXWFC0snErPx4EZCpoZQsUhFFndYTMHcBaUjKaW8RNYvhD17nPlEuXM7h4xuvVU6kZidx3bSOLIxhfMUJi48juL5iktHUkp5kax9Ydrhw87k0rNnnWF1t98unUjM/tP7CYgIACCuYxxlbykrnEgp5W2ybiGcOuXc9vLAAefOZ7VqSScSc+zsMRpHNub4ueMkdE6gWvFq0pGUUl4oaxbCuXMQEuKcO5g/Hx54QDqRmOQLyTSZ0oRfjv9CTMcY6pauKx1JKeWlsl4hXLwIYWGwciVMmeLsJbjU+dTzhE4LZe2BtcxuM5uGFRpKR1JKebGsVQgeD3Tr5iwr/eILZ4qpS6V50gifE0787ni+bv41ze9oLh1JKeXlss4qI2uhf3+IiIC33oJnnpFOJMZay7OLnmXG1hl8FPARXe7uIh1JKeUDsk4hDB/uzCXq1w+GDJFOI2rI8iGM2zCOQQ0G8eIDL0rHUUr5iKxRCKNHwyuvQHi4M8HUxTN5Plr9Ee+seoce9/Tg7cfelo6jlPIhvl8I06bBc89Bs2bw1VeuHlb39cav+V/8/3iyxpN80eQLHVanlLomvv3TMzbW2Sto0MApBhcPq5u7fS5PL3ga/4r+RLSM0GF1Sqlr5ruF8O23EBoKd97prCrKm1c6kZjEPYm0ndmW+0rfx+yw2TqsTil1XXyzEH76ybmfQenSEBMDhQpJJxKz/sB6QqJDqFS0EovaL6JArgLSkZRSPsr3CuHXX51hdXnzOsPqSpaUTiRmx9EdBEYFUjRvUeI6xlEsXzHpSEopHyZSCMaYJ40xW4wxHmPMvVf9vLQ0Z1hdSgrExUGFChmY0rsdSTmCf4Q/BkN8eDxlbikjHUkp5eOkrlT+CQgFxl7Lk/Lt3w85cjjD6u68M2OS+YCjZ48yYPMATqWdIrFzIlWKVZGOpJTKAkQKwVq7DbjmZZHZzp93htXVr58huXzBmfNnCI4K5lDKIeI7xVOnVB3pSEqpLMJYa+Ve3JhE4H/W2nWXeUwPoEf6pzVx9i4UFAeOSofwErotLtFtcYlui0uqWWuveHvEDNtDMMYsBf7t9mRDrLXzrvbrWGvHAePSv+Y6a+1Vn3PIynRbXKLb4hLdFpfotrjEGPOf/+n+uwwrBGvtExn1tZVSSt18vrfsVCmlVIaQWnba0hizH3gAWGSMib3Kp47LwFi+RrfFJbotLtFtcYlui0uualuInlRWSinlPfSQkVJKKUALQSmlVDqfKwRjzAfGmO3GmE3GmDnGmMLSmaRc7wiQrMIYE2iM2WGM2WWMGSidR5IxZoIx5ogxxtXX6RhjyhljEowxW9PfG/2kM0kxxuQxxnxvjPkxfVu8caXn+FwhAPFATWvtXcBOYJBwHkl/jQBJkg6S2Ywx2YHPgSCgBtDOGFNDNpWoiUCgdAgvkAr0t9bWAOoDz7n4++I88Ji1tjZwNxBojLnsmAefKwRrbZy1NjX90++AspJ5JFlrt1lrd0jnEFIP2GWt3W2tvQBMBZoLZxJjrU0CjkvnkGatPWit3ZD++zPANsCVkx+tIzn905zpH5ddReRzhfAPTwFLpEMoEWWAfX/7fD8ufeOrf2eMqQDUAdYIRxFjjMlujPkBOALEW2svuy2kpp1e1tWMvTDGDMHZPYzKzGyZ7WaNAFHKTYwxBYBZwPPW2tPSeaRYa9OAu9PPtc4xxtS01v7neSavLIQrjb0wxnQBmgKP2yx+IYWOAPlPvwPl/vZ52fQ/Uy5njMmJUwZR1trZ0nm8gbX2pDEmAec8038Wgs8dMjLGBAIvASHW2rPSeZSYtUAVY8ztxphcQFtgvnAmJcw4M/W/ArZZa0dI55FkjPH7axWmMSYv4A9sv9xzfK4QgM+AgkC8MeYHY8wY6UBSbmAEiM9LX1jQG4jFOXE43Vq7RTaVHGNMNPAtUM0Ys98Y0006k5CHgHDgsfSfDz8YY4KlQwkpBSQYYzbh/Acq3lq78HJP0NEVSimlAN/cQ1BKKZUBtBCUUkoBWghKKaXSaSEopZQCtBCUUkql00JQSikFaCEopZRKp4Wg1A0wxtyXfm+OPMaY/Olz52tK51LqeuiFaUrdIGPMMCAPkBfYb619RziSUtdFC0GpG5Q+S2ktkAI8mD5hUimfo4eMlLpxxYACODO28ghnUeq66R6CUjfIGDMf545ttwOlrLW9hSMpdV288n4ISvkKY0wn4KK1dkr6fZ5XG2Mes9Yul86m1LXSPQSllFKAnkNQSimVTgtBKaUUoIWglFIqnRaCUkopQAtBKaVUOi0EpZRSgBaCUkqpdP8HExX4BSM53cUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 10, 1000) # start, finish, n points\n",
    "y1 = 1 + 2*x\n",
    "y2 = 3 + 2*x\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-1, 5])\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf966d34",
   "metadata": {},
   "source": [
    ">- No Solution (Parallel lines having same slope, but different y-intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51e9d05",
   "metadata": {},
   "source": [
    "**Example 7:**\n",
    "Solve the following set of two linear equations with two unknowns using substitution strategy, or elimination strategy (at your own). Use Matplotlib and see if two lines representing the two equations intersect.<br>\n",
    "\n",
    "$$ y = 1 + 2x$$\n",
    "\n",
    "$$ 4x - 2y + 2 = 0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c59378d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 10, 1000) # start, finish, n points\n",
    "y1 = 1 + 2*x\n",
    "y2 = 2/2 + (4/2)*x\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-1, 5])\n",
    "ax.plot(x, y1, 'r:')\n",
    "ax.plot(x, y2, 'g-.')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12536dd",
   "metadata": {},
   "source": [
    ">- Infinite Solutions (Parallel lines having same slope and same intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f4874e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5b4206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00aad90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ba7180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6c2bc8c",
   "metadata": {},
   "source": [
    "**Example 8:** \n",
    "- Suppose a robber robbed a bank and escaped in a car with speed of 150Km/hr. The sheriff start following the robber after 5 minutes in a car with speed of 180Km/hr. \n",
    "- We need to find out, whether the sherrif can catch the robber. And if yes, after how much time and what is the distance that both have travelled at that point. For simplicity, you can ignore acceleration and traffic conditions.\n",
    "- Let us write the two equations:\n",
    "    - The bank robber equation is: $d = 150t$\n",
    "    - The sherrif equation is: $d=180(t-5)$\n",
    "- Let us solve these equations graphically by plotting them using Matplotlib and see their point of intersection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "688ecdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "t = np.linspace(0, 100, 100) # start, finish, n points\n",
    "# to manage units on graph divide both equations by 60\n",
    "d1 = 2.5*t\n",
    "d2 = 3*(t-5)\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Distance')\n",
    "ax.set_xlim([0, 40])\n",
    "ax.set_ylim([0, 100])\n",
    "ax.plot(t, d1, c='green',linestyle= '-.')\n",
    "ax.plot(t, d2, c='r', linestyle=':')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555dbc7a",
   "metadata": {},
   "source": [
    "The above line graph shows that the two lines intersect at point $(30, 75)$. So we can infer that the sheriff has caught the robber after 30 minutes drive and after both has travelled a distnce of 75 Km."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb668e57-f726-4185-990e-bfe0e56ef469",
   "metadata": {},
   "source": [
    ">- **Replot the line graph, if the speed of the sheriff's car and robber's car is same**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "456b87de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "t = np.linspace(0, 100, 100) # start, finish, n points\n",
    "d1 = 0 + 2.5*t\n",
    "d2 = -15 + 2.5*t\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Distance')\n",
    "ax.set_xlim([0, 40])\n",
    "ax.set_ylim([0, 100])\n",
    "ax.plot(t, d1, c='green',linestyle= '-.')\n",
    "ax.plot(t, d2, c='r', linestyle=':')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcb571b",
   "metadata": {},
   "source": [
    "The two lines are parallel and never intersect. So we can infer that the sheriff will never be able to catch the theif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90571f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7f3cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e07aef2-47a2-426d-aeda-ddc363c89e28",
   "metadata": {},
   "source": [
    ">- **Replot the line graph, if the speed of the sheriff's car and robber's car is same as well as they leave at the same time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b022c33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "t = np.linspace(0, 100, 100) # start, finish, n points\n",
    "d1 = 2.5*t\n",
    "d2 = 2.5*t\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Distance')\n",
    "ax.set_xlim([0, 40])\n",
    "ax.set_ylim([0, 100])\n",
    "#ax.plot(t, d1, c='green')\n",
    "#ax.plot(t, d2, c='red')\n",
    "ax.plot(t, d1, c='green',linestyle= '-.')\n",
    "ax.plot(t, d2, c='r', linestyle=':')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53090a",
   "metadata": {},
   "source": [
    "The two lines are having same slope and same y-intercept. So there are infinite solutions, the sheriff can catch the theif any time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe08dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284dce0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c470dcc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f16b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f2c42e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87706fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89baaac1",
   "metadata": {},
   "source": [
    "### d. Points to Ponder\n",
    "\n",
    "<img align=\"center\" width=\"900\" height=\"900\"  src=\"images/LA/consistentequations1.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca4064f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e0823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c1cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9514de39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6863ba25",
   "metadata": {},
   "source": [
    "### e. Plotting a Linear Equation with Three Variables\n",
    "<img align=\"left\" width=\"300\" height=\"300\"  src=\"images/LA/3Dimage.png\"  >\n",
    "<img align=\"right\" width=\"500\" height=\"500\"  src=\"images/LA/plotting3varline.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309f29ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f03ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ac1109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7027aef",
   "metadata": {},
   "source": [
    "### f. Solving set of Three Linear Equations with Three Variables\n",
    "- The way we can solve a system of two linear equations with two variables using elimination and substitution strategy, we can solve a system of three linear equations with three variables using elimination and substitution.\n",
    "- The way we can visually plot the solution of a system of two linear equations with two variables by drawing the two lines and checking out their point of intersection. \n",
    "- Similarly, we can visually plot solution of a system of three linear equations with three variables by drawing the three planes for the three equations. Remember when two planes intersect, you get a line. The third plane may intersect in such a way that you get a unique point of intersection to all three planes. The third poane may intersect in such a way that you get a common line instead of a point. \n",
    "- Keeping this in mind, there can be following possibilities:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37ebef",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" height=\"300\"  src=\"images/LA/3DUniquesol.png\"  >\n",
    "\n",
    "**Consistant Independent System of Linear Equations:** \n",
    "- In this case, there is a unique solution.\n",
    "- Geometrically, all three planes intersect at exactly one point. In other words there is exactly one point that lies on all the three planes.\n",
    "- You can visualize it as the corner of your room, where the two walls and the floor intersect at exactly one point/corner.\n",
    "- An example of such a system of linear equations is shown below having a solution of $(4, 1, -2)$:\n",
    "\n",
    "$ \\hspace{2 cm}x +y  +z  = 3$\n",
    "\n",
    "$ \\hspace{2 cm}x +2y +3z = 0$\n",
    "\n",
    "$ \\hspace{2 cm}x +3y +2z = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa886ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab51229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5653590",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d48c6d79",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"300\" height=\"300\"  src=\"images/LA/3DInfinitesol.png\"  >\n",
    "\n",
    "**Consistant Dependent System of Linear Equations:** \n",
    "- In this case, there are infinite solutions.\n",
    "- Geometrically, all the three planes will intersect with eachother and make a line of intersection instead of a point.\n",
    "- An example of such a system of linear equations is:\n",
    "\n",
    "$ \\hspace{2 cm}2x + 2y +2z = -2$\n",
    "\n",
    "$ \\hspace{2 cm}2x + 3y +2z = 4$\n",
    "\n",
    "$ \\hspace{2 cm}x + y +z = -1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcef16c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86b2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0a0360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a953ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea979c1e",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"500\" height=\"500\"  src=\"images/LA/3DNosol.png\"  >\n",
    "\n",
    "**Inconsistant System of Linear Equations:** \n",
    "- In this case, there is no solution.\n",
    "- There are three scenarios for this:\n",
    "    - The three planes intersect with each other, but not at a common point\n",
    "    - Two of the planes are parallel and intersect with the third plane, but not with each other\n",
    "    - All three planes are parallel, so there is no point of intersection\n",
    "- Example of such a system of linear equations are:\n",
    "    - $ x  +y +z = 1$, $ 2x  +2y +2z = 2$, and $ 4x +4y +4z = 4$\n",
    "    - $ 2x  -4y +z = 3$, $ 8x  -2y +4z = 7$, and $ -4x +y -2z = -14$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417e186f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb7451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652c643d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55c5dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "735f34d7",
   "metadata": {},
   "source": [
    "## 4. Solving System of Linear Equations using Matrix Algebra\n",
    "- In linear algebra, data is represented in the form of linear equations, which in turn are represented in the form of matrices and vectors.\n",
    "- We can later apply different techniques on the matrix equation, to solve for unknowns. \n",
    "- Some of the most commonly used techniques are:\n",
    "    - Gaussian Elimination.\n",
    "    - Gauss Jordan Elimination.\n",
    "    - Cramer's Rule.\n",
    "    - Matrix Inversion Method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacc62bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a9a61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add8ac9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e4f47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2929d7d",
   "metadata": {},
   "source": [
    "### a. Writing  System of Linear Equation in Matrix Form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7a400",
   "metadata": {},
   "source": [
    "**System of Two Linear Equations having two unknowns ($x_1$, and  $x_2$), with four coefficients:**<br>\n",
    "$$ a_{1,1}x_1 + a_{1,2}x_2 = b_1 $$\n",
    "$$ a_{2,1}x_1 + a_{2,2}x_2  = b_2 $$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} a_{1,1} & a_{1,2}  \\\\ a_{2,1} & a_{2,2} \\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2  \\end{bmatrix}=\n",
    "\\begin{bmatrix} b_1 \\\\ b_2  \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "**System of Three Linear Equations having three unknowns($x_1, x_2$, and  $x_3$), with nine coefficients:**<br>\n",
    "\n",
    "$$ a_{1,1}x_1 + a_{1,2}x_2 + a_{1,3}x_3 = b_1 $$\n",
    "$$ a_{2,1}x_1 + a_{2,2}x_2 + a_{2,3}x_3 = b_2 $$\n",
    "$$ a_{3,1}x_1 + a_{3,2}x_2 + a_{3,3}x_3 = b_3 $$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} a_{1,1} & a_{1,2} & a_{1,3}  \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\\\a_{3,1} & a_{3,2} & a_{3,3}\\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3  \\end{bmatrix}=\n",
    "\\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3  \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "\n",
    "$$ Ax = b$$\n",
    "\n",
    "- Where,\n",
    "    - $A$ is the matrix of coefficients, or scalar values (`known matrix`)\n",
    "    - $x$ is a vector of variables (`unknown vector`)\n",
    "    - $b$ is a vector containing constants on the RHS of equations (`known vector`)\n",
    "        - If $b = 0_{nx1}$, we say that it is a homogeneous system of equations\n",
    "        - If $b \\neq 0_{nx1}$, we say that it is a non-homogeneous system of equations\n",
    "> You can say that a known matrix $A$ transforming an unknown vector $x$, and we know what the output vector is going to be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6c77e",
   "metadata": {},
   "source": [
    "### b. What do you mean by applying a Matrix to another Vector or Matrix\n",
    "- The way we can apply a transformation matrix to a vector, we can apply a transformation matrix to another matrix.\n",
    "- In such a scenario the transformation matrix is individually applied to all the vectors of the other matrix.\n",
    "- Let us understand this with a theoratical example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263c3f1",
   "metadata": {},
   "source": [
    "Consider the following 3-D transformation matrix $A$ and two 3-D vectors:\n",
    "$$\n",
    "\\overrightarrow{u_1} = \\begin{bmatrix} 2 \\\\ 5 \\\\  -3   \\end{bmatrix}\n",
    "\\hspace{2 cm}\\overrightarrow{u_2} = \\begin{bmatrix} 0 \\\\ -4 \\\\  6   \\end{bmatrix}\n",
    "\\hspace{2 cm}A = \\begin{bmatrix} 2 & 0 & -1 \\\\ -2 & 3 & 1 \\\\  0 & 4 & -1   \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Task 1:** Apply matrix $A$ to vector $\\overrightarrow{u_1}$\n",
    "$$\n",
    "A\\overrightarrow{u_1} = \\begin{bmatrix} 2 & 0 & -1 \\\\ -2 & 3 & 1 \\\\  0 & 4 & -1   \\end{bmatrix}  \\begin{bmatrix} 2 \\\\ 5 \\\\  -3   \\end{bmatrix} =   \\begin{bmatrix} 7 \\\\ 8 \\\\  23   \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Task 2:** Apply matrix $A$ to vector $\\overrightarrow{u_2}$\n",
    "$$\n",
    "A\\overrightarrow{u_2} = \\begin{bmatrix} 2 & 0 & -1 \\\\ -2 & 3 & 1 \\\\  0 & 4 & -1   \\end{bmatrix}  \\begin{bmatrix} 0 \\\\ -4 \\\\  6   \\end{bmatrix} =   \\begin{bmatrix} -6 \\\\ -6 \\\\  -22   \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Task 3:** Let us create a matrix $U$ by concatenating vector $\\overrightarrow{u_1}$ and vector $\\overrightarrow{u_2}$\n",
    "$$\n",
    "U = \\begin{bmatrix} 2 & 0 \\\\ 5 & -4 \\\\  -3 & 6    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Task 4:** Apply matrix $A$ to matrix $U$\n",
    "$$\n",
    "AU = \\begin{bmatrix} 2 & 0 & -1 \\\\ -2 & 3 & 1 \\\\  0 & 4 & -1   \\end{bmatrix}  \\begin{bmatrix} 2 & 0 \\\\ 5 & -4 \\\\  -3 & 6   \\end{bmatrix} =   \\begin{bmatrix} 7 & -6 \\\\ 8 & -6 \\\\ 23 & -22   \\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a18c547",
   "metadata": {},
   "source": [
    ">- Note the first column vector of matrix $AU$ is the same as applying matrix $A$ to vector $\\overrightarrow{u_1}$. \n",
    ">- Similarly, the second column vector of matrix $AU$ is the same as applying matrix $A$ to vector $\\overrightarrow{u_2}$.\n",
    ">- Note the the result of $AU$ is the same as we concatenate $A\\overrightarrow{u_1}$ and $A\\overrightarrow{u_2}$. So that means, whatever linear transformations we apply to matrix $U$, that is independently applied to each of it's columns (vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98794fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef279790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e30a2b14",
   "metadata": {},
   "source": [
    "### c. Solving set of Linear Equations Using Gaussian Elimination Method\n",
    "- Gaussian Elimination is a method for solving systems of linear equations with several unknown variables. It works by bringing the matrix representing the equations into row echelon form and resolving the unknown variables by back-substitution.\n",
    "- Gaussian elimination is a method named after German mathematician Larl Friedrich Gauss.\n",
    "- Suppose we want to solve a system of three linear equations with three unknowns given below:\n",
    "$$ a_{1,1}x_1 + a_{1,2}x_2 + a_{1,3}x_3 = b_1 $$\n",
    "$$ a_{2,1}x_1 + a_{2,2}x_2 + a_{2,3}x_3 = b_2 $$\n",
    "$$ a_{3,1}x_1 + a_{3,2}x_2 + a_{3,3}x_3 = b_3 $$\n",
    "\n",
    "- **Step 1**: We represent the system of equations in `augmented matrix` form. An augmentation matrix for a system of three linear equations with three unknowns is of the form:\n",
    "$$\n",
    "\\begin{bmatrix} a_{1,1} & a_{1,2} & a_{1,3}  \\bigm| & b_1 \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\bigm| & b_2 \\\\a_{3,1} & a_{3,2} & a_{3,3} \\bigm| & b_3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Step 2**: Then we apply different operations on augmented matrix in no specific order, with the goal to eliminate one variable at a time to achieve `upper triangular marix` (Row echelon form is a diagonal matrix where all entries below a leading coefficient are zero. Some textbooks also state that the leading coefficient must equal one):\n",
    "$$\n",
    "\\begin{bmatrix} 1 & a_{1,2} & a_{1,3}  \\bigm| & b_1 \\\\ 0 & 1 & a_{2,3} \\bigm| & b_2 \\\\0 & 0 & 1 \\hspace{.4 cm} \\bigm| & b_3 \\end{bmatrix}\n",
    "$$\n",
    "- The matrix operations performed for triangularization are:\n",
    "    - Interchange order of any two rows ($R_i = R_j$).\n",
    "    - Multiply a row by a non-zero constant($R_i = nR_j$\n",
    "    - Add a multiple of a row to another row ($R_j = R_i + R_j$)\n",
    "    \n",
    "- **Step 3**:Once in this form, we can say that $x_3 = b_3$ and use `back substitution` to solve for $x_2$ and $x_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33b8b16",
   "metadata": {},
   "source": [
    "**Example 9:** Given the system of three linear equations with three unknowns, solve for unknowns by using Gauss Elimination method:\n",
    "- Write the System of Linear Equation in Augmented Matrix Form: An augmented matrix is a rectangular array of numbers that represents a system of equations.\n",
    "    $$𝑥 + 𝑦 + 𝑧 = 3$$\n",
    "    $$𝑥 + 2𝑦 +3z= 0$$\n",
    "    $$𝑥 + 3𝑦 + 2𝑧 = 3$$    \n",
    "\n",
    "- Step 1: Augmented Matrix of system of equations\n",
    "  $$\n",
    "\\begin{bmatrix}\n",
    "    1 & 1 & 1 \\bigm| & 3 \\\\\n",
    "    1 & 2 & 3 \\bigm| & 0  \\\\\n",
    "    1 & 3 & 2\\bigm| & 3 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- Step 2: Convert it into row-echlon form (by performing triangularization)\n",
    "\n",
    "$\\hspace{3 cm} R_2 = R_2 - R1:\\hspace{1 cm} \\begin{bmatrix}1 & 1 & 1 \\bigm| & 3 \\\\ 0 & 1 & 2 \\bigm| & -3  \\\\ 1 & 3 & 2\\bigm| & 3 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_3 = R_3 - R1:\\hspace{1 cm} \\begin{bmatrix}1 & 1 & 1 \\bigm| & 3 \\\\ 0 & 1 & 2 \\bigm| & -3  \\\\ 0 & 2 & 1\\bigm| & 0 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_3 = 2R_2:\\hspace{1 cm} \\begin{bmatrix}1 & 1 & 1 \\bigm| & 3 \\\\ 0 & 2 & 4 \\bigm| & -6  \\\\ 0 & 2 & 4\\bigm| & 0 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_3 = R_2 - R_3:\\hspace{1 cm} \\begin{bmatrix}1 & 1 & 1 \\bigm| & 3 \\\\ 0 & 2 & 4 \\bigm| & -6  \\\\ 0 & 0 & 3\\bigm| & -6 \\end{bmatrix}$ \n",
    "   \n",
    "     \n",
    "- Step 3: Back Substitution\n",
    "Now convert the matrix in row-echlon form to a system of linear equations and solve:\n",
    "$$𝑥 + 𝑦 + 𝑧 = 3$$\n",
    "$$    2𝑦 +4z= -6$$\n",
    "$$        3𝑧 = -6$$    \n",
    "Perform back substitution, you get $z=-2, y=1, x=4$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9221bff8",
   "metadata": {},
   "source": [
    "**Practice Problems:** Use paper pencil to solve following system of linear equations:\n",
    "\n",
    "(i)  $\\hspace{.5 cm}x +3𝑦 + 4𝑧 = 4$ $\\hspace{2 cm}−𝑥 + 3𝑦 +2z = 2$ $\\hspace{2 cm}3𝑥 + 9𝑦 + 6𝑧 = -6$ \n",
    "\n",
    "(ii) $\\hspace{.5 cm}x +4𝑦 + 3𝑧 = 1$ $\\hspace{2 cm}𝑥 + 2𝑦 + 9z = 1$ $\\hspace{2 cm}𝑥 + 6𝑦 + 6𝑧 = 1$ \n",
    "\n",
    "(iii) $\\hspace{.5 cm}x +3𝑦 + 3𝑧 = 2$ $\\hspace{2 cm}3𝑥 + 9𝑦 +3z = 3$ $\\hspace{2 cm}3𝑥 + 6𝑦 + 6𝑧 = 4$ \n",
    "\n",
    "> Verify your answers using this online calculator https://www.handymath.com/cgi-bin/matrix3d.cgi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6492c54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9aa3a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9206a5cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5aa61adc",
   "metadata": {},
   "source": [
    "### d. Solving set of Linear Equations Using Gauss Jordan Method\n",
    "- Gauss-Jordan elimination is another method for solving systems of equations in matrix form. It is really a\n",
    "continuation of Gaussian elimination. However, it works for non-square matrices as well.\n",
    "- Suppose we want to solve a system of three linear equations with three unknowns given below:\n",
    "$$ a_{1,1}x_1 + a_{1,2}x_2 + a_{1,3}x_3 = b_1 $$\n",
    "$$ a_{2,1}x_1 + a_{2,2}x_2 + a_{2,3}x_3 = b_2 $$\n",
    "$$ a_{3,1}x_1 + a_{3,2}x_2 + a_{3,3}x_3 = b_3 $$\n",
    "\n",
    "- **Step 1**: We represent the system of equations in `augmented matrix` form. An augmentation matrix for a system of three linear equations with three unknowns is of the form:\n",
    "$$\n",
    "\\begin{bmatrix} a_{1,1} & a_{1,2} & a_{1,3}  \\bigm| & b_1 \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\bigm| & b_2 \\\\a_{3,1} & a_{3,2} & a_{3,3} \\bigm| & b_3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Step 2**: Then we apply different operations on augmented matrix in no specific order, with the goal to eliminate one variable at a time to achieve reduced row-echlon form or `diagonal matrix` (non-zero elements along main diagonal and zeros every where else)):\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 0 & 0  \\bigm| & 0 \\\\ 0 & 1 & 0 \\bigm| & b_2 \\\\0 & 0 & 1 \\bigm| & b_3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- **Step 3**: Once in this form, we can say that $x_1 = b_1$, $x_2 = b_2$ and $x_3 = b_3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af291b5e",
   "metadata": {},
   "source": [
    "**Example 10:** Given the system of three linear equations with three unknowns, solve for unknowns by using Gauss Elimination method:\n",
    "- Write the System of Linear Equation in Augmented Matrix Form: An augmented matrix is a rectangular array of numbers that represents a system of equations.\n",
    "    $$5𝑥 + 2𝑦  = 2$$\n",
    "    $$2𝑥 + 𝑦 -z= 0$$\n",
    "    $$2𝑥 + 3𝑦 - 𝑧 = 3$$    \n",
    "\n",
    "- Step 1: Augmented Matrix of system of equations\n",
    "  $$\n",
    "\\begin{bmatrix}\n",
    "    5 & 2 & 0 \\bigm| & 2 \\\\\n",
    "    2 & 1 & -1 \\bigm| & 0  \\\\\n",
    "    2 & 3 & -1\\bigm| & 3 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "- Step 2: Convert it into reduced row-echlon form\n",
    "\n",
    "$\\hspace{3 cm} R_1 = \\frac{1}{5}R_1:\\hspace{5 cm} \\begin{bmatrix}1 & 2/5 & 0 \\bigm| & 2/5 \\\\ 2 & 1 & -1 \\bigm| & 0  \\\\ 2 & 3 & -1\\bigm| & 3 \\end{bmatrix}$ \n",
    "\n",
    "$\\hspace{3 cm} R_2 = R_2 - 2R_1:\\hspace{4 cm} \\begin{bmatrix}1 & 2/5 & 0 \\bigm| & 2/5 \\\\ 0 & 1/5 & -1 \\bigm| & -4/5  \\\\ 2 & 3 & -1\\bigm| & 3 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_3 = R_3 - 2R_1:\\hspace{4 cm} \\begin{bmatrix}1 & 2/5 & 0 \\bigm| & 2/5 \\\\ 0 & 1/5 & -1 \\bigm| & -4/5  \\\\ 0 & 11/5 & -1\\bigm| & 11/5 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_2 = 5R_2$ and $R_3=5R_3:\\hspace{2.6 cm} \\begin{bmatrix}1 & 2/5 & 0 \\bigm| & 2/5 \\\\ 0 & 1 & -5 \\bigm| & -4  \\\\ 0 & 11 & -5\\bigm| & 11 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_2 = R_2 - R_3:\\hspace{4.55 cm} \\begin{bmatrix}1 & 2/5 & 0 \\bigm| & 2/5 \\\\ 0 & -10 & 0 \\bigm| & -15  \\\\ 0 & 11 & -5\\bigm| & 11 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_2 = \\frac{-1}{10}R_2$ and $R_3=\\frac{1}{11}R_3:\\hspace{2 cm} \\begin{bmatrix}1 & 2/5 & 0 \\bigm| & 2/5 \\\\ 0 & 1 & 0 \\bigm| & 3/2  \\\\ 0 & 1 & -5/11\\bigm| & 1 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_1 = R_1 - \\frac{2}{5}R_2$ and $R_3=R_3 - R_2:\\hspace{1 cm} \\begin{bmatrix}1 & 0 & 0 \\bigm| & -1/5 \\\\ 0 & 1 & 0 \\bigm| & 3/2  \\\\ 0 & 0 & -5/11\\bigm| & -1/2 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "$\\hspace{3 cm} R_3 = \\frac{-11}{5}R_3:\\hspace{5 cm} \\begin{bmatrix}1 & 0 & 0 \\bigm| & -1/5 \\\\ 0 & 1 & 0 \\bigm| & 3/2  \\\\ 0 & 0 & 1\\bigm| & 11/10 \\end{bmatrix}$ \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Step 3:\n",
    "$x=-1/5, y=3/2, z=11/10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c18f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc96aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25fa80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15bbabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae16a57b",
   "metadata": {},
   "source": [
    "### e. Solving set of Linear Equations Using Cramer's Rule\n",
    "- Cramer’s Rule uses determinants to determine the solution of a system of linear equations in matrix form.\n",
    "- Cramer's rule only works on square matrices that have a non-zero determinant and a unique solution.\n",
    "- Consider a system of three linear equations with three unknowns:\n",
    "\n",
    "$$ a_{1,1}x_1 + a_{1,2}x_2 + a_{1,3}x_3 = b_1 $$\n",
    "$$ a_{2,1}x_1 + a_{2,2}x_2 + a_{2,3}x_3 = b_2 $$\n",
    "$$ a_{3,1}x_1 + a_{3,2}x_2 + a_{3,3}x_3 = b_3 $$\n",
    "\n",
    "\n",
    "- These three equations can be written in matrix form as:\n",
    "$$\n",
    "\\begin{bmatrix} a_{1,1} & a_{1,2} & a_{1,3}  \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\\\a_{3,1} & a_{3,2} & a_{3,3}\\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\\\ x_3  \\end{bmatrix}=\n",
    "\\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3  \\end{bmatrix} \n",
    "$$\n",
    "\n",
    "$$ Ax = b$$\n",
    "\n",
    "\n",
    "- Cramer's Formula for the three unknowns in this scenario is:\n",
    "\n",
    "$$x = \\frac{D_x}{D}$$\n",
    "\n",
    "$$y = \\frac{D_y}{D}$$\n",
    "\n",
    "$$z = \\frac{D_z}{D}$$\n",
    "\n",
    "- Where,\n",
    "- D is the determinant of matrix $A = \\begin{bmatrix} a_{1,1} & a_{1,2} & a_{1,3}  \\\\ a_{2,1} & a_{2,2} & a_{2,3} \\\\a_{3,1} & a_{3,2} & a_{3,3}\\end{bmatrix}$\n",
    "\n",
    "\n",
    "- $D_x$ is the determinant of matrix $A$ by replacing x-column by the vector of right hand side of the matrix equation: $\\begin{vmatrix} b_1 & a_{1,2} & a_{1,3}  \\\\ b_2 & a_{2,2} & a_{2,3} \\\\b_3 & a_{3,2} & a_{3,3}\\end{vmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "- $D_y$ is the determinant of matrix $A$ by replacing x-column by the vector of right hand side of the matrix equation: $\\begin{vmatrix} a_{1,1} & b_1 & a_{1,3}  \\\\ a_{2,1} & b_2 & a_{2,3} \\\\a_{3,1} & b_2 & a_{3,3}\\end{vmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- $D_z$ is the determinant of matrix $A$ by replacing x-column by the vector of right hand side of the matrix equation: $\\begin{vmatrix} a_{1,1} & a_{1,2} & b_1  \\\\ a_{2,1} & a_{2,2} & b_2 \\\\a_{3,1} & a_{3,2} & b_3\\end{vmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48603b0",
   "metadata": {},
   "source": [
    "\n",
    "**Example 11:** Given the system of two linear equations with two unknowns, solve for unknowns by using Cramer's Rule\n",
    "    $$𝑥 + 2𝑦 = 3$$\n",
    "    $$4𝑥 + 5𝑦 = 6$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 &  2 \\bigm| & 3 \\\\  4 & 5  \\bigm| & 6 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$\\hspace{4 cm}D = \\begin{vmatrix} 1 &  2  \\\\  4 & 5 \\end{vmatrix} = 5 - 8 = -3$\n",
    "\n",
    "\n",
    "$\\hspace{4 cm}D_x = \\begin{vmatrix} 3 &  2  \\\\  6 & 5 \\end{vmatrix} = 15 - 12 = 3$\n",
    "\n",
    "\n",
    "$\\hspace{4 cm}D_y = \\begin{vmatrix} 1 &  3  \\\\  4 & 6 \\end{vmatrix} = 6 - 12 = -6$\n",
    "\n",
    "$\\hspace{2 cm}x = \\frac{D_x}{D} = \\frac{3}{-3} = -1$\n",
    "\n",
    "$\\hspace{2 cm}y = \\frac{D_y}{D} = \\frac{-6}{-3} = 2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc2c6a",
   "metadata": {},
   "source": [
    "**Example 12:** Given the system of three linear equations with three unknowns, solve by using Cramer's Rule:\n",
    "    $$𝑥 + 4𝑦 +3z = 1$$\n",
    "    $$𝑥 + 2𝑦 +9z= 1$$\n",
    "    $$𝑥 + 6𝑦 + 6𝑧 = 1$$    \n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 &  4 & 3 \\bigm| & 1 \\\\  1 & 2 & 9 \\bigm| & 1  \\\\ 1 & 6 & 6\\bigm| & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$\\hspace{4 cm}D = \\begin{vmatrix} 1 &  4 & 3 \\\\  1 & 2 & 9 \\\\ 1 & 6 & 6 \\end{vmatrix} = 1(12-54) - 4(6-9)+3(6-2) = -18$\n",
    "\n",
    "$\\hspace{4 cm}D_x = \\begin{vmatrix} 1 &  4 & 3 \\\\  1 & 2 & 9 \\\\ 1 & 6 & 6 \\end{vmatrix} = 1(12-54) - 4(6-9)+3(6-2) = -18$\n",
    "\n",
    "$\\hspace{4 cm}D_y = \\begin{vmatrix} 1 &  1 & 3 \\\\  1 & 1 & 9 \\\\ 1 & 1 & 6 \\end{vmatrix} = 1(6-9) - 1(6-9)+3(1-1) = 0$\n",
    "\n",
    "$\\hspace{4 cm}D_z = \\begin{vmatrix} 1 &  4 & 1 \\\\  1 & 2 & 1 \\\\ 1 & 6 & 1 \\end{vmatrix} = 1(2-6) - 4(1-1)+1(6-2) = 0$\n",
    "\n",
    "$\\hspace{2 cm}x = \\frac{D_x}{D} = \\frac{-18}{-18} = 1$\n",
    "\n",
    "$\\hspace{2 cm}y = \\frac{D_y}{D} = \\frac{0}{-18} = 0$\n",
    "\n",
    "$\\hspace{2 cm}z = \\frac{D_z}{D} = \\frac{0}{-18} = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45de02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2e5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab0fcb21",
   "metadata": {},
   "source": [
    "### f. Solving set of Linear Equations Using Matrix Inversion Method\n",
    "\n",
    "$$ Ax = b$$\n",
    "\n",
    "- Now, the matrix equation representing the set of linear equations can be solved using different techniques. Let us use Matrix Inversion method:\n",
    "\n",
    "$$ Ax = b$$\n",
    "\n",
    "$$ A^{-1}Ax = A^{-1}b $$\n",
    "\n",
    "$$  Ix = A^{-1}b $$\n",
    "\n",
    "$$  x = A^{-1}b $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f476d8c",
   "metadata": {},
   "source": [
    "**Example 13:** Solve the set of two linear equations having two unknowns, by Matrix Inversion technique using paper pencil:\n",
    "$$ 4x + 2y = 4 $$\n",
    "$$ -5x - 3y = -7 $$ \n",
    "We can write these two equations in Matrix form as:<br>\n",
    "$$\n",
    "\\begin{bmatrix} 4 & 2 \\\\  -5 & -3  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 4 \\\\ -7  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "Ax = b\n",
    "$$\n",
    "\n",
    "$$\n",
    "x = A^{-1}b\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix}  =  \\frac{1}{det(A)}\\begin{bmatrix}    -3 & -2\\\\ 5 & 4 \\end{bmatrix}  \n",
    "\\begin{bmatrix} 4 \\\\ -7  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix}  =  \\frac{1}{-12-(-10)}\\begin{bmatrix}    -3 & -2\\\\ 5 & 4 \\end{bmatrix}  \n",
    "\\begin{bmatrix} 4 \\\\ -7  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =   \\frac{1}{-2}\\begin{bmatrix}    2 \\\\ -8 \\end{bmatrix}  \n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =   \\begin{bmatrix}    -1 \\\\ 4 \\end{bmatrix}  \n",
    "$$\n",
    ">- **So the solution is $x=-1$ and $y=4$**\n",
    ">- **Let us perfrom the above steps in Python**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93214456",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 2], [-5, -3]])\n",
    "b = np.array([4,-7])\n",
    "Ainv = np.linalg.inv(A)\n",
    "x = np.dot(Ainv, b)\n",
    "# You can use `numpy.linalg.solve()` to solve a system of linear equations by passing it the matrix $X$ \n",
    "# and the known vector on the right-hand side of the equation\n",
    "x = np.linalg.solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f29bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f503b02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09fbf933",
   "metadata": {},
   "source": [
    "**Example 14:** Solve the set of two linear equations having two unknowns, by Matrix Inversion technique using Python:\n",
    "$$ x - \\frac{1}{2}y = 1 $$\n",
    "$$ -\\frac{1}{2}x + y = -1 $$\n",
    "\n",
    "- The above two equations can be written in matrix form as shown below. \n",
    "$$\n",
    "\\begin{bmatrix} 1 & -1/2 \\\\ -1/2 & 1\\end{bmatrix} \n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 1 \\\\ -1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "$$Ax = b$$\n",
    "$$x = A^{-1}b$$\n",
    "$$x = \\begin{bmatrix} 4/3 & 2/3 \\\\2/3 & 4/3\\end{bmatrix} \\begin{bmatrix} 1 \\\\ -1  \\end{bmatrix}$$\n",
    "\n",
    "$$x =  \\begin{bmatrix} 2/3 \\\\ -2/3  \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b3de3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, -1/2], [-1/2, 1]])\n",
    "b = np.array([1,-1])\n",
    "Ainv = np.linalg.inv(A)\n",
    "x = np.dot(Ainv, b)\n",
    "# You can use `numpy.linalg.solve()` to solve a system of linear equations by passing it the matrix $X$ \n",
    "# and the known vector on the right-hand side of the equation\n",
    "x = np.linalg.solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94352e28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651c9933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1468b4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d03a42e4",
   "metadata": {},
   "source": [
    "**Example 15:** Solve the set of three linear equations having three unknowns, by Matrix Inversion technique using Python:\n",
    "$$ x + 2y + 3z = -7 $$\n",
    "$$ 2x - 3y - 5z   = 9 $$\n",
    "$$ -6x - 8y + z = -22$$\n",
    "\n",
    "- The above three equations can be written in matrix form as shown bbelow. \n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 & 3 \\\\ 2 & -3 & -5 \\\\  -6 & -8 & 1\\end{bmatrix} \n",
    "\\begin{bmatrix} x \\\\ y  \\\\ z\\end{bmatrix} =  \n",
    "\\begin{bmatrix} -7 \\\\ 9 \\\\ -22  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "$$\n",
    "Ax = b\n",
    "$$\n",
    "- Above equation says, that vector $x$ lands on vector $bb$ via transformation matrix $A$\n",
    "\n",
    "$$\n",
    "x = A^{-1}b\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 3], [2, -3, -5], [-6, -8, 1]])\n",
    "b = np.array([-7,9, -22])\n",
    "Ainv = np.linalg.inv(A)\n",
    "x = np.dot(Ainv, b)\n",
    "# You can use `numpy.linalg.solve()` to solve a system of linear equations by passing it the matrix $X$ \n",
    "# and the known vector on the right-hand side of the equation\n",
    "x = np.linalg.solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457e286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee12c8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "56428b0d",
   "metadata": {},
   "source": [
    "**Example 16:** Solve the set of four linear equations having four unknowns, by Matrix Inversion technique using Python:\n",
    "$$ w + x + y = 75 $$\n",
    "$$ w + x + z  = 80 $$\n",
    "$$ w + y + z = 75$$\n",
    "$$ x + y + z  = 70 $$\n",
    "\n",
    "- The above three equations can be written in matrix form as shown bbelow. \n",
    "$$\n",
    "\\begin{bmatrix} 1 & 1 & 1 & 0 \\\\ 1 & 1 & 0 & 1 \\\\  1 & 0 & 1 & 1 \\\\ 0 & 1 & 1 & 1\\end{bmatrix} \n",
    "\\begin{bmatrix} w \\\\ x \\\\ y  \\\\ z\\end{bmatrix} =  \n",
    "\\begin{bmatrix} 75 \\\\ 80 \\\\ 75 \\\\ 70  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "<br><br>\n",
    "$$\n",
    "Ax = b\n",
    "$$\n",
    "- Above equation says, that vector $x$ lands on vector $bb$ via transformation matrix $A$\n",
    "\n",
    "$$\n",
    "x = A^{-1}b\n",
    "$$\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a75e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, 1, 0], [1, 1, 0, 1], [1, 0, 1, 1], [0, 1, 1, 1]])\n",
    "b = np.array([75,80, 75,70])\n",
    "Ainv = np.linalg.inv(A)\n",
    "x = np.dot(Ainv, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfea680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 1, 1, 0], [1, 1, 0, 1], [1, 0, 1, 1], [0, 1, 1, 1]])\n",
    "b = np.array([75,80, 75,70])\n",
    "x = np.linalg.solve(A, b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f910c030",
   "metadata": {},
   "source": [
    "### g. Limitations\n",
    "- If coefficient matrix $A$, is Singular, that is all of its columns are not linearly independent, then you cannot find its inverse, and hence cannot solve the system of linear equations\n",
    "- If coefficient matrix $A$, is not square, then you cannot find its inverse, and hence cannot solve the system of linear equations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdd4833",
   "metadata": {},
   "source": [
    "**Example 17:** If coefficient matrix $A$, is Singular, i.e., all of its columns are not linearly independent, then you cannot find its inverse, and hence cannot solve the system of linear equations. This is shown below:\n",
    "$$-9x - 15y = -15$$\n",
    "$$3x + 5y = -10$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} -9 & -15 \\\\  3 & 5  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 15 \\\\ -10  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- The above two equations are linearly dependent, this can be observed from the coefficients of two equations\n",
    "- The determinant of coefficient matrix is zero, therefore, the inverse of matrix $A$ does not exist and hence the solution.\n",
    "- You can confirm this by solving the system of equations using either substitution strategy, or elimination strategy at your own.\n",
    "- Finally if you plot a graph of these two equations, you will get two parallel lines. This can be observed from the rearranged equations below having same slope and different y-intercept. \n",
    "$$ y = \\frac{-9}{15}x + 1$$\n",
    "$$ y = \\frac{-3}{5}x - 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff5f9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-20, 20, 1000) # start, finish, n points\n",
    "y1 = (-9/15)*x + 1\n",
    "y2 = (-3/5)*x - 1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.set_xlim([-10, 20])\n",
    "ax.set_ylim([-10, 10])\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='brown')\n",
    "plt.grid(True)\n",
    "\n",
    "A = np.array([[-9,-15],[3,5]])\n",
    "b = np.array([15, -10])\n",
    "print(\"det(A): \", np.linalg.det(A))\n",
    "#Ainv = np.linalg.inv(A)         #Uncomment this line to check the error `LinAlgError: Singular matrix`\n",
    "#w = np.linalg.solve(A, b)       #Uncomment this line to check the error `LinAlgError: Singular matrix`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c234288",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5047ec",
   "metadata": {},
   "source": [
    "## 3. Categories of System of Linear Equations\n",
    "- Uptill now we have seen linear system of equations which have same number of equations as the number of unknowns, hence, the coefficient matrix $A$ becomes a square matrix. Since the coefficient matrix $A$ is square therefore, we can find the solution using simple matrix inversion method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9c2dc7",
   "metadata": {},
   "source": [
    "### a. Overdetermined Systems of Linear Equations\n",
    "- An overdetermined system of equations is a system in which the number of equations is greater than the number of unknowns. \n",
    "- Such a system cannot be solved using simple matrix inversion method, as the coefficient matrix is not square and thus cannot be inverted. \n",
    "- In machine learning many a times we have overdetermined systems that we need to solve. For example, a dataset having thousands of houses but only a few features.\n",
    "\n",
    " <h3 align=\"center\">$ A_{n\\times m}\\hspace{.2 cm}x_{n\\times 1}\\hspace{.3 cm}=\\hspace{.3 cm}b_{n\\times 1} \\hspace{1 cm}$ and $ \\hspace{.3 cm}n\\hspace{.3 cm}\\gt\\hspace{.3 cm}m$ </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999dddc6",
   "metadata": {},
   "source": [
    "**Consistent Overdetermined System having `Unique` Solution:**\n",
    "$$\\hspace{3 cm}x+y=3$$\n",
    "$$\\hspace{3 cm}x-y=1$$\n",
    "$$\\hspace{3 cm}3x-y=5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd25198",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 20, 5) # start, finish, n points\n",
    "y1 = 3 - x\n",
    "y2 = -1 + x\n",
    "y3 = -5 + 3*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "ax.plot(x, y3, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15456e2c",
   "metadata": {},
   "source": [
    "> If you plot these three equations the three lines will intersect at point $(2,1)$, giving a unique solution. Note all the three equations are not linearly independent, rather you can get third equation if you add first equation with second equation multiplied by 2. Since number of liner independent equations is two which is equal to the number of unknowns therefore we get a unique solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75386aa3",
   "metadata": {},
   "source": [
    "**Consistent Overdetermined System having `Infinite` Solution:**\n",
    "$$x+y=1$$\n",
    "$$2x+2y=2$$\n",
    "$$ 3x+3y=3$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acc40d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-10, 20, 5) # start, finish, n points\n",
    "y1 = 1 - x\n",
    "y2 = 2/2 - (2/2)*x\n",
    "y3 = 3/3 - (3/3)*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "ax.plot(x, y3, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c59dcb0",
   "metadata": {},
   "source": [
    "> All of these three equations are actually same. If you plot them you will see the three lines are exactly overlaping, therefore, having infinite points that satisfies these three equations.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b53d07",
   "metadata": {},
   "source": [
    "**InConsistent Overdetermined System:**\n",
    "$$x+y=3$$\n",
    "$$x-y=1$$\n",
    "$$ 2x-5y=10$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95caee93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-5, 5, 10) # start, finish, n points\n",
    "y1 = 3 - x\n",
    "y2 = -1 + x\n",
    "y3 = -2 + (2/5)*x\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "ax.plot(x, y3, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8dacf",
   "metadata": {},
   "source": [
    "> All of these three equations are linearly independent so, we have no solution. If you plot them you will see the three linese intersect with eachother at three different points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46561bac",
   "metadata": {},
   "source": [
    "### b. Undertermined Systems of Linear Equations\n",
    "- An underdetermined system of equations is a system in which the number of equations is less than the number of unknowns. \n",
    "- Such a system cannot be solved using simple matrix inversion method, as the coefficient matrix is not square and thus cannot be inverted. \n",
    "- In deep learning many a times we have underdetermined systems that we need to solve. For example, we have thousands of training data points, while there are millions of parameters in the model.\n",
    "\n",
    " <h3 align=\"center\">$ A_{n\\times m}\\hspace{.2 cm}x_{n\\times 1}\\hspace{.3 cm}=\\hspace{.3 cm}b_{n\\times 1} \\hspace{1 cm}$ and $ \\hspace{.3 cm}n\\hspace{.3 cm}\\lt\\hspace{.3 cm}m$ </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4be70a0",
   "metadata": {},
   "source": [
    "**Consistent Underdetermined System having `Infinite` Solution:**\n",
    "$$x+y=3$$\n",
    "- A single equation having two unknowns is an example of undertermined system of linear equation. If you plot it you get a straight line and there are infinite many points that satisfies this equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f18f2a",
   "metadata": {},
   "source": [
    "**InConsistent Underdetermined System:**\n",
    "$$x+2y+2z=2$$\n",
    "$$x+2y+2z=4$$\n",
    "- This is an example of underdetermined system of linear equations having two equations and three unknowns. \n",
    "- We have seen that an equation having three variables when plotted gives you a plane.\n",
    "- Since both the equations have same coefficient, but different constants so these two equations represent two parallel planes in 3D space with no common point. So no solution. \n",
    "- Therefore, this system of liner equation is inconsistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3e3225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c2d66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b5beb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e0821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa806eb8",
   "metadata": {},
   "source": [
    "#  What is Linear Equation in Machine Learning\n",
    "- In machine learning, **a Linear Equation is a formaliation that describes the relationship between variables**\n",
    "- In machine learning, we use the following format of linear equations with one, two, three and so on m variables:<br>\n",
    "\n",
    "<h3>${\\hspace 9 cm}y = \\beta_0 + a_1\\beta_1 $</h3>\n",
    "<h3>${\\hspace 9 cm}y = \\beta_0 + a_1\\beta_1 + a_2\\beta_2$</h3>\n",
    "<h3>${\\hspace 9 cm}y = \\beta_0 + a_1\\beta_1 + a_2\\beta_2 + a_3\\beta_3 $</h3>\n",
    "<h3>${\\hspace 9 cm}y = \\beta_0 + a_1\\beta_1 + a_2\\beta_2 + a_3\\beta_3 + \\cdots + a_n\\beta_m $</h3>\n",
    "\n",
    "\n",
    "- Where, \n",
    "    - $y$ is the dependent or outcome or response variable.\n",
    "    - $\\beta_1, \\beta_2, \\beta_3, \\cdots, \\beta_m$  are the coefficients that stand before the independent variables. They quantify the effet of independent variable on the dependent variable (unknowns).\n",
    "    - $\\beta_0$ is the minimum value of $y$ when all the feature variables are zero.\n",
    "    - $a_1, a_2, a_3, \\cdots, a_n$ are the independent or feature or predictor variables\n",
    "    \n",
    "    \n",
    "- A system of `n` linear equations involving `m` variables/unknowns is shown below:\n",
    "\n",
    "$$ y_1 = a + a_{1,1}\\beta_1 + a_{1,2}\\beta_2 + a_{1,3}\\beta_3 + \\cdots + a_{1,m}\\beta_m $$\n",
    "$$ y_2 = a + a_{2,1}\\beta_1 + a_{2,2}\\beta_2 + a_{2,3}\\beta_3 + \\cdots + a_{2,m}\\beta_m $$\n",
    "$$ y_3 = a + a_{3,1}\\beta_1 + a_{3,2}\\beta_2 + a_{3,3}\\beta_3 + \\cdots + a_{3,m}\\beta_m $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "\n",
    "$$ y_n = a + a_{n,1}\\beta_1 + a_{n,2}\\beta_2 + a_{n,3}\\beta_3 + \\cdots + a_{n,m}\\beta_m $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add02a28",
   "metadata": {},
   "source": [
    "**Dependent Variables** vs **Independent Variables**\n",
    "- GPA depends on study hours\n",
    "- salary depends on number of years studied\n",
    "- car rent depends on time/duration of rent.\n",
    "- house price depends on covered area and number of bedrooms\n",
    "- forgetness level depends on drug dosage\n",
    "- sales depends on advertising expenditures\n",
    "\n",
    "Question: Identify the correlation coefficient and regression between the two variables.\n",
    "Question: Can we swap the dependent and independent variable? For example does the advertising expenditures depends on sales? Does the drug dosage depends on forgetness level? What will be the correlation coefficient in this case?\n",
    "Question: Can we have more than one dependent variables?\n",
    "Question: Can we have more than one independent variables?\n",
    "\n",
    "\n",
    "- For population the equation for simple linear regression looks like this:\n",
    "$$y = \\beta_0 + \\beta_1x + \\epsilon$$\n",
    "- $\\beta_0$ and $\\beta_1$ are population parameters, which are difficult to get.\n",
    "- When we have sample estimates then we use the symbols $ b_0$ and $b_1$ instead of $\\beta_0$ and $\\beta_1$\n",
    "- For sample the estimated simple linear regression equation looks like this:\n",
    "$$\\hat{y} = b_0 + b_1x$$\n",
    "- $\\hat{y}$ is the predicted value of y for a given value x (gpa)\n",
    "- $b_0$ is the y intercept of the line (gpa if studyhours is zero)\n",
    "- $b_1$ is the slope of the line (we need to compute this)\n",
    "- x is the number of hours studied\n",
    "\n",
    "\n",
    "Given data points (studyhours, gpa), use least squares method to fit a line\n",
    "$$min(\\sum(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- We need to find a straight line equation, that minimize the distance of each $y_i$ from each corresponding $\\hat{y}_i$ OR minimize the sum of squares of the deviations between observed and the predicted points.\n",
    "- $y_i$ is the  observed value of the dependent variable for the ith observation\n",
    "- $\\hat{y}_i$ is the  predicted value of the independent variable for the ith observation\n",
    "- You can perform prediction from the graph. Given a x value you predict the value from the line and the actual data point. Note the difference between the predicted value and the actual value.\n",
    "\n",
    "- To calculate the slope (Check out pearson correlation coefficient formula):\n",
    "$$ b_1 = \\frac{\\sum(x_i - \\bar{x})(y_i - \\bar{y})}{\\sum(x_i - \\bar{x})^2}$$\n",
    "- To calculate the y intercept:\n",
    "$$ b_0 = \\bar{y} - b_1\\bar{x}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02945d62",
   "metadata": {},
   "source": [
    "- Consider following linear equation, that represent the price of a house based on its features:\n",
    "<h3 align='center'>$y = a + a_1\\beta_1 + a_2\\beta_2 + a_3\\beta_3 + \\cdots + a_m\\beta_m$</h3>\n",
    "\n",
    "- Where,\n",
    "    - $y$ is the known house price (dependent variable or variable that we want to predict in regression)\n",
    "    - $a$ is the y-intercept (known base price of a house)\n",
    "    - $a_1, a_2, a_3, \\cdots, a_m$ are `m` different known features of this house. For example, covered area, number of bedrooms, distance to office,...\n",
    "    - $\\beta_1, \\beta_2, \\beta_3, \\cdots, \\beta_m $ are the unknowns (independent or predictor variables)\n",
    "<br> <br>\n",
    "\n",
    "- In the above equation, we have `m` unknowns, and to find the values of these `m` unknowns we need to have `m` equations.\n",
    "- If we collect data of `n` such houses, we will have a system of `n` linear equations involving `m` variables/unknowns as shown below:\n",
    "\n",
    "$$y_1 = a + a_{1,1}\\beta_1 + a_{1,2}\\beta_2 + a_{1,3}\\beta_3 + \\cdots + a_{1,m}\\beta_m$$\n",
    "$$y_2 = a + a_{2,1}\\beta_1 + a_{2,2}\\beta_2 + a_{2,3}\\beta_3 + \\cdots + a_{2,m}\\beta_m$$\n",
    "$$y_3 = a + a_{3,1}\\beta_1 + a_{3,2}\\beta_2 + a_{3,3}\\beta_3 + \\cdots + a_{3,m}\\beta_m $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$y_n = a + a_{n,1}\\beta_1 + a_{n,2}\\beta_2 + a_{n,3}\\beta_3 + \\cdots + a_{n,m}\\beta_m$$\n",
    "\n",
    "- We can write the avoce system of linear equations in matrix form as below:<br>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_n  \\end{bmatrix} =\n",
    "\\begin{bmatrix} 1 & a_{1,1} & a_{1,2} & a_{1,3} & \\cdots & a_{1,m} \\\\\n",
    "                1 & a_{2,1} & a_{2,2} & a_{2,3} & \\cdots & a_{2,m} \\\\\n",
    "                1 & a_{3,1} & a_{3,2} & a_{3,3} & \\cdots & a_{3,m}  \\\\\n",
    "                \\vdots  & \\vdots  & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                1 & a_{n,1} & a_{n,2} & a_{n,3} & \\cdots & a_{n,m}  \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ \\vdots \\\\ \\beta_m  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ y = Aw$$\n",
    "$$ Aw = y$$\n",
    "$$ Ax = b$$\n",
    "\n",
    " <h3 align=\"center\">$ A_{n\\times m}\\hspace{.2 cm}x_{n\\times 1}\\hspace{.3 cm}=\\hspace{.3 cm}b_{n\\times 1}$ </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9685850d",
   "metadata": {},
   "source": [
    "### k. Regression Example\n",
    "- Simple Linear Regression:\n",
    "    - Simple means there is one independent and on dependent variable.\n",
    "    - Linear means the relationship is approximated/described using straight line.\n",
    "    - Regression means\n",
    "- Multiple Linear Regression means we use more than one independent variables to predict the dependent variable. For example instead of just covered area we also use number of bedrooms to predict the price of the house.\n",
    "    \n",
    "\n",
    "$\\hspace{2 cm} y = a + bx_1 + cx_2 + dx_3 + \\cdots + mx_m $\n",
    "- Where,\n",
    "    - `y` is the house price\n",
    "    - `a` is the y-intercept (base price of a house)\n",
    "    - `x1` is feature of the house, distance to school\n",
    "    - `x2` is feature of the house, number of bedrooms\n",
    "    - `x3` is feature of the house, area of house\n",
    "\n",
    "- We may have hundred or thousands of houses\n",
    "- A system of `n` linear equations involving `m` variables/unknowns is shown below:\n",
    "\n",
    "$$y_1 = a + a_{1,1}\\beta_1 + a_{1,2}\\beta_2 + a_{1,3}\\beta_3 + \\cdots + a_{1,m}\\beta_m$$\n",
    "$$y_2 = a + a_{2,1}\\beta_1 + a_{2,2}\\beta_2 + a_{2,3}\\beta_3 + \\cdots + a_{2,m}\\beta_m$$\n",
    "$$y_3 = a + a_{3,1}\\beta_1 + a_{3,2}\\beta_2 + a_{3,3}\\beta_3 + \\cdots + a_{3,m}\\beta_m $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$y_n = a + a_{n,1}\\beta_1 + a_{n,2}\\beta_2 + a_{n,3}\\beta_3 + \\cdots + a_{n,m}\\beta_m$$\n",
    "\n",
    "- Let us write above set of linear equations in matrix form:<br>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_n  \\end{bmatrix} =\n",
    "\\begin{bmatrix} 1 & a_{1,1} & a_{1,2} & a_{1,3} & \\cdots & a_{1,m} \\\\\n",
    "                1 & a_{2,1} & a_{2,2} & a_{2,3} & \\cdots & a_{2,m} \\\\\n",
    "                1 & a_{3,1} & a_{3,2} & a_{3,3} & \\cdots & a_{3,m}  \\\\\n",
    "                \\vdots  & \\vdots  & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                1 & a_{n,1} & a_{n,2} & a_{n,3} & \\cdots & a_{n,m}  \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \\\\ \\vdots \\\\ \\beta_m  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- For any house, $y_i$ in the dataset, \n",
    "    - We know the outcome, $y_i$, which is the price of the house\n",
    "    - We know the features of the house, $X$, which are predictors like number of bedrooms, distance to school, ...\n",
    "    - Vector $w$ contains the unknowns, the model's learnable parameters\n",
    "- Assuming $X^{-1}$ exists, we can use matrix inversion  technique to solve for w:\n",
    "$$ y = Aw$$\n",
    "\n",
    "$$ A^{-1}y = A^{-1}Aw $$\n",
    "\n",
    "$$  A^{-1}y = Iw $$\n",
    "\n",
    "$$  A^{-1}y = w $$\n",
    "\n",
    "$$  w = A^{-1}y $$\n",
    "\n",
    "\n",
    "- Limitations:\n",
    "    - Inverse of matrix $X$ can only be calculated if it is square, i.e., $n_{rows} = n_{cols}$\n",
    "        - Cannot be calculated for over determined systems, i.e., $n_{rows} \\gt n_{cols}$\n",
    "        - Cannot be calculated for under determined systems, i.e., $n_{rows} \\lt n_{cols}$\n",
    "    - Can only be calculated if the Matrix is NOT Singular, i.e., all columns are linearly independent.\n",
    "    \n",
    "- **Good News**: Solving a system of linear equations is still possible even if the matrix can't be inverted using **Pseudo-Inverse**\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd75de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2fe18c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7075f25b",
   "metadata": {},
   "source": [
    "## 4. Solving Inconsistent Overdetermined System of Linear Equations using Least Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbd8626",
   "metadata": {},
   "source": [
    "**Example 1:** Given an overdetermined system having three linear equations with two unknowns. Draw the graph of three lines and see if the three lines intersect at one point. If the system is overdetermined, Find Least Squares Solution using paper pencil.\n",
    "$$-x +y =0$$\n",
    "$$y=1$$\n",
    "$$x+y=2$$\n",
    "$$2x+y=1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-20, 20, 100) # start, finish, n points\n",
    "y1 = x\n",
    "y2 = 0*x + 1\n",
    "y3 = -x + 2\n",
    "y4 = -2*x + 1\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-5, 5])\n",
    "ax.set_ylim([0, 5])\n",
    "#ax.plot(t, d1, c='green')\n",
    "#ax.plot(t, d2, c='red')\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "ax.plot(x, y3, c='blue')\n",
    "ax.plot(x, y4, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c19477d",
   "metadata": {},
   "source": [
    "> The system is overdetermined and inconsistent. However, we need to find x and y using least square solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb315e06",
   "metadata": {},
   "source": [
    "$$-x +y =0$$\n",
    "$$0x + y=1$$\n",
    "$$x+y=2$$\n",
    "$$2x+y=1$$\n",
    "\n",
    "- From the four equations create the matrix equation\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5643999",
   "metadata": {},
   "source": [
    "- Let us plot the four points of the coefficient matrix as a scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2407960",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2])       \n",
    "y = np.array([0, 1, 2, 1])  \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-2, 3])\n",
    "ax.scatter(x,y);\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0a7745",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "$$Ax = b$$\n",
    "\n",
    "$$A^TAx = A^Tb $$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 0 & 1 & 2 \\\\  1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} -1 & 0 & 1 & 2 \\\\  1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 \\\\  2 & 4  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3ceffc",
   "metadata": {},
   "source": [
    "**Option 1:**\n",
    "- Rewrite, above matrix equation:\n",
    "$$6m + 2c  = 4 $$\n",
    "$$2m + 4c = 4$$\n",
    "\n",
    "- Now this is a system of linear equation in which the number of equations is equal to the number of unknowns, so you can solve it using substitution or elimination method and you get the slope and y-intercept: $m=2/5$ and $c = 4/5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bc157b",
   "metadata": {},
   "source": [
    "**Option 2:**\n",
    "- Since the coefficient matrix is a square matrix so you can solve it using matrix inversion method\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 \\\\  2 & 4  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$x = A^{-1}b$$\n",
    "\n",
    "$$x = \\frac{1}{det(A)}\\begin{bmatrix} 4 & -2\\\\ -2 & 6 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}$$\n",
    "\n",
    "$$x = \\frac{1}{20}\\begin{bmatrix} 4 & -2\\\\ -2 & 6 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}$$\n",
    "\n",
    "$$x = \\begin{bmatrix} 1/5 & -1/10\\\\ -1/10 & 3/10 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}$$  \n",
    "\n",
    "$$x = \\begin{bmatrix} 2/5 \\\\ 4/5\\end{bmatrix}$$\n",
    "- Using this way, you get the same slope and y-intercept: $m=2/5$ and $c = 4/5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09d9f1",
   "metadata": {},
   "source": [
    "- **Solve using Python Code:**<br>\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$A^TAx = A^Tb $$\n",
    "\n",
    "$$x=(A^TA)^{-1}A^Tb$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c9b954",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1,1], [0,1],[1,1],[2,1]])\n",
    "b = np.array([[0],[1],[2],[1]])\n",
    "ATb = A.T@b\n",
    "ATA = A.T@A\n",
    "ATA_inv = np.linalg.inv(ATA)\n",
    "result = ATA_inv @ ATb\n",
    "print(\"Slope: \", result[0])\n",
    "print(\"Y-intercept: \", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13421fa",
   "metadata": {},
   "source": [
    "- **Shortcut:** Use `linregress(A, b)` method of `stats` module of `scipy` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c5f7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "result = scipy.stats.linregress([-1,0,1,2], [0,1,2,1])\n",
    "print(\"Slope: \", result.slope)\n",
    "print(\"Y-intercept: \", result.intercept)\n",
    "print(\"Correlation coefficient: \", result.rvalue)\n",
    "print(\"p-value (Hypothesis Student t-Test: \", result.pvalue)\n",
    "print(\"Error of Slope: \", result.stderr)\n",
    "print(\"Error of y-intercept: \", result.intercept_stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879bb75d",
   "metadata": {},
   "source": [
    ">- Let us now draw this line, which should be the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb991696",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2])       \n",
    "y = np.array([0, 1, 2, 1])  \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-2, 3])\n",
    "ax.scatter(x,y);\n",
    "\n",
    "\n",
    "x2 = np.linspace(-2,3, 10)\n",
    "y2 = 2/5 *x2 + 4/5\n",
    "ax.plot(x2,y2)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3c5134",
   "metadata": {},
   "source": [
    "> Now let us calculate the sum of squares of the errors\n",
    "$\\epsilon_i = \\hat{y}_i - y_i$, For a given instance $i$, $\\epsilon_i$ is a measure of the difference between the true $y_i$ and the model's estimate, $\\hat{y}_i$. If the model predicts $y_i$ perfectly, then the error is zero\n",
    "\n",
    "\n",
    "$$SSE = (c+mx_1-y_1)^2 + (c+mx_2-y_2)^2 + (c+mx_3-y_3)^2 + (c+mx_4-y_4)^2 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f764ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (-1,0) the error is:\n",
    "(.8 + 0.4*(-1)  - 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350bd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (0,1) the error is:\n",
    "(.8 + 0.4*(0) - 1)**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb463d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (1,2) the error is:\n",
    "(.8 + 0.4*(1) - 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026f15c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (2,1) the error is:\n",
    "(.8 + 0.4*(2) - 1)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b04f811",
   "metadata": {},
   "source": [
    ">- Mention the four equations for the four points, having two unknowns m (slope) and c (y-intercept)\n",
    "$$f(-1) = -m + c = 0$$\n",
    "$$f(0) =  0 + c = 1$$\n",
    "$$f(1) = m + c = 2$$\n",
    "$$f(2) = 2m + c = 1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac6206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fad69cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c52683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b83bf9e5",
   "metadata": {},
   "source": [
    "**Example 2:** \n",
    "- Given seven observations of students containing \n",
    "    - Number of hours a student has studied\n",
    "    - The GPA he/she has achieved\n",
    "    $$(1,1.4), (2,1.6),(3,2.5),(4,2.6), (5,3.5),(6,3.7),(7,4.0) $$\n",
    "- Fit a regression line to these seven data points\n",
    "\n",
    "- Mention the four equations for the four points $y=mx+c$\n",
    "- From the four equations create a Ax = b matrix equation\n",
    "- use psuedoinverse (either using transpose or inverse) to find m and y\n",
    "- Draw the line using this computed m and y, which is the best fit line\n",
    "- Finally calculate the least square errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68241da4",
   "metadata": {},
   "source": [
    ">- **Plot the observations using a scatter chart:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53648db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = np.array([1, 2, 3, 4, 5, 6, 7.])               # study hours \n",
    "gpa = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])   # gpa\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Study Hours vs GPA of Students\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"GPA\")\n",
    "ax.scatter(sh,gpa);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f122d0",
   "metadata": {},
   "source": [
    ">- **Mention the four equations for the four points:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd36b8",
   "metadata": {},
   "source": [
    "- We have just one feature/independent/predictor variable and that is the `study hours` and the outcome/dependent/response variable is `gpa`. \n",
    "- We know the equation of a line is:\n",
    "    \n",
    "$$ y = c + mx $$\n",
    "\n",
    "- Where,\n",
    "    - `y` is the outcome/dependent/response variable \n",
    "    - `x` is the only feature/independent/predictor variable\n",
    "    - `m` is the slope of the line \n",
    "    - `c` is the y-intercept. \n",
    "- In this scenario, there are only two model parameters (`m` is the slope of the line and `c` is the y-intercept)\n",
    "- In Machine Learning it is a convention to represent the model parameters with Greek letters Baita. So the above, equation can be re-written as regression equation as follows: \n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
    "\n",
    "- Where,\n",
    "    - $\\beta_0$ is the y-intercept\n",
    "    - $\\beta_1$ is the slope of the line \n",
    "    - $\\epsilon_i = \\hat{y}_i - y_i$, For a given instance $i$, $\\epsilon_i$ is a measure of the difference between the true $y_i$ and the model's estimate, $\\hat{y}_i$. If the model predicts $y_i$ perfectly, then the error is zero\n",
    "\n",
    "- Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**.  Our objective is to find the parameters $\\beta_0$ and $\\beta_1$ that minimize $\\epsilon$ across all the available data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdda8641",
   "metadata": {},
   "source": [
    "$$(1,1.4), \\hspace{.5 cm} (2,1.6), \\hspace{.5 cm}(3,2.5), \\hspace{.5 cm}(4,2.6),  \\hspace{.5 cm}(5,3.5), \\hspace{.5 cm}(6,3.7), \\hspace{.5 cm}(7,4.0) $$\n",
    "- Mention the seven equations for the seven points, having two unknowns: y-intercept ($\\beta_0$) and slope ($\\beta_1$)\n",
    "$$f(1): \\beta_0 + \\beta_1 = 1.4$$\n",
    "$$f(2): \\beta_0 + 2\\beta_1 = 1.6$$\n",
    "$$f(3): \\beta_0 + 3\\beta_1 = 2.5$$\n",
    "$$f(4): \\beta_0 + 4\\beta_1 = 2.6$$\n",
    "$$f(5): \\beta_0 + 5\\beta_1 = 3.5$$\n",
    "$$f(6): \\beta_0 + 6\\beta_1 = 3.7$$\n",
    "$$f(7): \\beta_0 + 7\\beta_1 = 4.0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72651870",
   "metadata": {},
   "source": [
    ">- **Create matrix equation from above seven equations: $Ax=b$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69dd5c",
   "metadata": {},
   "source": [
    "- Let the $y$-intercept is constant across all the points, so we can set it equal to `1` across the board.\n",
    "- Let us write the above overdetermined system of seven linear equations having two unknowns in matrix form.\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 1 \\\\  2 & 1 \\\\  3 & 1 \\\\ 4 & 1 \\\\  5 & 1 \\\\  6 & 1 \\\\ 7 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} m \\\\ c  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 1.4 \\\\ 1.6 \\\\ 2.5 \\\\ 2.6\\\\ 3.5 \\\\ 3.7 \\\\ 4.0  \\end{bmatrix}\n",
    "$$\n",
    "$$Ax = b$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3175128b",
   "metadata": {},
   "source": [
    ">- **Find the slope and y-intercept for the best fit line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add9862b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12fa36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 1:\n",
    "A = np.array([[1,1], [2,1],[3,1],[4,1],[5,1],[6,1],[7,1]])\n",
    "b = np.array([[1.4],[1.6],[2.5],[2.6],[3.5],[3.7],[4.0]])\n",
    "ATb = A.T@b\n",
    "ATA = A.T@A\n",
    "ATA_inv = np.linalg.inv(ATA)\n",
    "result = ATA_inv @ ATb\n",
    "print(\"Slope: \", result[0])\n",
    "print(\"Y-intercept: \", result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec9492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2:\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "y = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])\n",
    "N = 7 \n",
    "slope = (N*sum(x*y) - sum(x)*sum(y))/(N*sum(x**2)-(sum(x))**2)\n",
    "intercept = (sum(y) - slope*sum(x))/N\n",
    "print(\"Slope: \", slope)\n",
    "print(\"Y-intercept: \", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47337268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 3:\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "y = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])\n",
    "N = 7\n",
    "# To find cov(x,y) and var(x), use the covariance matrix\n",
    "cov_mat = np.cov(x, y)\n",
    "print(\"Covariance matrix: \\n\",cov_mat)\n",
    "\n",
    "slope = cov_mat[0,1]/cov_mat[0,0]       #slope = cov(x,y)/var(x)\n",
    "intercept = sum(y)/N  - slope * sum(x)/N\n",
    "\n",
    "print(\"\\nSlope: \", slope)\n",
    "print(\"Y-intercept: \", intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac9e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 4:\n",
    "import scipy.stats\n",
    "x = np.array([1, 2, 3, 4, 5, 6, 7])\n",
    "y = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])\n",
    "# linregress() function calculate a linear least-squares regression for two sets of measurements.\n",
    "# Return a five tuple value\n",
    "# slope of regression line\n",
    "# intercept of regression line\n",
    "# rvalue, which is the correlation coefficient\n",
    "# pvalue for a hypothesis test whose null hypothesis is that the slope is zero\n",
    "# stderr is the standard error of the estimated slope\n",
    "#slope, intercept, r, p, stderr = scipy.stats.linregress(drug, level)\n",
    "\n",
    "result = scipy.stats.linregress(x,y)\n",
    "print(\"Slope: \", result.slope)\n",
    "print(\"Y-intercept: \", result.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50eda4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b146732",
   "metadata": {},
   "source": [
    ">- **Draw the line using this computed slope and y-intercept, which is the best fit line**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b6aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7])       \n",
    "y = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])  \n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Study Hours vs GPA of Students\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"GPA\")\n",
    "ax.scatter(sh,gpa);\n",
    "\n",
    "x2 = np.linspace(0,8, 10)\n",
    "y2 = 0.464*x2 + 0.9\n",
    "ax.plot(x2,y2)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a308d693",
   "metadata": {},
   "source": [
    ">- **Finally calculate the least square errors to dtermine how well the regression line actually fits the data:**\n",
    "\n",
    "- **R-squared Error/Coefficient of Determination**. Tells us how well the regression line fit the data.  can range from 0 to 1. A value of 0 indicates that the response variable cannot be explained by the predictor variable at all. A value of 1 indicates that the response variable can be perfectly explained without error by the predictor variable.\n",
    "\n",
    "$$R^2 = \\frac{SSR}{SST}$$\n",
    "\n",
    "    - Where, **Sum of Squares due to Regression (SSR)** is calculated as the sum of the squares deviations of each predicted value of y, i.e., \\hat{y}, and subtract the avarage y, i.e., \\bar{y}. So it measures the difference between the predicted values and its average.\n",
    "\n",
    "$$SSR = \\sum(\\hat{y}_i - \\bar{y})^2$$ \n",
    "\n",
    "\n",
    "\n",
    "    - Where, **Sum of Squares Total (SST)** is the total variation squared.\n",
    "$$SST = SSR + SSE = \\sum(y_i - \\bar{y})^2$$ $$ \n",
    "\n",
    "\n",
    "- **Sum of Squares Error (SSE)** is the unexplained deviation:\n",
    "    \n",
    "$$SSE = \\sum(\\hat{y}_i - y_i)^2$$ \n",
    "\n",
    "- **Sum of Squares due to Regression (SSR)** is calculated as the sum of the squares  \n",
    "\n",
    "$$SSR = \\sum(\\hat{y}_i - \\bar{y})^2$$ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7])       \n",
    "y = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])  \n",
    "yhat = slope*x + intercept\n",
    "sse = sum((yhat - y)**2)\n",
    "ssr = sum((yhat- np.mean(y))**2)\n",
    "sst = ssr + sse\n",
    "r2 = ssr/sst\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0075fa8f",
   "metadata": {},
   "source": [
    "This tells us that 96.4% of the variation in GPA can be explained by the number of hours studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b79f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120187ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b546bb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70c0d233",
   "metadata": {},
   "source": [
    "**Example 3:** \n",
    "- Given four observations\n",
    "    $$(-1,0), (-2,-3),(1,2),(6,0) $$\n",
    "- Fit a regression line to these four data points and find R-squared or the coefficient of determination to determine how well the regression line fits the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4443721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "x = np.array([-1, -2, 1, 6])\n",
    "y = np.array([0, -3, 2, 0])\n",
    "result = scipy.stats.linregress(x,y)\n",
    "print(\"Slope: \", result.slope)\n",
    "print(\"Y-intercept: \", result.intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad5ec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y);\n",
    "x2 = np.linspace(-3,6, 10)\n",
    "y2 = result.slope*x2 + result.intercept\n",
    "ax.plot(x2,y2)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, -2, 1, 4])\n",
    "y = np.array([-1, -3, 2, 3])\n",
    "\n",
    "yhat = result.slope*x + result.intercept\n",
    "sse = sum((yhat - y)**2)\n",
    "ssr = sum((y- np.mean(y))**2)\n",
    "sst = ssr + sse\n",
    "r2 = ssr/sst\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2fc644",
   "metadata": {},
   "source": [
    "This tells us that just 59% of the variation of y-values is explained by the line or by variation in x-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497d0895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78921a62",
   "metadata": {},
   "source": [
    "### Performing Linear Regression using OLS() Funtion (Basic usage of StatsModels library)\n",
    "A linear regression model establishes the relation between a dependent variable(y) and at least one independent variable(x).\n",
    " - Step 1: First we define the variables **x** and **y**.\n",
    " - Step 2: The **OLS()** function of the statsmodels.api module is used to perform **OLS regression**. It returns an OLS object. \n",
    " - Step 3: Then **fit()** method is called on this object for fitting the regression line to the data\n",
    " - Step 4: Making Predictions of the Model\n",
    " - Step 5: The **summary()** method is used to obtain a table which gives an extensive description about the regression results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0869b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0226f097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cd7c09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487b445f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb26617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0243f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947ad77c",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section IV: (Linear Transformation and Matrices) </span>\n",
    "<h2 align=\"center\">\"The Matrix is everywhere, it is all around us, even now in this very room.\"</h2>\n",
    "<h4 align=\"right\">-Morpheus-</h4>\n",
    "\n",
    "\n",
    "- Applying Matrices to vectors or other matrices\n",
    "- Affine Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1de0f3-7d20-4405-85e2-3e0e5b8b6d3d",
   "metadata": {},
   "source": [
    "## 1. What do you mean by applying a Matrix to a Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e763bf46",
   "metadata": {},
   "source": [
    "- In this section, we will see, What are linear transformations in 2-Dimensions and how they relate to the idea of matrix vector multiplication.\n",
    "- Transformation is a fancy term for function. In Linear Algebra a transformation is a function that takes a vector as input and give a vector as output.\n",
    "- Why use the term transformation instead of function, if they mean the same thing. This is because when we transform one vector to another, we actually mean moving the input vector to the output vector.\n",
    "- There is a variety of transformations, some of which are quite complex. However, Linear algebra limits itself to a specific type of transformations that are easier to understand called linear transformation\n",
    "- Visually speaking, a transformation is linear if it has two properties:\n",
    "    - Lines remains lines\n",
    "    - Origin remains fixed\n",
    "- You can think of linear transformation as keeping gridlines parallel and evenly spaced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38454c05",
   "metadata": {},
   "source": [
    "## 1. Transformations in Linear Algebra\n",
    "- **Applying a matrix to a vector** (i.e., performing matrix-vector multiplication) can linearly transform the vector, e.g, rotate it or rescale it.\n",
    "- In Linear Algebra Transformation is a function that transforms points from one coordinate system to another.\n",
    "- These transformations can be very simple, such as scaling each coordinate, or complex, such as non-linear twists and bends. Some example transformations are rotation, translation, uniform/nonuniform scaling, shear, projection. \n",
    "- **Hierarchy of Transformations:**\n",
    "    - **Isometric Transformations:** After any of these transformations (rotation/turn, reflection/flip or translation/slide), the shape still has the same size, area, angles and line lengths.\n",
    "    - **Similarity Transformation:** Includes above transformations plus scaling, so after this the object is resized. However, area, angles and line lengths remain same.\n",
    "    - **Affine Transformation** is any transformation that preserves co-linearity (i.e., all points lying on a line initially still lie on a line after transformation) and preserves ratios of distances (e.g., the midpoint of a line segment remains the midpoint after transformation).\n",
    "    - **Projective Transformation** is any transformation (camera image) in which parallelism, lengths and angles are not preserved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a551c01",
   "metadata": {},
   "source": [
    "## 2. Linear Transformations in Two Dimensional Space\n",
    "- A **Linear Transformation** is an affine transformation that converts points from one coordinate system to another by addition and scaling. Scaling, reflection, rotation and shear are all examples of Linear Transformations. \n",
    "- Unlike affine, in linear transformation the origin must be preserved, so translation as well as rotation about an arbitrary point is not a linear transformation.\n",
    "- If you are given a 2x2 matrix and some specific vector and you want to know where that linear transformation will take that vector, you can take the coordinates of that vector, multiply that with the corresponding columns of the matrix and then add them together\n",
    "- Let us practically understand linear transformation by applying a 2-D transformation matrix $A =    \\begin{bmatrix} a_1 & a_2 \\\\  a_3 & a_4  \\end{bmatrix}$ to a 2-D column vector     $\\overrightarrow{v_1} = \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}$:\n",
    "\n",
    "$\\hspace{7 cm}\\overrightarrow{v_2} = A\\overrightarrow{v_1}$\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} a_1 & a_2 \\\\  a_3 & a_4  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "\\hspace{3 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ 1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} a_1 & a_2 & 0 \\\\  a_3 & a_4 & 0 \\\\ 0 & 0 & 1  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ 1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{6 cm}x_2 = a_1x_1 +a_2y_1$\n",
    "\n",
    "$\\hspace{6 cm}y_2 = a_3x_1 +a_4y_1$\n",
    "\n",
    "\n",
    "\n",
    "> The matrix $A$ represents the **linear transformation** that takes vector $\\overrightarrow{v_1} \\hspace{.2 cm}(x_1, y_1)$ and transforms it into $\\overrightarrow{v_2}\\hspace{.2 cm} (x_2, y_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bd5ec5",
   "metadata": {},
   "source": [
    "### a. Applying Identity Matrix:\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{2 cm} x_2 = x_1 + 0 = x_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = 0 + y_1 = y_1$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de159bb-c0f7-4e9e-9194-8b45b31eb17e",
   "metadata": {
    "id": "gLjGas2ij3Ws"
   },
   "source": [
    "**Example:** Apply identity matrix, $I = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2086f5-8470-4763-a0f8-be87627cba3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZvzKGRkj3Ws",
    "outputId": "e4948d7d-0202-4e46-f7a3-cfc7e065e5d9"
   },
   "outputs": [],
   "source": [
    "v1 = np.array([3, 1])\n",
    "I = np.array([[1, 0], [0, 1]])\n",
    "v2 = np.dot(I, v1)\n",
    "\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\")\n",
    "\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply identiy matrix on all points in a 2-D plane\n",
    "I = np.array([[1, 0], [0, 1]])\n",
    "plot_linear_transformation(I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00672cc8",
   "metadata": {},
   "source": [
    "### b. Applying a Scaling Matrix:\n",
    "- Scaling is the process of expanding or compressing the dimensions of an object\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} S_x & 0 \\\\  0 & S_y   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1S_x$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = y_1S_y$\n",
    "\n",
    "- Where $S_x$ is th scaling constant wrt x-direction, and $S_y$ is the scaling constant wrt y-direction.\n",
    "- If $S_x = S_y$, the scaling transformation is said to be homogeneous or uniform\n",
    "- If $S_x \\gt 1$, it is magnification/expansion\n",
    "- If $S_x \\lt 1$, it is reduction/compression\n",
    "- If $S_x = 1$, no effect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d68f722",
   "metadata": {},
   "source": [
    "**Example:** Apply scaling matrix, $A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 4 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6678e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([3, 1])\n",
    "A = np.array([[2, 0], [0, 4]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\")\n",
    "\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply a scaling matrix on all points in a 2-D plane\n",
    "A = np.array([[2, 0], [0, 4]])\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670d786b",
   "metadata": {},
   "source": [
    "### c. Applying a Reflection Matrix:\n",
    "- If either x-axis or y-axis is treated as mirror, the object has a mirror image or reflects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db087bb7",
   "metadata": {},
   "source": [
    "- **Reflection about x-axis:**\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  0 & -1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = -y_1$\n",
    "\n",
    "\n",
    "- **Reflection about y-axis:**\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} -1 & 0 \\\\  0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = -x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = y_1$\n",
    "\n",
    "\n",
    "- **Reflection about Diagonal:**\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} -1 & 0 \\\\  0 & -1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = -x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = -y_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d33f76-4ff3-4835-a650-9b4b5c9ff5ab",
   "metadata": {},
   "source": [
    "**Example:** Apply reflection matrix, $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc04a55-9615-4257-8699-a058a07e7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([3, 2])\n",
    "A = np.array([[1, 0], [0, -1]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply reflection matrix on all points in a 2-D plane\n",
    "A = np.array([[1, 0], [0, -1]])\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9936e3f4",
   "metadata": {},
   "source": [
    "### d. Applying a Shear Matrix:\n",
    "- The Shear transformation cause the object to slant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37edc2e",
   "metadata": {},
   "source": [
    "- **Shear in x-direction:** The x-shear maintains the y-coordinate but changes the x-coordinate, which causes the horizontal lines to tilt up or down\n",
    "$\\hspace{2 cm}\\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \\begin{bmatrix} 1 & s_x \\\\  0 & 1   \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1 + s_x y_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = y_1$\n",
    "\n",
    "\n",
    "- **Shear in y-direction:** The y-shear maintains the x-coordinate but changes the y-coordinate, which causes the vertical lines to tilt up or down\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  s_y & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = S_y x_1 + y_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f66033",
   "metadata": {},
   "source": [
    "**Example:** Apply x-shear matrix, $A = \\begin{bmatrix} 1 & 3 \\\\ 0 & 1 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2, 2])\n",
    "A = np.array([[1, 3], [0, 1]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708e61b",
   "metadata": {},
   "source": [
    "> Since this is x-shear, so it maintains the y-coordinate but changes the x-coordinate, which causes the horizontal lines to tilt up (Give a negative value to check the horizontal lines tilting down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edad17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply x-shear matrix on all points in a 2-D plane\n",
    "A = np.array([[1, 3], [0, 1]])\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6ca1e",
   "metadata": {},
   "source": [
    "### e. Applying a Rotation Matrix:\n",
    "- The process of rotating an object with respect to an angle in a two-dimensional plane is 2D rotation. We accomplish this rotation with the help of a 2 x 2 rotation matrix that has the standard form.\n",
    "- The **counter clockwise rotation matrix** in 2-D is given as:\n",
    "\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} cos\\theta & -sin\\theta  \\\\ sin\\theta & cos\\theta  \\end{bmatrix} $\n",
    "\n",
    "- The **clockwise rotation matrix** in 2-D is given as:\n",
    "\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} cos(-\\theta) & -sin(-\\theta)  \\\\ sin(-\\theta) & cos(-\\theta)  \\end{bmatrix}  = \n",
    "\\begin{bmatrix} cos\\theta & sin\\theta  \\\\ -sin\\theta & cos\\theta  \\end{bmatrix} $\n",
    "\n",
    "- Let us apply a counter clockwise rotation matrix to a 2-D vector:\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} cos\\theta & -sin\\theta  \\\\ sin\\theta & cos\\theta  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1cos\\theta - y_1sin\\theta$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = x_1sin\\theta + y_1cos\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ee0b1",
   "metadata": {},
   "source": [
    "**Example:**  If $\\overrightarrow{v_1} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}$ is rotated in the **counter clockwise direction** by 90 degrees, what are the coordinate values of new vector $\\overrightarrow{v_2}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2, 3])\n",
    "A = np.array([[m.cos(90*m.pi/180), -m.sin(90*m.pi/180)], \n",
    "              [m.sin(90*m.pi/180), m.cos(90*m.pi/180)]\n",
    "             ])\n",
    "v2 = np.dot(A, v1)\n",
    "print(\"Rotation matrix A:\\n\", A)\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation matrix (90 degrees), in counter clockwise direction on all points in a 2-D plane\n",
    "A = np.array([[m.cos(90*m.pi/180), -m.sin(90*m.pi/180)], \n",
    "              [m.sin(90*m.pi/180), m.cos(90*m.pi/180)]\n",
    "             ])\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51607ae4",
   "metadata": {},
   "source": [
    "**Example:**  If $\\overrightarrow{v_1} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}$ is rotated in the **clockwise direction** by 90 degrees, what are the coordinate values of new vector $\\overrightarrow{v_2}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2, 3])\n",
    "A = np.array([[m.cos(90*m.pi/180), m.sin(90*m.pi/180)], \n",
    "              [-m.sin(90*m.pi/180), m.cos(90*m.pi/180)]\n",
    "             ])\n",
    "v2 = np.dot(A, v1)\n",
    "print(\"A:\", A)\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bff67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation matrix (90 degrees), in clockwise direction on all points in a 2-D plane\n",
    "A = np.array([[m.cos(90*m.pi/180), m.sin(90*m.pi/180)], \n",
    "              [-m.sin(90*m.pi/180), m.cos(90*m.pi/180)]\n",
    "             ])\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2e0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation matrix (30 degrees), in counter clockwise direction on all points in a 2-D plane\n",
    "A = np.array([[m.cos(30*m.pi/180), -m.sin(30*m.pi/180)], \n",
    "              [m.sin(30*m.pi/180), m.cos(30*m.pi/180)]\n",
    "             ])\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af31a237",
   "metadata": {},
   "source": [
    "### f. Applying a Translation Matrix:\n",
    "$$\n",
    "\\overrightarrow{v_2} = A\\overrightarrow{v_1} + t\n",
    "$$\n",
    "\n",
    "$$\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  0 & 1  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix} +\n",
    "    \\begin{bmatrix} t_x \\\\ t_y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ 1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\\\ 0 & 0 & 1  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$\\hspace{10 cm}x_2 = x_1 + t_x$\n",
    "\n",
    "$\\hspace{10 cm}y_2 = x_1 + t_y$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4556a46e",
   "metadata": {},
   "source": [
    "### g. Apply Multiple Transformations Simultaneously\n",
    "- A single matrix can apply multiple affine transforms simultaneously. \n",
    "- Let us apply scaling and then rotation on a 2-D plane.\n",
    "- Remember, the order is important, as the output image will be different if you rotate first and then scale.\n",
    "- Let us understand this practically:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373183bb",
   "metadata": {},
   "source": [
    "**Example:** Apply two transformations: Scaling and then rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([[2, 0], [0, 4]])\n",
    "theta = 90*m.pi/180\n",
    "R = np.array([[m.cos(theta), -m.sin(theta)], \n",
    "              [m.sin(theta), m.cos(theta)]\n",
    "             ])\n",
    "print(\"S: \\n\",S)\n",
    "print(\"R: \\n\",R)\n",
    "plot_linear_transformations(S,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear_transformations(R,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938e93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b97b38",
   "metadata": {},
   "source": [
    "## 3. Scaling, Translation and Rotation in Three Dimensional Space\n",
    "- A 3-D Linear Transformation matrix is shown below:<br><br>\n",
    "\n",
    "$\\hspace{3 cm}\n",
    "  A\\hspace{.5 cm}=\\hspace{.5 cm} \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\  a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33}  \\end{bmatrix} \n",
    "  \\hspace{.5 cm}=\\hspace{.5 cm}\n",
    "  \\begin{bmatrix} a_{11} & a_{12} & a_{13} & 0\\\\  a_{21} & a_{22} & a_{23} & 0 \\\\ a_{31} & a_{32} & a_{33}  & 0 \\\\ 0&0&0&1 \\end{bmatrix} \n",
    "$\n",
    "\n",
    "$\\hspace{4 cm}\\overrightarrow{v_2} \\hspace{.5 cm}=\\hspace{.5 cm} A\\overrightarrow{v_1}$\n",
    "\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\z_2\\end{bmatrix} \\hspace{.5 cm}= \\hspace{.5 cm}\n",
    "   \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\  a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1\\end{bmatrix}\n",
    "\\hspace{3 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\ 1\\end{bmatrix} \\hspace{.5 cm}= \\hspace{.5 cm}\n",
    "\\begin{bmatrix} a_{11} & a_{12} & a_{13} & 0\\\\  a_{21} & a_{22} & a_{23} & 0 \\\\ a_{31} & a_{32} & a_{33}  & 0 \\\\ 0&0&0&1 \\end{bmatrix}\n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1\\\\ 1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{2 cm}x_2 = a_{11}x_1 + a_{12}y_1 + a_{13}z_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = a_{21}x_1 + a_{22}y_1 + a_{23}z_1$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = a_{31}x_1 + a_{32}y_1 + a_{33}z_1$\n",
    "\n",
    "\n",
    "> The matrix $A$ represents the **linear transformation** that takes vector $\\overrightarrow{v_1} \\hspace{.2 cm}(x_1, y_1,z_1)$ and transforms it into $\\overrightarrow{v_2}\\hspace{.2 cm} (x_2, y_2, z_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ff562",
   "metadata": {},
   "source": [
    "**3-D Scaling:**<br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} S_x & 0 & 0 & 0\\\\  0 & S_y & 0 & 0 \\\\ 0 & 0 & S_z & 0 \\\\ 0 & 0 & 0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = a_{11}x_1 + a_{12}y_1 + a_{13}z_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = a_{21}x_1 + a_{22}y_1 + a_{23}z_1$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = a_{31}x_1 + a_{32}y_1 + a_{33}z_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9c2e5",
   "metadata": {},
   "source": [
    "**3-D Translation:**<br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 & 0 & t_x\\\\  0 & 1 & 0 & t_y \\\\ 0 & 0 & 1 & t_z \\\\ 0 & 0 & 0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1 + t_x$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = y_1 + t_y$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = z_1 + t_z$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46113d6c",
   "metadata": {},
   "source": [
    "**3-D Counter Clockwise Rotation about Z-axis by an angle $\\theta$:**<br><br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} cos\\theta & -sin\\theta & 0 & 0\\\\  sin\\theta & cos\\theta & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1cos\\theta - y_1sin\\theta$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = x_1sin\\theta + y_1cos\\theta$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = z_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f2c83",
   "metadata": {},
   "source": [
    "**3-D Counter Clockwise Rotation about X-axis by an angle $\\gamma$:**<br><br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 &0 & 0 \\\\ 0 & cos\\gamma & -sin\\gamma & 0 \\\\ 0 & sin\\gamma & cos\\gamma & 0 \\\\ 0 & 0 & 0& 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = y_1cos\\gamma - z_1sin\\gamma$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = y_1sin\\gamma + z_1cos\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309adfb",
   "metadata": {},
   "source": [
    "**3-D Counter Clockwise Rotation about Y-axis by an angle $\\beta$:**<br><br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} cos\\beta & 0 & sin\\beta & 0 \\\\ 0 & 1  & 0 &1 \\\\ -sin\\beta & 0 & cos\\beta & 0 \\\\ 0&0&0&1\\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1cos\\beta + z_1sin\\beta$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = y_1$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = -x_1sin\\beta + z_1cos\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6222d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c581f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715e3294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf33f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ad5992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f096e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bfaac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8d6ed1f",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section V: (Matrix Decomposition) </span>\n",
    "- Eigen Decomposition\n",
    "- Singular Value Decomposition\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eee4a2",
   "metadata": {},
   "source": [
    "## 1. Matrix Decomposition\n",
    "- `Matrix decompositions` are a useful tool for reducing a matrix to their constituent parts in order to simplify a range of more complex operations, similar to decomposing an integer ito its prime factors.\n",
    "- `Matrix decompositions` breaks a matrix into constituent parts to make certain operations on the matrix easier to perform. \n",
    "- There are different types of matrix decompositions like:\n",
    "    - Eigendecomposition. (decompose square matrices only)\n",
    "    - Singular Value Decomposition. (used to decompose rectangular matrices)\n",
    "        - Pesudoinverse\n",
    "    - LU Decomposition\n",
    "    - LR Decomposition.\n",
    "    - QR Decomposition.\n",
    "    - Cholesky Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e65499f",
   "metadata": {},
   "source": [
    "## 2. Eigendecomposition\n",
    "- Eigendecomposition, is perhaps the most commonly used type of matrix decomposition\n",
    "- Eigendecomposition is used to calculate the principal components of a matrix in the Principal Component Analysis method (PCA) that is be used to reduce the dimensionality of data in machine learning.\n",
    "- Eigendecomposition decomposes a `square matrix` into `eigenvectors` and `eigenvalues`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775c4dd6",
   "metadata": {},
   "source": [
    "### a. Eigenvectors and Eigenvalues (An Abstract View) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28448ebe",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen1.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5c7924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39540930",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen2.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb06f6a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "123aba79",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen3.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0584c95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13c9936d",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen4.png\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843180ef",
   "metadata": {},
   "source": [
    "### b. Hands on Code Demo\n",
    "- Eigenvectors are `unit vectors`, which means that their `length` or `magnitude` is equal to `1.0`. They are often referred as right vectors, which simply means a column vector (as opposed to a row vector or a left vector). \n",
    "- Eigenvalues are coefficients applied to eigenvectors that give the vectors their length or magnitude. For example, a negative eigenvalue may reverse the direction of the eigenvector as part of scaling it. A matrix that has only positive eigenvalues is referred to as a `positive definite matrix`, whereas if the eigenvalues are all negative, it is referred to as a `negative definite matrix`.\n",
    "- A vector is an **eigenvector** $v$ of a transformation matrix $A$, such that when it is transformed by the matrix, the product $Av$ has the exact same direction as $v$.\n",
    "- An **eigenvalue** is a scalar quantity (denoted by $\\lambda$) that simply scales the eigenvector $v$ such that the following equation is satisfied: \n",
    "\n",
    "$$\n",
    "Av = \\lambda v\n",
    "$$\n",
    "\n",
    "- The above equation says, that when we apply the transformation matrix $A$ to the eigenvector $v$, that is exactly equal to when we multiply the lambda scalar value to the vector $v$. On one side of equation we are applying a matrix to a vector, while on the other side we are applying a scalar to a vector.\n",
    "- Instead of calculating the eigenvalues and eigenvectors using paper and pencil, let us use the `np.linalg.eig()` method on NumPy to help us out. The method is passed a square transformation matrix and it returns a tuple containing\n",
    "    - A vector of eigenvalues\n",
    "    - A matrix of right eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228d4ce",
   "metadata": {},
   "source": [
    "**Example:** Find the Eigenvalues and Eigenvectors of a random transformation matrix  $A = \\begin{bmatrix} -1 & 4 \\\\ 2 & -2\\end{bmatrix}_{2x2}$, and later verify that the eigenvalues and eigenvectors satisfies the equation $Av = \\lambda v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8605bb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 4], [2, -2]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "\n",
    "# Each column of matrix V will be an eigenvector. Since input matrix A has two columns, therefore, \n",
    "# matrix V will have two eigen vectors, one for each column\n",
    "print(\"Matrix V having two columns/eigenvectors:\\n\", V) \n",
    "\n",
    "# Each eigenvector in matrix V (a column of V) will have a corresponding eigenvalue stored in vector lambdas. \n",
    "# Since matrix V has two columns, therefore, vector lambdas will have two eigenvalues\n",
    "print(\"\\nVector of Eigenvalues corresponding to each Eigenvector: \", lambdas) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f30886",
   "metadata": {},
   "source": [
    ">**Let's confirm that $Av = \\lambda v$ for the first eigenvector:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = V[:,0] #slice the first column from matrix of eigenvectors\n",
    "lamb = lambdas[0] # get the first scalar value from the vector of eigenvalues\n",
    "lhs = np.dot(A, v)\n",
    "rhs = lamb * v\n",
    "print(\"First Eigen vector: \", v)\n",
    "print(\"Eigen value: \", lamb)\n",
    "print(\"Av = \", lhs)\n",
    "print(\"𝜆𝑣 = \", rhs)\n",
    "\n",
    "\n",
    "plot_vector([v])\n",
    "pyplot.title(\"Vector v\");\n",
    "plot_vector([lhs])\n",
    "pyplot.title(\"Vector Av\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd2e37",
   "metadata": {},
   "source": [
    "Note that the first eigenvector $v$ of transformation matrix $A$ maintains exactly the same direction after the matrix is applied to it. Its length has increased which corresponds exactly to its eigenvalue and that is 1.37"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95df616",
   "metadata": {},
   "source": [
    ">**Let's confirm that $Av = \\lambda v$ for the second eigenvector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f1a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = V[:,1] #slice the second column from matrix of eigenvectors\n",
    "lamb = lambdas[1] # get the second scalar value from the vector of eigenvalues\n",
    "lhs = np.dot(A, v)\n",
    "rhs = lamb * v\n",
    "print(\"Second Eigen vector: \", v)\n",
    "print(\"Eigen value: \", lamb)\n",
    "print(\"Av = \", lhs)\n",
    "print(\"𝜆𝑣 = \", rhs)\n",
    "\n",
    "\n",
    "plot_vector([v])\n",
    "pyplot.title(\"Vector v\");\n",
    "plot_vector([lhs])\n",
    "pyplot.title(\"Vector Av\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a821fef",
   "metadata": {},
   "source": [
    "Note that the second eigenvector $v$ of transformation matrix $A$ is in the second quadrant. Once we apply the transformation matrix its direction becomes exactly opposite. Moreover, it's length has increased more than 4 times, and that corresponds exactly to its eigenvalue and that is -4.37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7ffcf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6844b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a0c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617aa19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bf56b44",
   "metadata": {},
   "source": [
    "### c. Eigenvectors for a 3 Dimensional Matrix\n",
    "- Let us now compute the three eigenvectors and the three corresponding eigenvalues for a 3-D matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d0b35",
   "metadata": {},
   "source": [
    "**Example:** Find the Eigenvalues and Eigenvectors of a random transformation matrix  $A = \\begin{bmatrix} 25 & 2 & 9 \\\\ 5 & 26 & -5 \\\\ 3 & 7 & -1\\end{bmatrix}_{3x3}$, and later verify that the eigenvalues and eigenvectors satisfies the equation $Av = \\lambda v$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be7589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[25, 2, 9], [5, 26, -5], [3, 7, -1]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "\n",
    "# Each column of matrix V will be an eigenvector. Since input matrix A has two columns, therefore, \n",
    "# matrix V will have two eigen vectors, one for each column\n",
    "print(\"Matrix V having three columns/eigenvectors:\\n\", V) \n",
    "\n",
    "# Each eigenvector in matrix V (a column of V) will have a corresponding eigenvalue stored in vector lambdas. \n",
    "# Since matrix V has two columns, therefore, vector lambdas will have two eigenvalues\n",
    "print(\"\\nVector of Eigenvalues corresponding to each Eigenvector: \", lambdas) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1937e296",
   "metadata": {},
   "source": [
    ">**Let's confirm that $Av = \\lambda v$ for the first eigenvector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96615d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = V[:,0] #slice the first column from matrix of eigenvectors\n",
    "lamb = lambdas[0] # get the first scalar value from the vector of eigenvalues\n",
    "lhs = np.dot(A, v)\n",
    "rhs = lamb * v\n",
    "print(\"First Eigen vector: \", v)\n",
    "print(\"Eigen value: \", lamb)\n",
    "print(\"Av = \", lhs)\n",
    "print(\"𝜆𝑣 = \", rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea34a34b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a447e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47f94e86",
   "metadata": {
    "id": "d2MIHl4MLWw0"
   },
   "source": [
    "### d. Determinants & Eigenvalues\n",
    "#### (i) Relationship between Determinant and Eigenvalues of a Matrix\n",
    "- There exist a very simple relationship between determinant of a matrix and its eigenvalues, and that is the determinant of some matrix $A$ is equal to the product of all eigenvalues of $A$:\n",
    "$$\n",
    "det(A) \\hspace{.4 cm}=\\hspace{.4 cm} Product \\hspace{.2 cm}of \\hspace{.2 cm}all \\hspace{.2 cm}eigenvalues\\hspace{.2 cm} of\\hspace{.2 cm} A\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 4], [2, -1, 3], [0, 5, 1]])\n",
    "det = np.linalg.det(A)\n",
    "print(\"Matrix A :\\n\", A)\n",
    "print(\"\\ndet(A) = \", det)\n",
    "\n",
    "\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"\\nThe three eigenvalues are:\", lambdas)\n",
    "rhs = np.product(lambdas)\n",
    "print(\"\\nProduct of three eigenvalues are: \", rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4198e73",
   "metadata": {
    "id": "Rf83gqIULWw2"
   },
   "source": [
    "#### (ii) Impact of different values of Determinant of a Transformation Matrix\n",
    "- Let us now develop a geometric intitution ragarding the relationship between the determinant and eigenvalues:\n",
    "\n",
    "$$\n",
    "|det(A)| \\hspace{.3 cm}quantifies\\hspace{.3 cm}volume\\hspace{.3 cm}change \\hspace{.3 cm}as \\hspace{.3 cm}a\\hspace{.3 cm}result\\hspace{.3 cm} of\\hspace{.3 cm}applying\\hspace{.3 cm}matrix\\hspace{.3 cm}A\\hspace{.3 cm}to \\hspace{.3 cm}some\\hspace{.3 cm}vector\n",
    "$$\n",
    "\n",
    "- If $|det(A)| = 0$, then $A$ collapses all volume of the vector/tensor it is applied to\n",
    "- If $0 \\lt |det(A)| \\gt 0$, then $A$ contracts some of the volume of the vector/tensor it is applied to\n",
    "- If $|det(A)| = 1$, then $A$ preserves the volume of the vector/tensor it is applied to\n",
    "- If $|det(A)| \\gt 1$, then $A$ expands the volume of the vector/tensor it is applied to"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c5b35",
   "metadata": {
    "id": "6zNOgq7I62YA"
   },
   "source": [
    "Here's $|\\text{det}(X)|$ in NumPy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b2cf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 4], [2, -1, 3], [0, 5, 1]])\n",
    "det = np.linalg.det(A)\n",
    "det = np.abs(det)\n",
    "det"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13730639",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7Bleu07j3X-",
    "outputId": "0d8a701b-d685-4b45-d2f4-4e751323f1e1"
   },
   "source": [
    ">Since $|det(A)| = 20$, which is ofcourse greater than 1. This means that applying the matrix $A = \\begin{bmatrix} 1 & 2 & 4 \\\\ 2 & -1 & 3 \\\\ 0 & 5 & 1\\end{bmatrix}$ on a vector/tensor will have the impact of increasing the volume of the vector/tensor by 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e01393",
   "metadata": {
    "id": "KZQaYZ0q7Zn2"
   },
   "source": [
    "Let's use a matrix $B$, which is composed of basis vectors, to explore the impact of applying matrices with varying $|\\text{det}(X)|$ values: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8e7571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9689d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0e90aef",
   "metadata": {},
   "source": [
    "**Example:** Given a matrix  $A = \\begin{bmatrix} -4 & 1 \\\\ -8 & 2\\end{bmatrix}$, compute its determinant. Later apply matrix $A$ on a matrix $B = \\begin{bmatrix} 1 & 0\\\\ 0 & 1\\end{bmatrix}$ and compare the volume of $B$ with the output matrix $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239aecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-4, 1], [-8, 2]])\n",
    "det = np.linalg.det(A)\n",
    "det = np.abs(det)\n",
    "print(\"Matrix A: \\n\", A)\n",
    "print(\"det(A): \", det)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bde2713",
   "metadata": {},
   "source": [
    ">- Note the matrix $A$ is having a determinant of zero, so it is a singular matrix, since its columns are dependent. We can multiply second column by -4 to get the first column.\n",
    ">- Let us now geometrically visualize matrix $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c02b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[1, 0], [0, 1]])\n",
    "vectors = [(B[0,0],B[1,0]), (B[0,1],B[1,1])]\n",
    "tails   = [(0,0), (0,0)]\n",
    "plot_vector(vectors, tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5701b05a",
   "metadata": {},
   "source": [
    ">- Note the volume of the two basis vecotrs in matrix $B$ that makes a square is 1.\n",
    ">- Let us now apply the matrix $A$ on matrix $B$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88cc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.dot(A, B)\n",
    "print(\"np.dot(A,B):\\n\", C)\n",
    "vectors = [(C[0,0],C[1,0]), (C[0,1],C[1,1])]\n",
    "tails   = [(0,0), (0,0)]\n",
    "plot_vector(vectors, tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934393fe",
   "metadata": {},
   "source": [
    ">- Since $|det(A)| = 0$, i.e., it is a singular matrix. So when we apply matrix $A$ on matrix $B$, we get a flat line and the volume is collapsed to zero.\n",
    ">- Let us now see if the product of the eigenvalues of $A$ is also zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386d1a7f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ErYF2Ss5zZj",
    "outputId": "f3480d94-d262-4501-d513-94d79f2bd7e0"
   },
   "outputs": [],
   "source": [
    "lambdas, V = np.linalg.eig(A)\n",
    "lambdas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d0d7ec",
   "metadata": {
    "id": "TLwFZuuN8L78"
   },
   "source": [
    ">- If any one of a matrix's eigenvalues is zero, then the product of the eigenvalues must be zero and the determinant must also be zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf39c62",
   "metadata": {},
   "source": [
    "**Example:** Given a matrix  $A = \\begin{bmatrix} -0.5 & 0 \\\\ 0 & 2\\end{bmatrix}$, compute its determinant. Later apply matrix $A$ on a matrix $B = \\begin{bmatrix} 1 & 0\\\\ 0 & 1\\end{bmatrix}$ and compare the volume of $B$ with the output matrix $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54873c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-0.5, 0], [0, 2]])\n",
    "det = np.linalg.det(A)\n",
    "det = np.abs(det)\n",
    "print(\"Matrix A: \\n\", A)\n",
    "print(\"det(A): \", det)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc672aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.array([[1, 0], [0, 1]])\n",
    "print(\"Matrix B:\\n\", B)\n",
    "vectors = [(B[0,0],B[1,0]), (B[0,1],B[1,1])]\n",
    "tails   = [(0,0), (0,0)]\n",
    "plot_vector(vectors, tails)\n",
    "\n",
    "\n",
    "C = np.dot(A, B)\n",
    "print(\"np.dot(A,B):\\n\", C)\n",
    "vectors = [(C[0,0],C[1,0]), (C[0,1],C[1,1])]\n",
    "tails   = [(0,0), (0,0)]\n",
    "plot_vector(vectors, tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8c56f8",
   "metadata": {},
   "source": [
    ">- Note the vector $(1,0)$ is transformed to $(-0.5, 0)$, while the vector $(0, 1)$ is transformed to $(0,2)$. Moreover, both the basis vectors are infact eigenvectors of the matrix $A$, because they remains on their spans, although scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f908852",
   "metadata": {},
   "source": [
    "**Example:** Given a matrix  $A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 2\\end{bmatrix}$, compute its determinant. Later apply matrix $A$ on a matrix $B = \\begin{bmatrix} 1 & 0\\\\ 0 & 1\\end{bmatrix}$ and compare the volume of $B$ with the output matrix $C$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d396f101",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 0], [0, 2]])\n",
    "det = np.linalg.det(A)\n",
    "det = np.abs(det)\n",
    "print(\"Matrix A: \\n\", A)\n",
    "print(\"det(A): \", det)\n",
    "\n",
    "B = np.array([[1, 0], [0, 1]])\n",
    "print(\"\\nMatrix B:\\n\", B)\n",
    "vectors = [(B[0,0],B[1,0]), (B[0,1],B[1,1])]\n",
    "tails   = [(0,0), (0,0)]\n",
    "plot_vector(vectors, tails)\n",
    "\n",
    "\n",
    "C = np.dot(A, B)\n",
    "print(\"np.dot(A,B):\\n\", C)\n",
    "vectors = [(C[0,0],C[1,0]), (C[0,1],C[1,1])]\n",
    "tails   = [(0,0), (0,0)]\n",
    "plot_vector(vectors, tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49baab69",
   "metadata": {
    "id": "b1KENtMQ9g4g"
   },
   "source": [
    ">- This time the matrix $A$, when applied on matrix $B$ has scaled both its vectors by doubling along both the $x$ and $y$ axes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec67f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cfc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82c3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d7b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f228a812",
   "metadata": {
    "id": "MXNajp3Ej3Yb"
   },
   "source": [
    "## 6. Eigendecomposition of a Matrix and its Applications in Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906056f0",
   "metadata": {
    "id": "wQt403xbj3Yb"
   },
   "source": [
    "- An eigendecomposition is calculated on a square matrix using an efficient iterative algorithm, of which we will not go into the details. Often an eigenvalue is found first, then an eigenvector is found to solve the equation as a set of coefficients. \n",
    "- The eigendecomposition can be calculated in NumPy using the `eig()` function. The example below first defines a 3 × 3 square matrix. The eigendecomposition is calculated on the matrix returning the eigenvalues and eigenvectors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- The decomposition of a matrix into eigenvectors and eigenvalues reveils characteristics of the matrics, e.g., \n",
    "    - The matrix is singular, if and only if any of its eigenvalues are zero.\n",
    "    - Under specific conditions, can optimize quadratic expressions using eigenvalues\n",
    "        - Maximum of $f(x) = $ Largest eigenvalue\n",
    "        - Minimum of $f(x) = $ Smallest eigenvalue\n",
    "\n",
    "- The **eigendecomposition** of some matrix $A$ is \n",
    "\n",
    "$$\n",
    "A = V \\Lambda V^{-1}\n",
    "$$\n",
    "\n",
    "- Where,\n",
    "    - $V$ is a matrix comprised of the `eigenvectors` of matrix $A$, \n",
    "    - Uppercase lambda (Λ) is the diagonal matrix comprised of the `eigenvalues` of matrix $A$\n",
    "    - $V^{-1}$ is the inverse of the matrix comprised of the eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bcc68b",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A = \\begin{bmatrix} 4 & 2\\\\ -5 & -3\\end{bmatrix}$, decompose it using eigendecomposition, and later prove that the equation $A = V \\Lambda V^{-1}$ holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate matrix V containing the eigenvectors of matrix A\n",
    "A = np.array([[4, 2], [-5, -3]]) \n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"\\nThe matrix V contains two Eigenvectors:\\n\", V)\n",
    "print(\"\\nThe two eigenvalues are:\", lambdas)\n",
    "\n",
    "\n",
    "# Now, create the matrix Λ, which is the diagonal matrix of eigenvalues\n",
    "Lambda = np.diag(lambdas)\n",
    "print(\"\\nUppercase Lambda:\\n\", Lambda)\n",
    "\n",
    "# Now calculate inverse of matrix V\n",
    "Vinv = np.linalg.inv(V)\n",
    "print(\"\\nInverse of V:\\n\", Vinv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20051d6",
   "metadata": {
    "id": "KSBnzTBZj3Yg"
   },
   "source": [
    "- Now we have all the components of R.H.S of the equation. So we can confirm that $A = V \\Lambda V^{-1}$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b2dd3e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pG1E3yLYj3Yg",
    "outputId": "d0d5f55d-ad40-468e-9b59-b01544169863"
   },
   "outputs": [],
   "source": [
    "np.dot(V, np.dot(Lambda, Vinv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4691911",
   "metadata": {},
   "source": [
    ">This is the original matrix $A$, and this is what eigendecomposition is :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620ce1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0592b28",
   "metadata": {},
   "source": [
    "**Example** Given the matrix $A = \\begin{bmatrix} 1 & 2 & 3\\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9\\end{bmatrix}$. Calculate its eigenvectors and eigenvalues. Later checkout that given the eigenvectors and eigenvalues of a matrix, can you reconstruct the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6104e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate eigenvectors and eigenvalues\n",
    "A = np.array([[1,2,3], [4,5,6],[7,8,9]]) \n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"\\nThe matrix V contains three Eigenvectors:\\n\", V)\n",
    "print(\"\\nThe three eigenvalues are:\", lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e419e8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the original matrix from its eigenvectors in matrix V and eigenvalues in vector lambdas\n",
    "Lambda = np.diag(lambdas)\n",
    "Qinv = np.linalg.inv(Q)\n",
    "B = np.dot(Q, np.dot(Lambda, Qinv))\n",
    "print(\"Original Matrix:\\n\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fabefdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cc7fc0d",
   "metadata": {},
   "source": [
    "### a. An Efficient Eigendecomposition Equation\n",
    "- Eigendecomposition is not possible with all matrices. \n",
    "- With matrices involving complex numbers, we have to use the above technique, i.e., $A = V \\Lambda V^{-1}$\n",
    "- In machine learning, however, we are typically working with real symmetric matrices, which can be conveniently and efficiently decomposed into real-only eigenvectors and real-only eigenvalues using the following formula, that use transpose instead of inverse:\n",
    "\n",
    "$$A = Q \\Lambda Q^T$$\n",
    "\n",
    "- Where,\n",
    "    - $Q$ is a matrix comprised of the `eigenvectors` of matrix $A$, \n",
    "    - Uppercase lambda (Λ) is the diagonal matrix comprised of the `eigenvalues` of matrix $A$\n",
    "    - $Q^T$ is the transpose of the matrix comprised of the eigenvectors\n",
    "\n",
    "\n",
    "- The $A = Q \\Lambda Q^T$ is far more efficient than $A = V \\Lambda V^{-1}$, as computing transpose of a matrix is far more cheap than computing the inverse. \n",
    "- The only requirement is that the matrix $A$ need to be a real symmetric matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d44d30",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A = \\begin{bmatrix} 2 & 1\\\\ 1 & 2\\end{bmatrix}$, prove that the equation $A = Q \\Lambda Q^T$ holds true. Finally, also prove that Q is an orthogonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbb82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First calculate matrix Q containing the eigenvectors of matrix A\n",
    "A = np.array([[2, 1], [1, 2]]) \n",
    "lambdas, Q = np.linalg.eig(A)\n",
    "print(\"\\nThe matrix Q contains two Eigenvectors:\\n\", Q)\n",
    "print(\"\\nThe two eigenvalues are:\", lambdas)\n",
    "\n",
    "# Now, create the matrix Λ, which is the diagonal matrix of eigenvalues\n",
    "Lambda = np.diag(lambdas)\n",
    "print(\"\\nUppercase Lambda:\\n\", Lambda)\n",
    "\n",
    "# Now calculate transpose of matrix Q\n",
    "Qt = Q.T\n",
    "print(\"\\nTranspose of Q:\\n\", Qt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8248def",
   "metadata": {},
   "source": [
    "- Now we have all the components of R.H.S of the equation. So we can confirm that $A = Q \\Lambda Q^T$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f968057e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k4DukMWJj3Yo",
    "outputId": "3f63b1df-262d-4391-8441-a768428e63f2"
   },
   "outputs": [],
   "source": [
    "np.dot(Q, np.dot(Lambda, Q.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6a7e5",
   "metadata": {},
   "source": [
    "- Finally let us demonstrate that $Q$ is an orthogonal matrix because $Q^TQ = QQ^T = I$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22450b46",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TcavBhdEj3Ym",
    "outputId": "b70d091a-811d-41cd-a3aa-5df504445da4"
   },
   "outputs": [],
   "source": [
    "np.dot(Q.T, Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b04d391",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xup113b8j3Yo",
    "outputId": "4a2bc99b-af0f-4ebb-83db-1c6c1accc449"
   },
   "outputs": [],
   "source": [
    "np.dot(Q, Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96087580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47ffc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5418b78b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98ccb8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e9a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c2c2ed6",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section VI: (Matrix Operations for Machine Learning) </span>\n",
    "- Singular Value Decomposition (SVD)\n",
    "- The Moore-Penrose Pseudoinverse (empower us to invert non square matrices)\n",
    "- Pseudoinverse to Solve for unknowns in linear system of equations\n",
    "- Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7085d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as m\n",
    "from numpy.linalg import norm\n",
    "from matplotlib import pyplot as plt\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38938954",
   "metadata": {
    "id": "j-wbn7omj3Yr"
   },
   "source": [
    "## 1. Singular Value Decomposition (SVD)\n",
    "- Like other decomposition techniques, Singular Value Decomposition (SVD) is a matrix decomposition technique for `reducing a matrix to its constituent parts` in order to make certain subsequent matrix calculations `simpler`. \n",
    "- Unlike eigendecomposition, which is applicable to square matrix only, Singular Value Decomposition works for rectangular matrices as well.\n",
    "- Unlike eigendecomposition, all matrices have an SVD, which makes it more stable. \n",
    "- SVD decomposes a matrix into:\n",
    "    - Singular vectors (analogous to eigenvectors)\n",
    "    - Singular values (analogous to eigenvalues)\n",
    "    \n",
    "$$A = UDV^T$$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $A$ is the real $m \\times n$ matrix; matrix that we wish to decompose.\n",
    "* $U$ is an orthogonal $m \\times m$ matrix; its columns are the **left-singular vectors** of $A$.\n",
    "* $V$ is an orthogonal $n \\times n$ matrix; its columns are the **right-singular vectors** of $A$.\n",
    "* $D$ is a diagonal $m \\times n$ matrix; elements along its diagonal are the **singular values** of $A$ (one singular value per column).\n",
    "  \n",
    "- The SVD is calculated via iterative numerical methods. We will not go into the details of these methods. Every rectangular matrix has a singular value decomposition, although the resulting matrices may contain complex numbers and the limitations of floating point arithmetic may cause some matrices to fail to decompose neatly.            \n",
    "            \n",
    "- The singular value decomposition (SVD) has numerous applications in statistics, machine learning, and computer science i.e., such as `matrix inverse`, `data reduction`,  `least squares linear regression`, `image compression`, and `denoising data`. Applying the SVD to a matrix is like looking inside it with X-ray vision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0d976a",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A = \\begin{bmatrix} 1 & 2\\\\ 3 & 4\\\\5 & 6\\end{bmatrix}$, decompose it using SVD, and later prove that the equation $A = UDV^T$ holds true by reconstructing the matrix $A$ from its SVD constituent parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97df161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "#use svd() method\n",
    "U, d, VT = np.linalg.svd(A) # V is already transposed\n",
    "print(\"The input matrix A(3x2):\\n\", A)\n",
    "print(\"The matrix U (3x3), containing three left singular vectors of matrix A:\\n\", U)\n",
    "print(\"The matrix VT (2x2) containing two right singular vectors of matrix A:\\n\", VT)\n",
    "print(\"The vector d (of length 2): \", d)\n",
    "\n",
    "D = np.diag(d)\n",
    "print(\"The matrix D:\\n\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8875496d",
   "metadata": {},
   "source": [
    "- Now we have all the components of R.H.S of the equation: $A = UDV^T$. \n",
    "- However, $D$ must have the same dimensions as $A$, i.e., $3 \\times 2$, to carry out the multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa8db5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V47I3B87j3Y0",
    "outputId": "52643cfa-80ad-476b-d7da-10a66dd15ad9"
   },
   "outputs": [],
   "source": [
    "D = np.concatenate((D, [[0, 0]]), axis=0)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6485c3fc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9euCs5vvj3Y2",
    "outputId": "15771a45-e87e-4b9d-8a73-521e89818b2a"
   },
   "outputs": [],
   "source": [
    "np.dot(U, np.dot(D, VT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff77ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4c0197",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0417825b",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A = \\begin{bmatrix} 1 & 2 & 3\\\\ 4 & 5 & 6\\\\7 & 8 & 9\\end{bmatrix}$, decompose it using SVD, and later prove that the equation $A = UDV^T$ holds true by reconstructing the matrix $A$ from its SVD constituent parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94f260f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([ [1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "#use svd() method\n",
    "U, d, VT = np.linalg.svd(A) # V is already transposed\n",
    "print(\"The input matrix A(3x3):\\n\", A)\n",
    "print(\"The matrix U (3x3), containing three left singular vectors of matrix A:\\n\", U)\n",
    "print(\"The matrix VT (3x3) containing two right singular vectors of matrix A:\\n\", VT)\n",
    "print(\"The vector d (of length 3): \", d)\n",
    "\n",
    "D = np.diag(d)\n",
    "print(\"The matrix D:\\n\", D)\n",
    "\n",
    "\n",
    "B = np.dot(U, np.dot(D, VT))\n",
    "print(\"Original matrix reconstructed: \\n\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6633c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233b4800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40c1257b",
   "metadata": {},
   "source": [
    "**Example (Image Compression via SVD):** Read a colour image convert it into grey scale and compress it using SVD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "rgb_img = Image.open(\"datasets/img.jpg\")\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(rgb_img);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3c8cad",
   "metadata": {},
   "source": [
    "Let us convert image to grayscale so that we don't have to deal with the complexity of multiple color channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09e31a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = rgb_img.convert('L')\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(gray_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b71b5b",
   "metadata": {
    "id": "eVwgrA0Jj3Y9"
   },
   "source": [
    "Convert data into numpy matrix, which doesn't impact image data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58600563",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_matrix = np.array(gray_img)\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(img_matrix, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce8177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afabf25",
   "metadata": {
    "id": "x8VCD3lyj3Y-"
   },
   "source": [
    "Calculate SVD of the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be122ca3",
   "metadata": {
    "id": "kbBLn2Csj3Y-"
   },
   "outputs": [],
   "source": [
    "U, sigma, V = np.linalg.svd(img_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bba0d4",
   "metadata": {
    "id": "ApybkCdLj3Y-"
   },
   "source": [
    "As eigenvalues are arranged in descending order in diag($\\lambda$) so too are singular values, by convention, arranged in descending order in $D$ (or, in this code, diag($\\sigma$)). Thus, the first left-singular vector of $U$ and first right-singular vector of $V$ may represent the most prominent feature of the image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a132de2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "rZTwlhGxj3Y_",
    "outputId": "bbabb61f-17ac-4e73-b1e2-10754c9dc100"
   },
   "outputs": [],
   "source": [
    "new_img = np.matrix(U[:, :1]) * np.diag(sigma[:1]) * np.matrix(V[:1, :])\n",
    "fig = plt.figure(figsize=(3, 3))\n",
    "plt.imshow(new_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd7480c",
   "metadata": {
    "id": "4p2cEqIoj3Y_"
   },
   "source": [
    "Additional singular vectors improve the image quality: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ef215",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f5-6LEbij3ZA",
    "outputId": "c0504b84-9b7b-4ee7-86c7-0dcbefdcdc86"
   },
   "outputs": [],
   "source": [
    "for i in [2, 4, 8, 16, 32, 64]:\n",
    "    new_img = np.matrix(U[:, :i]) * np.diag(sigma[:i]) * np.matrix(V[:i, :])\n",
    "    fig = plt.figure(figsize=(2, 2))\n",
    "    val = \"n = %s\" % i\n",
    "    plt.title(val)\n",
    "    plt.imshow(new_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767e1f2",
   "metadata": {
    "id": "IjfUJ4wNj3ZA"
   },
   "source": [
    "With 64 singular vectors, the image is reconstructed quite well, however the data footprint is much smaller than the original image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469fb466",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hXQy4TzCj3ZB",
    "outputId": "c8a9c18c-a070-4dbc-9f6b-003492db1f06"
   },
   "outputs": [],
   "source": [
    "img_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8b6ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXJtpYGeLWxz",
    "outputId": "7e994526-5509-4ab4-bd1c-0b6f4c2b318c"
   },
   "outputs": [],
   "source": [
    "full_representation = 1786*2880\n",
    "full_representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a2de8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOHZXITLLWx1",
    "outputId": "6780de62-ccfd-4936-f0cb-172c2e178db4"
   },
   "outputs": [],
   "source": [
    "svd64_rep = 64*1786 + 64 + 64*2880\n",
    "svd64_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1f6a9f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YwdA6taLj3ZD",
    "outputId": "0dfe0239-d22e-4b54-ca53-3fc07b24ecc8"
   },
   "outputs": [],
   "source": [
    "svd64_rep/full_representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8824c5f2",
   "metadata": {
    "id": "_HdtL8p7j3ZD"
   },
   "source": [
    "Specifically, the image represented as 64 singular vectors is 5.8% of the size of the original! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3632c581",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "178b8110",
   "metadata": {},
   "source": [
    "### a. Calculate Pseudoinverse of a non-Square Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25527425",
   "metadata": {
    "id": "q4_MX4D5j3ZE"
   },
   "source": [
    "- One of the ways is to use Moore-Penrose Pseudoinverse.\n",
    "- The formula to calculate the pseudoinverse $A^+$ of some matrix $A$ is:\n",
    "$$A^+ = VD^+U^T$$\n",
    "\n",
    "Where: \n",
    "\n",
    "* $U$, $D$, and $V$ are SVD of matrix $A$.\n",
    "* $D^+ = $($D$ wit reciprocal of all non-zero elements)$^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c298e0ec",
   "metadata": {},
   "source": [
    "**Example:** Given a non-square matrix $A = \\begin{bmatrix} -1 & 2\\\\ 3 & -2\\\\5 & 7\\end{bmatrix}$. Calculate its Pseudoinverse using the formula $A^+ = VD^+U^T$, later compare your result by computing pseudoinverse of $A$ using `np.linalg.pinv(A)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea7f3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 2], [3, -2], [5, 7]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca841c60",
   "metadata": {},
   "source": [
    "- Following line will generate an error, as you cannot generate the multiplicative inverse of a matrix if:\n",
    "    - The matrix is not square\n",
    "    - The determinant of matrix is zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa428ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.linalg.inv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be4ddf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gbbiRcmzj3ZE",
    "outputId": "ed37e9e2-23b7-4246-8a19-7b50ced837cf"
   },
   "outputs": [],
   "source": [
    "A = np.array([[-1, 2], [3, -2], [5, 7]])\n",
    "#use svd() method\n",
    "U, d, VT = np.linalg.svd(A) # NumPy SVD method returns U, d, and transpose of V:\n",
    "print(\"The input matrix A(3x2):\\n\", A)\n",
    "print(\"The matrix U (3x3), containing three left singular vectors of matrix A:\\n\", U)\n",
    "print(\"The matrix VT (2x2) containing two right singular vectors of matrix A:\\n\", VT)\n",
    "print(\"The vector d (of length 2): \", d)\n",
    "\n",
    "D = np.diag(d)\n",
    "print(\"The matrix D:\\n\", D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0489087a",
   "metadata": {
    "id": "7yalmt19j3ZI"
   },
   "source": [
    "To create $D^+$, we need to invert the non-zero values of matrix $D$, and then take transpose of resulting matrix: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12cd308",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6O2LADtLj3ZJ",
    "outputId": "2cba2b81-e322-46c9-c914-68ec3b84ea39"
   },
   "outputs": [],
   "source": [
    "1/8.669"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ca85c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1ZbYtmIj3ZJ",
    "outputId": "5df71298-4522-481a-e7f9-c8d2e57729db"
   },
   "outputs": [],
   "source": [
    "1/4.104"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529c3974",
   "metadata": {
    "id": "yO1tNES9j3ZK"
   },
   "source": [
    "Since, $D$ is a diagonal matrix, we can do this by simpling inverting matrix $D$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac01bdd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y0sjcP3Ej3ZK",
    "outputId": "8b6588b0-a8a4-4764-f927-e3817e58ff1b"
   },
   "outputs": [],
   "source": [
    "Dinv = np.linalg.inv(D)\n",
    "Dinv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef69e1a",
   "metadata": {},
   "source": [
    "$D^+$ must have the same dimensions as $A^T$ in order for $VD^+U^T$ matrix multiplication to be possible, and that is 2 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b6df18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ydq0zJHNRZPy",
    "outputId": "389d0c75-984d-4f85-a8a1-e054f3d6d4ca"
   },
   "outputs": [],
   "source": [
    "Dplus = np.concatenate((Dinv, np.array([[0, 0]]).T), axis=1)\n",
    "Dplus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a121b22e",
   "metadata": {
    "id": "6Xt4NYHuj3ZO"
   },
   "source": [
    "Now we have everything we need to calculate $A^+$ with $VD^+U^T$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a946fa0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZtWN_wnij3ZO",
    "outputId": "14912908-896a-4b0e-c9b1-4bc3e8a17f32"
   },
   "outputs": [],
   "source": [
    "np.dot(VT.T, np.dot(Dplus, U.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df904916",
   "metadata": {
    "id": "3syT7-hCj3ZP"
   },
   "source": [
    "Let us now verify our working, and compute the Pseudoinverse of matrix $A$ using `np.linalg.pinv()` method of numPy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2b3799",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fh0nDMeLj3ZP",
    "outputId": "9178720c-7e4d-4ea7-98b2-500c5ba24a39"
   },
   "outputs": [],
   "source": [
    "np.linalg.pinv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3274959a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27649682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ce3a5af",
   "metadata": {},
   "source": [
    "**Example:** Given a singular matrix $A = \\begin{bmatrix} 2 & 4\\\\ 6 & 12\\end{bmatrix}$. See if you can calculate its inverse. If not why not? Then see if its Pseudoinverse exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 4], [6, 12]])\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d077ce6",
   "metadata": {},
   "source": [
    "> Above matrix $A$ is a square matrix, let us calculate its determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271122b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.det(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c75c908",
   "metadata": {},
   "source": [
    "> Since $det(A) = 0$, that means it is a singular matrix. This can also be observed from matrix data, as the columns are linearly dependent. i.e., we can get the second column by multiplying the first column by 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567cf1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ainv = np.linalg.inv(A)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe657b0",
   "metadata": {},
   "source": [
    "> If we execute the above line we get an error saying that you cannot compute the inverse of a singular matrix.\n",
    "> However, we can calculate the **pseudoinverse** of a singular matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7963c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.pinv(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a3c600",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72d3dc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac036d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb3bbeae",
   "metadata": {},
   "source": [
    "### b. Apply Pseudoinverse to Solve a System of Linear Equation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae3271",
   "metadata": {},
   "source": [
    "**Example 1:** Given an overdetermined system having three linear equations with two unknowns. Draw the graph of three lines and see if the three lines intersect at one point. If the system is overdetermined, Find Least Squares Solution using paper pencil.\n",
    "$$-x +y =0$$\n",
    "$$y=1$$\n",
    "$$x+y=2$$\n",
    "$$2x+y=1$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc137b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "x = np.linspace(-20, 20, 100) # start, finish, n points\n",
    "y1 = x\n",
    "y2 = 0*x + 1\n",
    "y3 = -x + 2\n",
    "y3 = -2*x + 1\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-5, 5])\n",
    "ax.set_ylim([0, 5])\n",
    "#ax.plot(t, d1, c='green')\n",
    "#ax.plot(t, d2, c='red')\n",
    "ax.plot(x, y1, c='green')\n",
    "ax.plot(x, y2, c='red')\n",
    "ax.plot(x, y3, c='blue')\n",
    "ax.plot(x, y4, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27247ece",
   "metadata": {},
   "source": [
    "> The system is overdetermined and inconsistent. However, we need to find x and y using least square solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b952ec8",
   "metadata": {},
   "source": [
    "$$-x +y =0$$\n",
    "$$0x + y=1$$\n",
    "$$x+y=2$$\n",
    "$$2x+y=1$$\n",
    "\n",
    "- From the four equations create the matrix equation\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbebf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2])       \n",
    "y = np.array([0, 1, 2, 1])  \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-2, 3])\n",
    "ax.scatter(x,y);\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ad6f66",
   "metadata": {},
   "source": [
    "$$Ax = b$$\n",
    "\n",
    "$$A^TAx = A^Tb $$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 0 & 1 & 2 \\\\  1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} -1 & 0 & 1 & 2 \\\\  1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 \\\\  2 & 4  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff51723",
   "metadata": {},
   "source": [
    "**Option 1:**\n",
    "- Rewrite, above matrix equation:\n",
    "$$6m + 2c  = 4 $$\n",
    "$$2m + 4c = 4$$\n",
    "\n",
    "- Now this is a system of linear equation in which the number of equations is equal to the number of unknowns, so you can solve it using substitution or elimination method and you get the slope and y-intercept: $m=2/5$ and $c = 4/5$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64dd8820",
   "metadata": {},
   "source": [
    "**Option 2:**\n",
    "- Since the coefficient matrix is a square matrix so you can solve it using matrix inversion method\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 \\\\  2 & 4  \\end{bmatrix}\n",
    "\\begin{bmatrix} x \\\\ y  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$x = A^{-1}b$$\n",
    "\n",
    "$$x = \\frac{1}{det(A)}\\begin{bmatrix} 4 & -2\\\\ -2 & 6 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}$$\n",
    "\n",
    "$$x = \\frac{1}{20}\\begin{bmatrix} 4 & -2\\\\ -2 & 6 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}$$\n",
    "\n",
    "$$x = \\begin{bmatrix} 1/5 & -1/10\\\\ -1/10 & 3/10 \\end{bmatrix} \\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}$$  \n",
    "\n",
    "$$x = \\begin{bmatrix} 2/5 \\\\ 4/5\\end{bmatrix}$$\n",
    "- Using this way, you get the same slope and y-intercept: $m=2/5$ and $c = 4/5$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1e3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another short way\n",
    "import scipy\n",
    "slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress([-1,0,1,2], [0,1,2,1])\n",
    "print(\"Slope: \", slope)\n",
    "print(\"Y-intercept: \", intercept)\n",
    "print(\"Error: \", stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c73904",
   "metadata": {},
   "source": [
    ">- Let us now draw this line, which should be the best fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae6eefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2])       \n",
    "y = np.array([0, 1, 2, 1])  \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-2, 3])\n",
    "ax.scatter(x,y);\n",
    "\n",
    "\n",
    "x2 = np.linspace(-2,3, 10)\n",
    "y2 = 2/5 *x2 + 4/5\n",
    "ax.plot(x2,y2)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fd29f0",
   "metadata": {},
   "source": [
    "> Now let us calculate the sum of squares of the errors\n",
    "$\\epsilon_i = \\hat{y}_i - y_i$, For a given instance $i$, $\\epsilon_i$ is a measure of the difference between the true $y_i$ and the model's estimate, $\\hat{y}_i$. If the model predicts $y_i$ perfectly, then the error is zero\n",
    "\n",
    "\n",
    "$$SSE = (c+mx_1-y_1)^2 + (c+mx_2-y_2)^2 + (c+mx_3-y_3)^2 + (c+mx_4-y_4)^2 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ce597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (-1,0) the error is:\n",
    "(.8 + 0.4*(-1)  - 0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d44a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (0,1) the error is:\n",
    "(.8 + 0.4*(0) - 1)**2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b804694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (1,2) the error is:\n",
    "(.8 + 0.4*(1) - 2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89e192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the point (2,1) the error is:\n",
    "(.8 + 0.4*(2) - 1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e91e059",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.ones(2)\n",
    "x0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14d653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = x_ls\n",
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f31f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((np.matrix(x0).T, np.matrix(x1).T), axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a32c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us draw this line having slope=0.42857 and y-intercept=1.4285\n",
    "%matplotlib inline\n",
    "t = np.linspace(-5, 5, 100) # start, finish, n points\n",
    "y1 = 2*x - 2\n",
    "y2 = .5*x + .5\n",
    "y3 = -x + 4\n",
    "\n",
    "y4 = 0.43857*x + 1.42867\n",
    "\n",
    "#y4 = 1.42867*x + 0.43857\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-5, 5])\n",
    "ax.set_ylim([-5, 5])\n",
    "#ax.plot(t, d1, c='green')\n",
    "#ax.plot(t, d2, c='red')\n",
    "ax.plot(x, y1, '.')\n",
    "ax.plot(x, y2, '.')\n",
    "ax.plot(x, y3, '.')\n",
    "ax.plot(x, y4, c='purple')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7002e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error\n",
    "(1.4285 + 0.42857*2  -2)**2 + (1.4285 + 0.42857*1 - 1)**2 + (1.4285 + 0.42857*1 - 4)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7928ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify slope, y-intercept and error\n",
    "from scipy.stats import linregress\n",
    "slope, intercept, r, p, stderr = linregress(A, c)\n",
    "\n",
    "print(\"Slope: \", slope, \"\\nY-intercept: \", intercept, \"\\nCorrelation Coefficient: \", r, \n",
    "      \"\\np-value: \", p,\"\\nError: \", stderr) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d062d2",
   "metadata": {},
   "source": [
    "**Example 2:** Given four 2-D points $(-1,0), (0,1),(1,2),(2,1)$\n",
    "- plot them using scatter plot\n",
    "- Mention the four equations for the four points $y=mx+c$\n",
    "- From the four equations create a Ax = b matrix equation\n",
    "- use psuedoinverse (either using transpose or inverse) to find m and y\n",
    "- Draw the line using this computed m and y, which is the best fit line\n",
    "- Finally calculate the least square errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d529048",
   "metadata": {},
   "source": [
    ">- Plot the four points using scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610fc788",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2.])       \n",
    "y = np.array([0, 1, 2, 1.])  \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-2, 3])\n",
    "ax.scatter(x,y);\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fc5811",
   "metadata": {},
   "source": [
    ">- Mention the four equations for the four points, having two unknowns m (slope) and c (y-intercept)\n",
    "$$f(-1) = -m + c = 0$$\n",
    "$$f(0) =  0 + c = 1$$\n",
    "$$f(1) = m + c = 2$$\n",
    "$$f(2) = 2m + c = 1$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67a0953",
   "metadata": {},
   "source": [
    "- From the four equations create a Ax = b matrix equation\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} m \\\\ c  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$A^TAx = A^Tb $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "face76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = A = numpy.array([[-1, 1],\n",
    "                      [0, 1],\n",
    "                      [1, 1],\n",
    "                      [2, 1]\n",
    "                    ])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14dcfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4782c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = numpy.array([[0], [1], [2], [1]])\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f5d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ata = A.T@A\n",
    "ata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "atb = A.T@b\n",
    "atb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3d56dc",
   "metadata": {},
   "source": [
    "- From the four equations create a Ax = b matrix equation\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} m \\\\ c  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$A^TAx = A^Tb $$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} -1 & 0 & 1 & 2 \\\\  1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} -1 & 1 \\\\  0 & 1 \\\\  1 & 1 \\\\ 2 & 1  \\end{bmatrix}\n",
    "\\begin{bmatrix} m \\\\ c  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} -1 & 0 & 1 & 2 \\\\  1 & 1 & 1 & 1 \\end{bmatrix}\n",
    "\\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 1  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 6 & 2 \\\\  2 & 4  \\end{bmatrix}\n",
    "\\begin{bmatrix} m \\\\ c  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 4 \\\\ 4\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$Ax = b$$\n",
    "\n",
    "$$x = A^{-1}b $$\n",
    "\n",
    "$$12m + 4c  = 8 $$\n",
    "$$2m + 4c = 4$$\n",
    "\n",
    "\n",
    "- Now solve these equations using substitution method and you get\n",
    "$$m=2/5$$\n",
    "$$c = 4/5$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9c986",
   "metadata": {},
   "outputs": [],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b88e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short way\n",
    "A_inv = numpy.linalg.pinv(A)\n",
    "result = A_inv @ b\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32d0313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another short way\n",
    "import scipy\n",
    "slope, intercept, rvalue, pvalue, stderr = scipy.stats.linregress([-1,0,1,2], [0,1,2,1])\n",
    "print(\"Slope: \", slope)\n",
    "print(\"Y-intercept: \", intercept)\n",
    "print(\"Error: \", stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa534c4",
   "metadata": {},
   "source": [
    "- So the best fit line equation is:\n",
    "$$ y = 0.4*x + 0.8$$\n",
    "- Now let us draw this line in the above scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6324f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2.])       \n",
    "y = np.array([0, 1, 2, 1.])  \n",
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim([-2, 3])\n",
    "ax.set_ylim([-2, 3])\n",
    "ax.scatter(x,y);\n",
    "\n",
    "x1 = np.linspace(-5, 5, 100) # start, finish, n points\n",
    "y1 = 0.4*x1 + 0.8\n",
    "ax.plot(x1,y1)\n",
    "\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011ef15",
   "metadata": {},
   "source": [
    "> Now let us calculate the sum of squares of the errors\n",
    "$\\epsilon_i = \\hat{y}_i - y_i$, For a given instance $i$, $\\epsilon_i$ is a measure of the difference between the true $y_i$ and the model's estimate, $\\hat{y}_i$. If the model predicts $y_i$ perfectly, then the error is zero\n",
    "\n",
    "\n",
    "$$(c+mx1-y1)^2 + (c+mx2-y2)^2 + (c+mx3-y3)^2 + (c+mx4-y4)^2 $$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f6ef46",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([-1, 0, 1, 2.])       \n",
    "y = np.array([0, 1, 2, 1.])  \n",
    "x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34b44ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = 0.4*x + 0.8\n",
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c6b14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_errors_line = (y-yhat)**2\n",
    "squared_errors_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cbf46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_line = squared_errors_line.sum()\n",
    "se_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff37806",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d92c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_errors_mean = (y - np.mean(y))**2\n",
    "squared_errors_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b5eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "se_mean = squared_errors_mean.sum()\n",
    "se_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04ce6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = se_line/se_mean\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3f8de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "1-.59999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b558b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b3f18ff",
   "metadata": {},
   "source": [
    "A popular application of psuedo-inverse is solving linear *least square* problems. The *least square* method offers a way to \"solve\" an *overdetermined* linear system of equations, where there are more equation than unknowns in the system. The following linear system is overdetermined:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "2x + y &= -1 \\\\\n",
    "3x - y &= 2  \\\\\n",
    "x - y  &= -1\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91bb3f12",
   "metadata": {},
   "source": [
    "Drawing the lines on the same plot below, you will find that there is no exact solution that can satisfy all three equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba9e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = numpy.array([-1, 1])\n",
    "pyplot.figure(figsize=(4,4))\n",
    "pyplot.plot(x, -1-2*x, lw=0.8)\n",
    "pyplot.plot(x, 3*x-2, lw=0.8)\n",
    "pyplot.plot(x, x+1, lw=0.8);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21425399",
   "metadata": {},
   "source": [
    "But can we find a pair of $x$ and $y$ that will make the left hand side (LHS) and the right hand side (RHS) as close as possible? In other words, can we come up with an approximate solution to this linear system?\n",
    "\n",
    "In the study of the shape of the earth and celestial orbits, Gauss and Legendre answered this question by proposing the *least squares* approach which minimizes the sum of the square of the residuals, the difference between LHS and RHS, of each equation.\n",
    "\n",
    "In our case, the least squares method is to find $x$ and $y$ that minimizes the sum $S(x,y) = (2x + y + 1)^2  + (3x - y - 2)^2 + (x - y + 1)^2$. You might have learnt in your calculus class that you can set partial derivatives to zero to find this saddle point, but today we would like to solve using a neat feature of pseudo-inverse. For an overdetermined linear system $A\\mathbf{x} = \\mathbf{b}$, the least squares solution is given by:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = A^\\dagger \\, \\mathbf{b} = V S^\\dagger U^T \\, \\mathbf{b}\n",
    "$$\n",
    "\n",
    "where $A^\\dagger$ is the pseudo-inverse of the coefficient matrix $A$.\n",
    "\n",
    "With pseudo-inverse built in function, we can obtain the least squares solution to the linear system above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f63ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = numpy.array([[2, 1],\n",
    "                 [3, -1],\n",
    "                 [1, -1]])\n",
    "b = numpy.array([-1, 2, -1])\n",
    "A_inv = numpy.linalg.pinv(A)\n",
    "x_ls = A_inv @ b\n",
    "print(x_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1988f93a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aa2ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b44f3c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c99d933",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22489371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb51b3a8",
   "metadata": {
    "id": "xMnIqjpfj3ZT"
   },
   "source": [
    "For regression problems, we typically have many more cases ($n$, or rows of $X$) than features to predict (columns of $X$). Let's solve a miniature example of such an overdetermined situation. \n",
    "\n",
    "We have eight data points ($n$ = 8): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515807ef",
   "metadata": {},
   "source": [
    "**Example:** Consider the following regression example:<br>\n",
    "$\\hspace{2 cm} y = a + bx_1 + cx_2 + dx_3 + \\cdots + mx_m $\n",
    "- Where,\n",
    "    - `y` is the house price\n",
    "    - `a` is the y-intercept (base price of a house)\n",
    "    - `x1` is feature of the house, distance to school\n",
    "    - `x2` is feature of the house, number of bedrooms\n",
    "    - `x3` is feature of the house, area of house\n",
    "\n",
    "- We may have hundred or thousands of houses\n",
    "$$ y_1 = a + bx_{1,1} + cx_{1,2} + dx_{1,3} + \\cdots + mx_{1,m} $$\n",
    "$$ y_2 = a + bx_{2,1} + cx_{2,2} + dx_{2,3} + \\cdots + mx_{2,m} $$\n",
    "$$ y_3 = a + bx_{3,1} + cx_{3,2} + dx_{3,3} + \\cdots + mx_{3,m} $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$\\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}   \\cdots \\hspace{1 cm} \\cdots \\hspace{1 cm}\\cdots\\hspace{1 cm} \\cdots $$\n",
    "$$ y_n = a + bx_{n,1} + cx_{n,2} + dx_{n,3} + \\cdots + mx_{n,m} $$\n",
    "\n",
    "Let us write above set of linear equations in matrix form:<br>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} y_1 \\\\ y_2 \\\\ y_3 \\\\ \\vdots \\\\ y_n  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 1 & x_{1,1} & x_{1,2} & x_{1,3} & \\cdots & x_{1,m} \\\\\n",
    "                1 & x_{2,1} & x_{2,2} & x_{2,3} & \\cdots & x_{2,m} \\\\\n",
    "                1 & x_{3,1} & x_{3,2} & x_{3,3} & \\cdots & x_{3,m}  \\\\\n",
    "                \\vdots  & \\vdots  & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "                1 & x_{n,1} & x_{n,2} & x_{n,3} & \\cdots & x_{n,m}  \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix} a \\\\ b \\\\ c \\\\ \\vdots \\\\ m  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- For any house, $y_i$ in the dataset, \n",
    "    - We know the outcome, $y_i$, which is the price of the house\n",
    "    - We know the features of the house, $X$, which are predictors like number of bedrooms, distance to school, ...\n",
    "    - Vector $w$ contains the unknowns, the model's learnable parameters\n",
    "- Assuming $X^{-1}$ exists, we can use matrix inversion  technique to solve for w:\n",
    "$$ y = Xw$$\n",
    "\n",
    "$$ X^{-1}y = X^{-1}Xw $$\n",
    "\n",
    "$$  X^{-1}y = Iw $$\n",
    "\n",
    "$$  X^{-1}y = w $$\n",
    "\n",
    "$$  w = X^{-1}y $$\n",
    "\n",
    "- In most of the cases the matrix will not be square. I mean there may be one thousand houses with only one dozen features. So the inverse of matrix $X$ will not exist.\n",
    "- **Good News**: Solving a system of such linear equations is still possible using **Pseudo-Inverse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d859f80",
   "metadata": {},
   "source": [
    "**Example 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd6af3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = np.array([1, 2, 3, 4, 5, 6, 7.])               # study hours \n",
    "gpa = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])   # gpa\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Study Hours vs GPA of Students\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"GPA\")\n",
    "ax.scatter(sh,gpa);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20552389",
   "metadata": {},
   "source": [
    "- Let us suppose that we want to fit a regression line to these seven data points. \n",
    "- We have just one feature/independent/predictor variable and that is the `study hours` and the outcome/dependent/response variable is `gpa`. \n",
    "- We know the equation of a line is:\n",
    "    \n",
    "$$ y = c + mx $$\n",
    "\n",
    "- Where,\n",
    "    - `y` is the outcome/dependent/response variable \n",
    "    - `x` is the only feature/independent/predictor variable\n",
    "    - `m` is the slope of the line \n",
    "    - `c` is the y-intercept. \n",
    "- In this scenario, there are only two model parameters (`m` is the slope of the line and `c` is the y-intercept)\n",
    "- In Machine Learning it is a convention to represent the model parameters with Greek letters Baita. So the above, equation can be re-written as regression equation as follows: \n",
    "\n",
    "$$ y = \\beta_0 + \\beta_1 x + \\epsilon $$\n",
    "\n",
    "- Where,\n",
    "    - $\\beta_0$ is the y-intercept\n",
    "    - $\\beta_1$ is the slope of the line \n",
    "    - $\\epsilon_i = \\hat{y}_i - y_i$, For a given instance $i$, $\\epsilon_i$ is a measure of the difference between the true $y_i$ and the model's estimate, $\\hat{y}_i$. If the model predicts $y_i$ perfectly, then the error is zero\n",
    "\n",
    "- Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**.  Our objective is to find the parameters $\\beta_0$ and $\\beta_1$ that minimize $\\epsilon$ across all the available data points. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56570a81",
   "metadata": {
    "id": "GWZUFeqzj3ZX"
   },
   "source": [
    ">- Although it appears there is only one predictor/study hours ($sh$), our model requires a second one (let's call it $x_0$) in order to allow for a $y$-intercept. \n",
    ">- Without this second variable, the line will pass through the origin (0, 0). \n",
    ">- The $y$-intercept is constant across all the points so we can set it equal to `1` across the board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b346df4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RpAIoxydj3ZX",
    "outputId": "7d2c3e3e-248e-4d25-c4ef-f07d52b272a3"
   },
   "outputs": [],
   "source": [
    "x0 = np.ones(7)\n",
    "x0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1ca361",
   "metadata": {
    "id": "_bkwC8Wnj3ZY"
   },
   "source": [
    "Concatenate $x_0$ and $x_1$ into a matrix $X$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb70d82",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x56TMNFMj3ZY",
    "outputId": "1d874fd7-f48a-4810-9d28-29dc75f1b201"
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((np.matrix(x0).T, np.matrix(sh).T), axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b82661e",
   "metadata": {},
   "source": [
    "Let us now compute the Pseudoinverse of matrix $X$, i.e., $X^+$, using `np.linalg.pinv()` method of numPy: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f682aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xplus = np.linalg.pinv(X)\n",
    "Xplus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fde059",
   "metadata": {
    "id": "v7TomkyCj3ZY"
   },
   "source": [
    "Let us now compute vector $w$ using the equation $w = X^+y$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284597c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iRYhw-N0j3ZZ",
    "outputId": "e118518f-cf9b-400a-a833-772ea9143bd7"
   },
   "outputs": [],
   "source": [
    "w = np.dot(Xplus, gpa)\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edfba39",
   "metadata": {
    "id": "N2SoGsRNj3ZZ"
   },
   "source": [
    ">- The first value is the $\\textbf{y}$**-intercept** of the line, which is typically denoted as $\\beta_0$.\n",
    ">- The second value is the **slope of the line**, which is typically denoted as $\\beta_1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557f414",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nLvuVmBGj3ZZ",
    "outputId": "a0733664-d354-4f4f-843c-e4b5c4e8eb93"
   },
   "outputs": [],
   "source": [
    "beta0 = w[0,0]\n",
    "beta1 = w[0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60eb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607d765",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dff6ee",
   "metadata": {
    "id": "lvGCTZRqj3Zc"
   },
   "source": [
    "Now, with the y-intercept and slope known, we can draw the regression line: \n",
    "$y = \\beta_0 + \\beta_1x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8aa5ee",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "q9SAiUyej3Zc",
    "outputId": "276d5d7c-444c-4638-d008-12fc1b46fed9"
   },
   "outputs": [],
   "source": [
    "sh = np.array([1, 2, 3, 4, 5, 6, 7.])               # study hours \n",
    "gpa = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])   # gpa\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Study Hours vs GPA of Students\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"GPA\")\n",
    "ax.scatter(sh,gpa);\n",
    "\n",
    "\n",
    "#x = np.linspace(-10, 10, 100) # start, finish, n points\n",
    "y = beta0 + beta1*sh\n",
    "#ax.plot(x1, y1, c='green')\n",
    "ax.plot(sh,y)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d8dd12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea205ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4b0f9640",
   "metadata": {
    "id": "vNJJNtDzSh83"
   },
   "source": [
    "**Example 2:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f405839",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = np.array([0, 1, 2, 3, 4, 5, 6, 7.])                         # Drug dosage in ml\n",
    "level = np.array([1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37])   # Level of forgetfullness\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Clinical Trial\")\n",
    "plt.xlabel(\"Drug dosage (mL)\")\n",
    "plt.ylabel(\"Forgetfulness\")\n",
    "ax.scatter(drug, level);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f13e48a",
   "metadata": {},
   "source": [
    "Create matrix X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26b207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.ones(8)\n",
    "X = np.concatenate((np.matrix(x0).T, np.matrix(drug).T), axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd237c77",
   "metadata": {},
   "source": [
    "Compute the Pseudoinverse of matrix $X$, i.e., $X^+$, and then compute vector $w$ using the equation $w = X^+y$: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef95f7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xplus = np.linalg.pinv(X)\n",
    "Xplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a83374",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xplus = np.linalg.pinv(X)\n",
    "w = np.dot(Xplus, level)\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5168ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta0 = w[0,0]    # y-intercept\n",
    "beta1 = w[0,1]    # slope of the line\n",
    "beta1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efbc329",
   "metadata": {},
   "source": [
    "Now, with the y-intercept and slope known, we can draw the regression line: \n",
    "$y = \\beta_0 + \\beta_1x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f3dff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "drug = np.array([0, 1, 2, 3, 4, 5, 6, 7.])                         # Drug dosage in ml\n",
    "level = np.array([1.86, 1.31, .62, .33, .09, -.67, -1.23, -1.37])   # Level of forgetfullness\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Clinical Trial\")\n",
    "plt.xlabel(\"Drug dosage (mL)\")\n",
    "plt.ylabel(\"Forgetfulness\")\n",
    "ax.scatter(drug, level);\n",
    "\n",
    "y = beta0 + beta1*drug\n",
    "ax.plot(drug, y, c='green')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303ab8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a5d5c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e73ff1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fa299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded7400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39abdc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6b75c796",
   "metadata": {},
   "source": [
    "### c. Use `scipy.stats.linregress()` Function to Fit the Regression Line\n",
    "- We can also use the `scipy.stats.linregress()` method to calculate the slope and y-intercept for the data points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4121eaf0",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2380c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "# linregress() function calculate a linear least-squares regression for two sets of measurements.\n",
    "# Return a five tuple value\n",
    "# slope of regression line\n",
    "# intercept of regression line\n",
    "# rvalue, which is the correlation coefficient\n",
    "# pvalue for a hypothesis test whose null hypothesis is that the slope is zero\n",
    "# stderr is the standard error of the estimated slope\n",
    "#slope, intercept, r, p, stderr = scipy.stats.linregress(drug, level)\n",
    "\n",
    "print(\"Slope: \", slope, \"\\nY-intercept: \", intercept, \"\\nCorrelation Coefficient: \", r, \n",
    "      \"\\np-value: \", p,\"\\nError: \", stderr) \n",
    "\n",
    "# This function receives x-value (drug) and returns corresponding y value (forgetnesslevel)\n",
    "# y = mx + c = slope * drug + intercept\n",
    "def myfunc(drug):\n",
    "  return slope * drug + intercept\n",
    "\n",
    "\n",
    "# Use list comprehension to create a new list of y values (forgetnesslevel) for all the drug values\n",
    "result = list(map(myfunc, drug))\n",
    "\n",
    "# Draw the data points using scatter plot\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Clinical Trial\")\n",
    "plt.xlabel(\"Drug dosage (mL)\")\n",
    "plt.ylabel(\"Forgetfulness\")\n",
    "ax.scatter(drug, level);\n",
    "plt.scatter(drug, level)\n",
    "# Draw the regression line using line plot\n",
    "plt.plot(drug, result);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afa2d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdfa4e63",
   "metadata": {
    "id": "1rQOXPyaj3Zh"
   },
   "source": [
    "## 3.  Principal Component Analysis\n",
    "- Curse of Dimensionality: Increasing the number of features does not always improve accuracy. When data does not have enough features, the model is likely to underfit, and when data has too many features, it is likely to overfit. Hence it is called the curse of dimensionality. The curse of dimensionality is an astonishing paradox for data scientists, based on the exploding amount of n-dimensional spaces — as the number of dimensions, n, increases.\n",
    "\n",
    "- Dimensionality Reduction: Dimensionality reduction eliminates some features of the dataset and creates a restricted set of features that contains all of the information needed to predict the target variables more efficiently and accurately.\n",
    "\n",
    "\n",
    "- Principal Component Analysis (PCA) is a linear dimensionality reduction technique that can be utilized for extracting information from a high-dimensional space by projecting it into a lower-dimensional sub-space. It tries to preserve the essential parts that have more variation of the data and remove the non-essential parts with fewer variation.\n",
    "- One important thing to note about PCA is that it is an Unsupervised dimensionality reduction technique, you can cluster the similar data points based on the feature correlation between them without any supervision (or labels).\n",
    "- Applications of PCA:\n",
    "    - Data Visualization: When working on any data related problem, the challenge in today's world is the sheer volume of data, and the variables/features that define that data. To solve a problem where data is the key, you need extensive data exploration like finding out how the variables are correlated or understanding the distribution of a few variables. Considering that there are a large number of variables or dimensions along which the data is distributed, visualization can be a challenge and almost impossible. Hence, PCA can do that for you since it projects the data into a lower dimension, thereby allowing you to visualize the data in a 2D or 3D space with a naked eye.\n",
    "    - Speeding Machine Learning (ML) Algorithm: Since PCA's main idea is dimensionality reduction, you can leverage that to speed up your machine learning algorithm's training and testing time considering your data has a lot of features, and the ML algorithm's learning is too slow.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e492675",
   "metadata": {},
   "source": [
    "### a. What are Principal Components?\n",
    "- At an abstract level, you take a dataset having many features, and you simplify that dataset by selecting a few Principal Components from original features.\n",
    "- when the data is projected into a lower dimension (assume three dimensions) from a higher space, the three dimensions are nothing but the three Principal Components that captures (or holds) most of the variance (information) of your data.\n",
    "- Principal components have both direction and magnitude. The direction represents across which principal axes the data is mostly spread out or has most variance and the magnitude signifies the amount of variance that Principal Component captures of the data when projected onto that axis. The principal components are a straight line, and the first principal component holds the most variance in the data. Each subsequent principal component is orthogonal to the last and has a lesser variance. In this way, given a set of x correlated variables over y samples you achieve a set of u uncorrelated principal components over the same y samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a355956",
   "metadata": {},
   "source": [
    "### b. Two Common Ways to Calculate PCA\n",
    "- Creating a Covariance matrix and doing some eigen-calculations on it.\n",
    "- Using Singular Value Decomposition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cc3983",
   "metadata": {
    "id": "X3_Etgo4j3Zh"
   },
   "source": [
    "This PCA example code is adapted from [here](https://jupyter.brynmawr.edu/services/public/dblank/CS371%20Cognitive%20Science/2016-Fall/PCA.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109d5b78",
   "metadata": {
    "id": "ubl3WdRWj3Zh"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9e75dd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZE2yvfEbj3Zi",
    "outputId": "22481efa-7413-4713-efc6-c3f2965252de"
   },
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2726ab3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa9fcMl2j3Zi",
    "outputId": "a58badd2-c61c-4555-a67e-273d9a86a665"
   },
   "outputs": [],
   "source": [
    "iris.get(\"feature_names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fb5265",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8O9xwrOLj3Zj",
    "outputId": "4cbdd710-0b45-46d7-9ca7-f69b0a94bbf8"
   },
   "outputs": [],
   "source": [
    "iris.data[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e92e40",
   "metadata": {
    "id": "YoodmvRsj3Zj"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726a590f",
   "metadata": {
    "id": "PcJwICbtj3Zk"
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a1813e7",
   "metadata": {
    "id": "bNb6txoIj3Zk"
   },
   "outputs": [],
   "source": [
    "X = pca.fit_transform(iris.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1408f29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "plS7skQGj3Zl",
    "outputId": "3cb1ebcf-3026-407f-b5bb-48a793fb8900"
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d1dc6a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wC_j-7Xyj3Zl",
    "outputId": "e9cfa100-941a-4804-803d-95485f933cf3"
   },
   "outputs": [],
   "source": [
    "X[0:6,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755f7ab9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "O_aNxFn5j3Zm",
    "outputId": "827f3462-d784-47d4-a231-4c6b62ee7705"
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1448a6df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bTck5c93j3Zm",
    "outputId": "d9ab042f-fd36-4211-f31f-576a917763d3"
   },
   "outputs": [],
   "source": [
    "iris.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d879de4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IzGhB6NTj3Zn",
    "outputId": "54ab57dc-3cff-49d6-b543-a5cdcc9bc9c0"
   },
   "outputs": [],
   "source": [
    "iris.target[0:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700befd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DQ8oRWsWj3Zn",
    "outputId": "20ec84c8-970f-4448-c51b-0297e4b8c51b"
   },
   "outputs": [],
   "source": [
    "unique_elements, counts_elements = np.unique(iris.target, return_counts=True)\n",
    "np.asarray((unique_elements, counts_elements))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9753288",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VAIoVTYWj3Zo",
    "outputId": "8e821e2c-fb38-48c2-e9c9-5919af3e541a"
   },
   "outputs": [],
   "source": [
    "list(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa5993",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "JlZX_2vQj3Zo",
    "outputId": "b2741dbb-3a32-4b0e-bb4c-84cee47de1fc"
   },
   "outputs": [],
   "source": [
    "_ = plt.scatter(X[:, 0], X[:, 1], c=iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe65512",
   "metadata": {
    "id": "w1Y8YA2oj3Zp"
   },
   "source": [
    "**Return to slides here.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8870825d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e71b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea250af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932755df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c1b7108",
   "metadata": {},
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Tools and Techniques for Data Science</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Instructor: Muhammad Arif Butt, Ph.D.</div></h3>    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331514b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a88bbe5",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction (Application of svd)\n",
    "- A popular application of SVD is for dimensionality reduction. Data with a large number of features, such as more `features` (columns) than `observations` (rows) may be reduced to a smaller subset of features that are most relevant to the `prediction problem`. The result is a matrix with a `lower rank` that is said to approximate the original matrix. To do this we can perform an SVD operation on the original data and `select the top k largest singular values in Σ`. These columns can be selected from Σ and the rows selected from V<sup>T</sup> . An `approximate B` of the original vector A can then be reconstructed.\n",
    "###### <center> B = U · Σ<sub>k</sub> · V<sub>k</sub><sup>T</sup> </center>\n",
    "\n",
    "\n",
    "- In natural language processing, this approach can be used on matrices of `word occurrences` or `word frequencies` in documents and is called `Latent Semantic Analysis` or `Latent Semantic Indexing`. In practice, we can retain and work with a descriptive subset of the data called `T` . This is a `dense summary` of the matrix or a projection.\n",
    "###### <center> T = U · Σ<sub>k</sub> </center>\n",
    "\n",
    "- Further, this transform can be calculated and applied to the original matrix A as well as other similar matrices.\n",
    "###### <center> T = A · V<sub>k</sub><sup>T</sup>  </center>\n",
    "\n",
    "\n",
    "- The example below demonstrates data reduction with the SVD. First a 3 × 10 matrix is defined, with more columns than rows. The SVD is calculated and only the first two features are selected. The elements are recombined to give an accurate reproduction of the original matrix. Finally the transform is calculated two different ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19a1aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from numpy import diag\n",
    "from numpy import zeros\n",
    "from scipy.linalg import svd\n",
    "\n",
    "# define matrix\n",
    "A = np.array([ [1,2,3,4,5,6,7,8,9,10],\n",
    "               [11,12,13,14,15,16,17,18,19,20],\n",
    "               [21,22,23,24,25,26,27,28,29,30]])\n",
    "\n",
    "# print original Matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "\n",
    "\n",
    "# Decomposing vector A using svd() function\n",
    "U, s, V = svd(A)\n",
    "\n",
    "# print Decompsed matrix in the form of U, Σ and V\n",
    "print(\"\\nU = \\n\", U)\n",
    "print(\"\\nΣ = \", s)\n",
    "print(\"\\nV = \\n\", V)\n",
    "\n",
    "\n",
    "\n",
    "# create m x n Sigma matrix\n",
    "Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:A.shape[0], :A.shape[0]] = diag(s)\n",
    "\n",
    "\n",
    "# Selecting Elements\n",
    "n_elements = 2\n",
    "Sigma = Sigma[:, :n_elements]\n",
    "V = V[:n_elements, :]\n",
    "\n",
    "\n",
    "# reconstruct\n",
    "B = U.dot(Sigma.dot(V))\n",
    "print(\"\\nReconstruct Matrix = \\n\", B)\n",
    "\n",
    "\n",
    "# computing T = U · Σk\n",
    "T = U.dot(Sigma)\n",
    "print(\"\\nU · Σk = \\n\", T)\n",
    "\n",
    "\n",
    "T = A.dot(V.T)\n",
    "print(\"\\nA · VkT = \\n\", T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9108352b",
   "metadata": {},
   "source": [
    "#### Dimensionality Reduction using scikit-learn library\n",
    "- The `scikit-learn` provides a `TruncatedSVD class` that implements this capability directly. The TruncatedSVD class can be created in which you must specify the number of `desirable features` or `components to select`, e.g. 2. Once created, you can fit the transform (e.g. calculate V<sub>k</sub><sup>T</sup> ) by calling the `fit()` function, then apply it to the `original matrix` by calling the `transform()` function. The result is the transform of A called `T` above. The example below demonstrates the TruncatedSVD class.\n",
    "\n",
    "\n",
    "- We can see that the values match those calculated manually above, except for the sign on some values. We can expect there to be some instability when it comes to the sign given the nature of the calculations involved and the differences in the underlying libraries and methods used. This instability of sign should not be a problem in practice as long as the transform is trained for reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd083d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# define matrix\n",
    "A = np.array([ [1,2,3,4,5,6,7,8,9,10],\n",
    "            [11,12,13,14,15,16,17,18,19,20],\n",
    "            [21,22,23,24,25,26,27,28,29,30]])\n",
    "\n",
    "# print original Matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "# create transform\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "\n",
    "# fit transform\n",
    "svd.fit(A)\n",
    "\n",
    "# apply transform\n",
    "result = svd.transform(A)\n",
    "print(\"\\nResultant Matrix = \\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da905d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da390bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c41000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33684f14",
   "metadata": {},
   "source": [
    "## Principal Component Analysis\n",
    "- An important `machine learning` method for `dimensionality reduction` is called `Principal Component Analysis`. It is a method that uses `simple matrix operations` from `linear algebra` and `statistics` to calculate a `projection` of the original data into the same number or `fewer dimensions`.\n",
    "\n",
    "- It can be thought of as a projection method where data with m-columns (features) is projected into a subspace with m or fewer columns, whilst retaining the essence of the original data. PCA is an operation applied to a dataset, represented by an `n × m` matrix `A` that results in a `projection of A` which we will call `B`.\n",
    "\n",
    "<img align=\"center\" width=\"150\" height=\"150\"  src=\"images/pca.png\"  >\n",
    "\n",
    "###### <center> B = PCA(A) </center>\n",
    "\n",
    "\n",
    "- Let’s walk through the steps of this operation. The first step is to calculate the mean values of each column.\n",
    "###### <center> M = mean(A) </center>\n",
    "\n",
    "- Next, we need to center the values in each column by subtracting the mean column value.\n",
    "###### <center> C = A − M </center>\n",
    "\n",
    "\n",
    "- The next step is to calculate the `covariance matrix` of the centered matrix C. `Correlation` is a normalized measure of the `amount and direction` (positive or negative) that two columns change together. `Covariance` is a generalized and unnormalized version of correlation across multiple columns. \n",
    "\n",
    "        - A covariance matrix is a calculation of covariance of a given matrix with covariance scores for every column with every other column, including itself.\n",
    "###### <center> V = cov(C) </center>\n",
    "\n",
    "- Finally, we calculate the `eigendecomposition` of the covariance matrix `V` . This results in a list of `eigenvalues` and a list of `eigenvectors`.\n",
    "###### <center> values, vectors = eig(V) </center>\n",
    "\n",
    "- The `eigenvectors` represent the `directions` or components for the reduced subspace of B, whereas the `eigenvalues` represent the `magnitudes` for the directions. The eigenvectors can be sorted by the eigenvalues in descending order to provide a ranking of the components or axes of the new subspace for A. \n",
    "\n",
    "\n",
    "- If all eigenvalues have a similar value, then we know that the existing representation may already be reasonably compressed or dense and that the projection may offer little. If there are eigenvalues close to zero, they represent components or axes of B that may be discarded. A total of m or less components must be selected to comprise the chosen subspace. Ideally, we would select k eigenvectors, called `principal components`, that have the k largest eigenvalues.\n",
    "###### <center> B = select(values, vectors) </center>\n",
    "\n",
    "- Once chosen, data can be projected into the subspace via matrix multiplication.\n",
    "###### <center> P = B<sup>T</sup> · A </center>\n",
    "\n",
    "Where `A` is the `original data` that we wish to project, B<sup>T</sup> is the `transpose` of the chosen `principal components` and `P` is the `projection of A`. This is called the covariance method for calculating the PCA, although there are alternative ways to calculate it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c8556",
   "metadata": {},
   "source": [
    "### Calculate Principal Component Analysis\n",
    "- There is no pca() function in NumPy, but we can easily calculate the Principal Component Analysis step-by-step using NumPy functions. The example below defines a small 3 × 2 matrix, centers the data in the matrix, calculates the covariance matrix of the centered data, and then the eigendecomposition of the covariance matrix. The eigenvectors and eigenvalues are taken as the principal components and singular values and used to project the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21469e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# define matrix\n",
    "A = np.array([ [1, 2],\n",
    "               [3, 4],\n",
    "               [5, 6]])\n",
    "\n",
    "# print matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "# column means\n",
    "M = mean(A.T, axis=1)\n",
    "\n",
    "\n",
    "# center columns by subtracting column means\n",
    "C = A - M\n",
    "\n",
    "# calculate covariance matrix of centered matrix\n",
    "V = cov(C.T)\n",
    "\n",
    "# factorize covariance matrix\n",
    "values, vectors = eig(V)\n",
    "\n",
    "print(\"\\neigenvectors = \\n\", vectors)\n",
    "print(\"\\neigenvalues = \", values)\n",
    "\n",
    "\n",
    "# project data\n",
    "P = vectors.T.dot(C.T)\n",
    "print(\"\\nProjected Data = \\n\", P.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c103e476",
   "metadata": {},
   "source": [
    "#### Principal Component Analysis using scikit-learn library\n",
    "- We can calculate a Principal Component Analysis on a dataset using the `PCA() class` in the `scikit-learn library`. The benefit of this approach is that once the projection is calculated, it can be applied to new data again and again quite easily. \n",
    "\n",
    "\n",
    "- When creating the class, the number of components can be specified as a parameter. The class is first fit on a dataset by calling the `fit()` function, and then the original dataset or other data can be projected into a subspace with the chosen number of dimensions by calling the `transform()` function. \n",
    "\n",
    "\n",
    "- Once fit, the singular values and principal components can be accessed on the PCA class via the explained variance and components attributes. \n",
    "\n",
    "\n",
    "- The example below demonstrates using this class by first creating an instance, fitting it on a 3 × 2 matrix, accessing the values and vectors of the projection, and transforming the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c89f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# define matrix\n",
    "A = np.array([ [1, 2],\n",
    "               [3, 4],\n",
    "               [5, 6]])\n",
    "\n",
    "# print matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "# create the transform\n",
    "pca = PCA(2)\n",
    "\n",
    "# fit transform\n",
    "pca.fit(A)\n",
    "\n",
    "# access values and vectors\n",
    "print(\"\\nAccessing Vectors = \\n\", pca.components_)\n",
    "print(\"\\nAccessing Values = \\n\", pca.explained_variance_)\n",
    "\n",
    "# transform data\n",
    "B = pca.transform(A)\n",
    "print(\"\\nProjected Data = \\n\",B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5138ad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af715b41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2833aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6a3ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4614c70a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e88dfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1600604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f92efa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0cc02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730c96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bc87a1a",
   "metadata": {},
   "source": [
    "### LU Decomposition\n",
    "- The LU decomposition is for `square` matrices and decomposes a matrix into `L` and `U` components.\n",
    "###### <center> A = L · U </center>\n",
    "\n",
    "- Where `A` is the `square matrix` that we wish to decompose, `L` is the `lower triangle` matrix and `U` is the `upper triangle` matrix. The factors L and U are triangular matrices.\n",
    "\n",
    "\n",
    "- The LU decomposition is often used to simplify the solving of `systems of linear equations`, such as finding the coefficients in a linear regression, as well as in calculating the `determinant` and `inverse of a matrix`.\n",
    "\n",
    "\n",
    "- The LU decomposition can be implemented in Python with the `lu()` function. The example below first defines a 3×3 square matrix. The LU decomposition is calculated, then the original matrix is reconstructed from the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ccfd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "# define a square matrix\n",
    "A = np.array([ [1, 2, 3],\n",
    "            [4, 5, 6],\n",
    "            [7, 8, 9]])\n",
    "\n",
    "# print matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "# Decomposing matrix using lu() function\n",
    "P, L, U = lu(A)\n",
    "\n",
    "# print decomposed matrices\n",
    "print(\"\\nP = \\n\", P)\n",
    "print(\"\\nL = \\n\", L)\n",
    "print(\"\\nU = \\n\", U)\n",
    "\n",
    "# reconstruct\n",
    "B = P.dot(L).dot(U)\n",
    "print(\"\\nReconstructed Matrix = \\n\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe561182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a64d8ac2",
   "metadata": {},
   "source": [
    "### QR Decomposition\n",
    "- The QR decomposition is for n × m matrices (not limited to square matrices) and decomposes a matrix into Q and R components.\n",
    "###### <center> A = Q · R </center>\n",
    "\n",
    "- Where `A` is the matrix that we wish to decompose, `Q` a matrix with the size `m×m`, and `R` is an `upper triangle` matrix with the size `m × n`.\n",
    "\n",
    "\n",
    "- Like the LU decomposition, the QR decomposition is often used to solve systems of linear equations, although is not limited to square matrices. The QR decomposition can be implemented in NumPy using the `qr()` function. By default, the function returns the Q and R matrices with smaller or reduced dimensions that is more economical. \n",
    "\n",
    "\n",
    "- We can change this to return the expected sizes of m × m for Q and m × n for R by specifying the mode argument as ‘complete’, although this is not required for most applications. \n",
    "\n",
    "\n",
    "- The example below defines a 3 × 2 matrix, calculates the QR decomposition, then reconstructs the original matrix from the decomposed elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb23f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import qr\n",
    "\n",
    "# define rectangular matrix\n",
    "A = np.array([ [1, 2],\n",
    "           [3, 4],\n",
    "           [5, 6]])\n",
    "\n",
    "# print matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "\n",
    "# Decomposing matrix using qr() function\n",
    "Q, R = qr(A, 'complete')\n",
    "\n",
    "# print decomposed matrices\n",
    "print(\"\\nQ = \\n\", Q)\n",
    "print(\"\\nR = \\n\", R)\n",
    "\n",
    "# reconstruct Matrix\n",
    "B = Q.dot(R)\n",
    "print(\"\\nReconstructed Matrix = \\n\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390ad4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af0043c5",
   "metadata": {},
   "source": [
    "### Cholesky Decomposition\n",
    "- The Cholesky decomposition is for `square symmetric matrices` where all values are greater than `zero`, so-called `positive definite matrices`. \n",
    "\n",
    "\n",
    "- For our interests in machine learning, we will focus on the Cholesky decomposition for `real-valued matrices` and ignore the cases when working with complex numbers. The decomposition is defined as follows:\n",
    "###### <center> A = L · L<sup>T</sup> </center>\n",
    "\n",
    "\n",
    "- Where `A` is the matrix being decomposed, `L` is the `lower triangular matrix` and L<sup>T</sup> is the transpose of L. The decompose can also be written as the product of the upper triangular matrix, for example:\n",
    "###### <center>A = U<sup>T</sup> · U </center>\n",
    "\n",
    "- Where `U` is the upper triangular matrix. \n",
    "\n",
    "\n",
    "- The Cholesky decomposition is used for solving linear least squares for linear regression, as well as simulation and optimization methods. When decomposing symmetric matrices, the Cholesky decomposition is nearly twice as efficient as the LU decomposition.\n",
    "\n",
    "\n",
    "- The Cholesky decomposition can be implemented in NumPy by calling the `cholesky()` function. The function only returns `L` as we can easily access the L transpose as needed. \n",
    "\n",
    "\n",
    "- The example below defines a 3×3 symmetric and positive definite matrix and calculates the Cholesky decomposition, then the original matrix is reconstructed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8255ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import numpy as np\n",
    "from numpy.linalg import cholesky\n",
    "\n",
    "\n",
    "# define symmetrical matrix\n",
    "A = np.array([ [2, 1, 1],\n",
    "            [1, 2, 1],\n",
    "            [1, 1, 2]])\n",
    "\n",
    "# print matrix\n",
    "print(\"Original Matrix A = \\n\", A)\n",
    "\n",
    "# Decomposing matrix using cholesky function\n",
    "L = cholesky(A)\n",
    "\n",
    "# print decomposed matrix\n",
    "print(\"\\nL = \\n\", L)\n",
    "\n",
    "# reconstruct matrix\n",
    "B = L.dot(L.T)\n",
    "print(\"\\nReconstructed Matrix = \\n\", B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1886bd63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
