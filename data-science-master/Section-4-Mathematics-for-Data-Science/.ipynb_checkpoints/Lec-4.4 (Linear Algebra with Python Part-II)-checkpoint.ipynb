{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab29875",
   "metadata": {},
   "source": [
    "---   \n",
    " <img align=\"left\" width=\"75\" height=\"75\"  src=\"https://upload.wikimedia.org/wikipedia/en/c/c8/University_of_the_Punjab_logo.png\"> \n",
    "\n",
    "<h1 align=\"center\">Department of Data Science</h1>\n",
    "<h1 align=\"center\">Course: Tools and Techniques for Data Science</h1>\n",
    "\n",
    "---\n",
    "<h3><div align=\"right\">Instructor: Muhammad Arif Butt, Ph.D.</div></h3>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ffed4",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Lecture 4.4 (Linear Algebra for Machine Learning: Part-II)</h1><br>\n",
    "<a href=\"https://colab.research.google.com/github/arifpucit/data-science/blob/master/Section-3-Python-for-Data-Scientists/Lec-3.01(NumPy-01-ArrayCreation).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fff9cb",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"350\" height=\"300\"  src=\"images/ds1.png\"  >\n",
    "<img align=\"center\" width=\"400\" height=\"250\"  src=\"images/mathsandstat.jpeg\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47900344",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"900\" height=\"250\"  src=\"images/mathimg1.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2051f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbad76cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e996a5d6",
   "metadata": {},
   "source": [
    "## Learning agenda of this notebook\n",
    "\n",
    "**Section I: (Overview of Linear Algebra: Vectors)**\n",
    "\n",
    "**Section II: (Overview of Linear Alagebra: Matrices)**\n",
    "\n",
    "**Section III: (Solving System of Linear Equations)**\n",
    "\n",
    "**Section IV: (Matrix as a Linear Transformation)**\n",
    "1. What do you mean by applying a Matrix to a Vector?\n",
    "2. Algebra Behind Linear Transformations in 2-D Space\n",
    "    - Applying an Identity Matrix\n",
    "    - Applying a Scaling Matrix\n",
    "    - Applying a Reflection Matrix\n",
    "    - Applying a Shear Matrix\n",
    "    - Applying a Rotation Matrix\n",
    "    - Apply Multiple Transformations Simultaneously\n",
    "3. Scaling, Translation and Rotation in Three Dimensional Space\n",
    "4. Hierarchy of Transformations\n",
    "    - Class-I: Isometries\n",
    "    - Class-II: Similarity\n",
    "    - Class-III: Affine\n",
    "    - Class-IV: Projective\n",
    "\n",
    "**Section V:  (Eigen Decomposition and SVD)**\n",
    "1. What is Matrix Decomposition?\n",
    "2. Eigenvalues and Eigenvectors (An abstract view)\n",
    "3. Calculating Eigenvalues and Eigenvectors of a Matrix using Paper-Pencil\n",
    "4. Calculating Eigenvalues and Eigenvectors of a Matrix in Python\n",
    "5. Points to Ponder\n",
    "    - Relationship between Determinant and Eigenvalues of a Matrix\n",
    "    - Relationship between Trace and Eigenvalues of a Matrix\n",
    "    - Not all Transformation Matrices have Real Eigenvalues\n",
    "    - Eigenvectors and Eigenvalues of a Diagonal Transformation Matrix\n",
    "6. Eigendecomposition\n",
    "7. Eigendecomposition for Symmetric Matrices\n",
    "8. What is Singular Value Decomposition?\n",
    "9. Calculating SVD using NumPy\n",
    "9. Calculating SVD using SciPy\n",
    "9. Calculating SVD using Scikit-learn\n",
    "\n",
    "**Section VI: (Applications of SVD & Eigendecomposition)**\n",
    "1. Image Compression\n",
    "2. What is Principal Component Analysis\n",
    "    - Example 1: Dimensionality Reduction of Housing Dataset using NumPy\n",
    "    - Example 2: Dimensionality Reduction of Digits Dataset using Scikit-learn\n",
    "    - Example 3: Dimensionality Reduction of Iris Dataset using Scikit-learn (Data Visualization)\n",
    "3. The Moore-Penrose Pseudoinverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0243f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef28984b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54721447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1ecbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5313b67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "947ad77c",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section IV: (Matrix as a Linear Transformation) </span>\n",
    "<h2 align=\"center\">\"The Matrix is everywhere, it is all around us, even now in this very room.\"</h2>\n",
    "<h4 align=\"right\">-Morpheus-</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc9c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "import sklearn\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7026b",
   "metadata": {},
   "source": [
    "Some of the codes of this notebook are adapted from:\n",
    "- [Jon Krohn's](https://github.com/jonkrohn).\n",
    "- [Frank Cleary's](https://gist.github.com/frankcleary).\n",
    "- [Engineers Code](https://github.com/engineersCode/EngComp4_landlinear)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adc27f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e18afe8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bb3807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f2a919",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a1a87d0",
   "metadata": {},
   "source": [
    "## 1. What do you mean by applying a Matrix to a Vector?\n",
    "- In Linear Algebra a transformation is a function that takes a vector as input and give a vector as output.\n",
    "- There are a variety of transformations, some of which are quite complex, and the most simplest one is called linear transformation.\n",
    "- A linear transformation is a function from one vector space to another that respects the underlying (linear) structure of each vector space\n",
    "- Visually speaking, a transformation is linear if it has two properties:\n",
    "    - Lines remains lines\n",
    "    - Origin remains fixed\n",
    "- **Applying a matrix to a vector** (i.e., performing matrix-vector multiplication) can linearly transform the vector, e.g, rotate it or rescale it.\n",
    "<h2>$$x' = Ax$$</h2>\n",
    "\n",
    "$$i = \\begin{bmatrix} 1  \\\\ 0 \\end{bmatrix}, \\hspace{2 cm}j = \\begin{bmatrix} 0 \\\\ 1\\end{bmatrix}, \\hspace{2 cm}A = \\begin{bmatrix} 1 & 1 \\\\ -1 & 1 \\end{bmatrix}$$\n",
    "\n",
    "$\\hspace{2 cm}i' = Ai = \\begin{bmatrix} 1 & 1 \\\\ -1 & 1 \\end{bmatrix}\\begin{bmatrix} 1  \\\\ 0 \\end{bmatrix} = \\begin{bmatrix} 1  \\\\ -1 \\end{bmatrix}$ \n",
    "\n",
    "$\\hspace{2 cm}j' = Aj = \\begin{bmatrix} 1 & 1 \\\\ -1 & 1 \\end{bmatrix}\\begin{bmatrix} 0  \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1  \\\\ 1 \\end{bmatrix}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40614379",
   "metadata": {},
   "source": [
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db55f492",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = numpy.array([[1,1], [-1,1]])\n",
    "print(A)\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2bf06d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899c50d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94624f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6ea32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4655325b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55c838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a551c01",
   "metadata": {},
   "source": [
    "## 2. Algebra Behind Linear Transformations in 2-D Space\n",
    "- A **Linear Transformation** is an affine transformation that converts points from one coordinate system to another by addition and scaling. Scaling, reflection, rotation and shear are all examples of Linear Transformations. \n",
    "- Unlike affine, in linear transformation the origin must be preserved, so translation as well as rotation about an arbitrary point is not a linear transformation.\n",
    "- If you are given a 2x2 matrix and some specific vector and you want to know where that linear transformation will take that vector, you can take the coordinates of that vector, multiply that with the corresponding columns of the matrix and then add them together\n",
    "- Let us practically understand linear transformation by applying a 2-D transformation matrix $A =    \\begin{bmatrix} a_1 & a_2 \\\\  a_3 & a_4  \\end{bmatrix}$ to a 2-D column vector     $\\overrightarrow{v_1} = \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}$:\n",
    "\n",
    "$\\hspace{7 cm}\\overrightarrow{v_2} = A\\overrightarrow{v_1}$\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} a_1 & a_2 \\\\  a_3 & a_4  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "\\hspace{3 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ 1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} a_1 & a_2 & 0 \\\\  a_3 & a_4 & 0 \\\\ 0 & 0 & 1  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ 1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{6 cm}x_2 = a_1x_1 +a_2y_1$\n",
    "\n",
    "$\\hspace{6 cm}y_2 = a_3x_1 +a_4y_1$\n",
    "\n",
    "\n",
    "\n",
    "> The matrix $A$ represents the **linear transformation** that takes vector $\\overrightarrow{v_1} \\hspace{.2 cm}(x_1, y_1)$ and transforms it into $\\overrightarrow{v_2}\\hspace{.2 cm} (x_2, y_2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758b03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9eabb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144a149",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f6b610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99bd5ec5",
   "metadata": {},
   "source": [
    "### a. Applying Identity Matrix:\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{2 cm} x_2 = x_1 + 0 = x_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = 0 + y_1 = y_1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66132c9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e96945f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4ed5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0de159bb-c0f7-4e9e-9194-8b45b31eb17e",
   "metadata": {
    "id": "gLjGas2ij3Ws"
   },
   "source": [
    "**Example:** Apply identity matrix, $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2086f5-8470-4763-a0f8-be87627cba3c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zZvzKGRkj3Ws",
    "outputId": "e4948d7d-0202-4e46-f7a3-cfc7e065e5d9"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "v1 = np.array([3, 1])\n",
    "A = np.array([[1, 0], [0, 1]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\")\n",
    "\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0e050d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07497a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639420e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1d8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c6410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply identiy matrix on all points in a 2-D plane\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b48e873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b6be6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad2e31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfce88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f321b31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00672cc8",
   "metadata": {},
   "source": [
    "### b. Applying a Scaling Matrix:\n",
    "- Scaling is the process of expanding or compressing the dimensions of an object\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} S_x & 0 \\\\  0 & S_y   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1S_x$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = y_1S_y$\n",
    "\n",
    "- Where $S_x$ is th scaling constant wrt x-direction, and $S_y$ is the scaling constant wrt y-direction.\n",
    "- If $S_x = S_y$, the scaling transformation is said to be homogeneous or uniform\n",
    "- If $S_x \\gt 1$, it is magnification/expansion\n",
    "- If $S_x \\lt 1$, it is reduction/compression\n",
    "- If $S_x = 1$, no effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1219ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc15558",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e37367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32dbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d68f722",
   "metadata": {},
   "source": [
    "**Example:** Apply scaling matrix, $A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 4 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6678e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([3, 1])\n",
    "A = np.array([[2, 0], [0, 4]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\")\n",
    "\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c8133",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe5bf56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a0c629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9de38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply scaling matrix 'A' on all points in a 2-D plane\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6810c2d3",
   "metadata": {},
   "source": [
    "> Applying inverse of scaling matrix, $A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 4 \\end{bmatrix}$ on the transformed vector $\\overrightarrow{v_2} = \\begin{bmatrix} 6 \\\\ 4 \\end{bmatrix}$, will undo the effect of transformation and give you $\\overrightarrow{v_1}$.\n",
    "$$A^{-1}v_2 = \\begin{bmatrix} 0.5 & 0 \\\\ 0 & 0.25 \\end{bmatrix}\\begin{bmatrix} 6 \\\\ 4 \\end{bmatrix}= \\begin{bmatrix} 3 \\\\ 1 \\end{bmatrix} = \\overrightarrow{v_1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44021127",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_inv = numpy.linalg.inv(A)\n",
    "A_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9150f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply matrix A and then inverse of matrix A on all points in a 2-D plane\n",
    "v2 = np.array([6, 4])\n",
    "A_inv = np.linalg.inv(A)\n",
    "v1 = np.dot(A_inv, v2)\n",
    "\n",
    "print(\"v2 = \", v2)\n",
    "print(\"v1 = \", v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642a4ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618c1b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd83e528",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07970a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply matrix A and then inverse of matrix A on all points in a 2-D plane\n",
    "plot_linear_transformations(A, numpy.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0522060e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851de7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e77de3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65782370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628ea7d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a2b865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "670d786b",
   "metadata": {},
   "source": [
    "### c. Applying a Reflection Matrix:\n",
    "- If either x-axis or y-axis is treated as mirror, the object has a mirror image or reflects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db087bb7",
   "metadata": {},
   "source": [
    "- **Reflection about x-axis:**\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  0 & -1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = -y_1$\n",
    "\n",
    "\n",
    "- **Reflection about y-axis:**\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} -1 & 0 \\\\  0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = -x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = y_1$\n",
    "\n",
    "\n",
    "- **Reflection about Diagonal:**\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} -1 & 0 \\\\  0 & -1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = -x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = -y_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0058f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5196b603",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a641e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09b316c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0d33f76-4ff3-4835-a650-9b4b5c9ff5ab",
   "metadata": {},
   "source": [
    "**Example:** Apply reflection matrix, $A = \\begin{bmatrix} 1 & 0 \\\\ 0 & -1 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc04a55-9615-4257-8699-a058a07e7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([3, 2])\n",
    "A = np.array([[1, 0], [0, -1]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babe9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply reflection matrix on all points in a 2-D plane\n",
    "A = np.array([[1, 0], [0, -1]])\n",
    "print(A)\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f391f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply matrix A and then inverse of matrix A on all points in a 2-D plane\n",
    "plot_linear_transformations(A, numpy.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d374c13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c7deb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97caa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba875a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778c6de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8b2058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9936e3f4",
   "metadata": {},
   "source": [
    "### d. Applying a Shear Matrix:\n",
    "- The Shear transformation cause the object to slant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37edc2e",
   "metadata": {},
   "source": [
    "- **Shear in x-direction:** The x-shear maintains the y-coordinate but changes the x-coordinate, which causes the horizontal lines to tilt up or down\n",
    "$\\hspace{2 cm}\\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \\begin{bmatrix} 1 & s_x \\\\  0 & 1   \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1 + s_x y_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = y_1$\n",
    "\n",
    "\n",
    "- **Shear in y-direction:** The y-shear maintains the x-coordinate but changes the y-coordinate, which causes the vertical lines to tilt up or down\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  s_y & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = S_y x_1 + y_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f66033",
   "metadata": {},
   "source": [
    "**Example:** Apply x-shear matrix, $A = \\begin{bmatrix} 1 & 3 \\\\ 0 & 1 \\end{bmatrix}_{2x2}$ on a vector $\\overrightarrow{v_1} = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}$. Calculate and graphically show the vector before and after the transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2845fe71",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2, 2])\n",
    "A = np.array([[1, 3], [0, 1]])\n",
    "v2 = np.dot(A, v1)\n",
    "\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8708e61b",
   "metadata": {},
   "source": [
    "> Since this is x-shear, so it maintains the y-coordinate but changes the x-coordinate, which causes the horizontal lines to tilt up (Give a negative value to check the horizontal lines tilting down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edad17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply x-shear matrix on all points in a 2-D plane\n",
    "A = np.array([[1, 3], [0, 1]])\n",
    "print(A)\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b586e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply matrix A and then inverse of matrix A on all points in a 2-D plane\n",
    "A = np.array([[1, 3], [0, 1]])\n",
    "plot_linear_transformations(A, numpy.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59169",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f7dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5afb897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e663dd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86b48e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80d4db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21b69da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90b6ca1e",
   "metadata": {},
   "source": [
    "### e. Applying a Rotation Matrix:\n",
    "- The process of rotating an object with respect to an angle in a two-dimensional plane is 2D rotation. We accomplish this rotation with the help of a 2 x 2 rotation matrix that has the standard form.\n",
    "- The **counter clockwise rotation matrix** in 2-D is given as:\n",
    "\n",
    "$\\hspace{2 cm}  R =  \\begin{bmatrix} cos\\theta & -sin\\theta  \\\\ sin\\theta & cos\\theta  \\end{bmatrix} $\n",
    "\n",
    "- The **clockwise rotation matrix** in 2-D is given as:\n",
    "\n",
    "$\\hspace{2 cm}   R^T = \\begin{bmatrix} cos(-\\theta) & -sin(-\\theta)  \\\\ sin(-\\theta) & cos(-\\theta)  \\end{bmatrix}  = \n",
    "\\begin{bmatrix} cos\\theta & sin\\theta  \\\\ -sin\\theta & cos\\theta  \\end{bmatrix} $\n",
    "\n",
    "- Let us apply a counter clockwise rotation matrix to a 2-D vector:\n",
    "\n",
    "$\\hspace{2 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} cos\\theta & -sin\\theta  \\\\ sin\\theta & cos\\theta  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{3 cm}x_2 = x_1cos\\theta - y_1sin\\theta$\n",
    "\n",
    "$\\hspace{3 cm}y_2 = x_1sin\\theta + y_1cos\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ee0b1",
   "metadata": {},
   "source": [
    "**Example:**  If $\\overrightarrow{v_1} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}$ is rotated in the **counter clockwise direction** by 90 degrees, what are the coordinate values of new vector $\\overrightarrow{v_2}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccda3add",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2, 3])\n",
    "theta = 90*math.pi/180   # the input to sin() and cos() should be in radians\n",
    "A = np.array([[math.cos(theta), -math.sin(theta)], \n",
    "              [math.sin(theta), math.cos(theta)]\n",
    "             ])\n",
    "\n",
    "v2 = np.dot(A, v1)\n",
    "print(\"Rotation matrix A:\\n\", A)\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b6d00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation matrix (90 degrees), in counter clockwise direction on all points in a 2-D plane\n",
    "theta = 90*math.pi/180   # the input to sin() and cos() should be in radians\n",
    "A = np.array([[math.cos(theta), -math.sin(theta)], \n",
    "              [math.sin(theta), math.cos(theta)]\n",
    "             ])\n",
    "print(A)\n",
    "plot_linear_transformation(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51607ae4",
   "metadata": {},
   "source": [
    "**Example:**  If $\\overrightarrow{v_1} = \\begin{bmatrix} 2 \\\\ 3 \\end{bmatrix}$ is rotated in the **counter clockwise direction** by 45 degrees, what are the coordinate values of new vector $\\overrightarrow{v_2}$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1bcec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = np.array([2, 3])\n",
    "theta = 45*math.pi/180   # the input to sin() and cos() should be in radians\n",
    "A = np.array([[math.cos(theta), -math.sin(theta)], \n",
    "              [math.sin(theta), math.cos(theta)]\n",
    "             ])\n",
    "v2 = np.dot(A, v1)\n",
    "print(\"Rotation matrix A:\\n\", A)\n",
    "print(\"v1 = \", v1)\n",
    "print(\"v2 = \", v2)\n",
    "\n",
    "plot_vector([v1])\n",
    "pyplot.title(\"Before Transformation\");\n",
    "plot_vector([v2])\n",
    "pyplot.title(\"After Transformation\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bff67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply rotation matrix (45 degrees), in counter clockwise direction on all points in a 2-D plane\n",
    "theta = 45*math.pi/180   # the input to sin() and cos() should be in radians\n",
    "A = np.array([[math.cos(theta), -math.sin(theta)], \n",
    "              [math.sin(theta), math.cos(theta)]\n",
    "             ])\n",
    "plot_linear_transformations(A, numpy.linalg.inv(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b16c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800f13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a292c2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6731309d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0449a87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb1762f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c367937",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af31a237",
   "metadata": {},
   "source": [
    "### f. Applying a Translation Matrix:\n",
    "$$\n",
    "\\overrightarrow{v_2} = A\\overrightarrow{v_1} + t\n",
    "$$\n",
    "\n",
    "$$\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 \\\\  0 & 1  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\end{bmatrix} +\n",
    "    \\begin{bmatrix} t_x \\\\ t_y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ 1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 & t_x \\\\ 0 & 1 & t_y \\\\ 0 & 0 & 1  \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ 1\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "$\\hspace{10 cm}x_2 = x_1 + t_x$\n",
    "\n",
    "$\\hspace{10 cm}y_2 = x_1 + t_y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a254c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390c662c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9b8da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c54361d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc4093f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4556a46e",
   "metadata": {},
   "source": [
    "### g. Apply Multiple Transformations Simultaneously\n",
    "- A single matrix can apply multiple affine transforms simultaneously. \n",
    "- Let us apply scaling and then rotation on a 2-D plane.\n",
    "- Remember, the order is important, as the output image will be different if you rotate first and then scale.\n",
    "- Let us understand this practically:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373183bb",
   "metadata": {},
   "source": [
    "**Example:** Apply two transformations: Scaling and then rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.array([[2, 0], [0, 4]])\n",
    "\n",
    "theta = 90*math.pi/180\n",
    "R = np.array([[math.cos(theta), -math.sin(theta)], \n",
    "              [math.sin(theta), math.cos(theta)]\n",
    "             ])\n",
    "print(\"S: \\n\",S)\n",
    "print(\"R: \\n\",R)\n",
    "plot_linear_transformations(S,R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ed3be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_linear_transformations(R,S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938e93c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf78733",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f407213d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c677893a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd178ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f793eb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b97b38",
   "metadata": {},
   "source": [
    "## 3. Scaling, Translation and Rotation in Three Dimensional Space\n",
    "- A 3-D Linear Transformation matrix is shown below:<br><br>\n",
    "\n",
    "$\\hspace{3 cm}\n",
    "  A\\hspace{.5 cm}=\\hspace{.5 cm} \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\  a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33}  \\end{bmatrix} \n",
    "  \\hspace{.5 cm}=\\hspace{.5 cm}\n",
    "  \\begin{bmatrix} a_{11} & a_{12} & a_{13} & 0\\\\  a_{21} & a_{22} & a_{23} & 0 \\\\ a_{31} & a_{32} & a_{33}  & 0 \\\\ 0&0&0&1 \\end{bmatrix} \n",
    "$\n",
    "\n",
    "$\\hspace{4 cm}\\overrightarrow{v_2} \\hspace{.5 cm}=\\hspace{.5 cm} A\\overrightarrow{v_1}$\n",
    "\n",
    "\n",
    "\n",
    "$\\hspace{3 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\z_2\\end{bmatrix} \\hspace{.5 cm}= \\hspace{.5 cm}\n",
    "   \\begin{bmatrix} a_{11} & a_{12} & a_{13} \\\\  a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1\\end{bmatrix}\n",
    "\\hspace{3 cm}\n",
    "   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\ 1\\end{bmatrix} \\hspace{.5 cm}= \\hspace{.5 cm}\n",
    "\\begin{bmatrix} a_{11} & a_{12} & a_{13} & 0\\\\  a_{21} & a_{22} & a_{23} & 0 \\\\ a_{31} & a_{32} & a_{33}  & 0 \\\\ 0&0&0&1 \\end{bmatrix}\n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1\\\\ 1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "\n",
    "$\\hspace{2 cm}x_2 = a_{11}x_1 + a_{12}y_1 + a_{13}z_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = a_{21}x_1 + a_{22}y_1 + a_{23}z_1$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = a_{31}x_1 + a_{32}y_1 + a_{33}z_1$\n",
    "\n",
    "\n",
    "> The matrix $A$ represents the **linear transformation** that takes vector $\\overrightarrow{v_1} \\hspace{.2 cm}(x_1, y_1,z_1)$ and transforms it into $\\overrightarrow{v_2}\\hspace{.2 cm} (x_2, y_2, z_2)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92ff562",
   "metadata": {},
   "source": [
    "**3-D Scaling:**<br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} S_x & 0 & 0 & 0\\\\  0 & S_y & 0 & 0 \\\\ 0 & 0 & S_z & 0 \\\\ 0 & 0 & 0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = a_{11}x_1 + a_{12}y_1 + a_{13}z_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = a_{21}x_1 + a_{22}y_1 + a_{23}z_1$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = a_{31}x_1 + a_{32}y_1 + a_{33}z_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba9c2e5",
   "metadata": {},
   "source": [
    "**3-D Translation:**<br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 & 0 & t_x\\\\  0 & 1 & 0 & t_y \\\\ 0 & 0 & 1 & t_z \\\\ 0 & 0 & 0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1 + t_x$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = y_1 + t_y$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = z_1 + t_z$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46113d6c",
   "metadata": {},
   "source": [
    "**3-D Counter Clockwise Rotation about Z-axis by an angle $\\theta$:**<br><br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} cos\\theta & -sin\\theta & 0 & 0\\\\  sin\\theta & cos\\theta & 0 & 0 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1cos\\theta - y_1sin\\theta$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = x_1sin\\theta + y_1cos\\theta$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = z_1$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646f2c83",
   "metadata": {},
   "source": [
    "**3-D Counter Clockwise Rotation about X-axis by an angle $\\gamma$:**<br><br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} 1 & 0 &0 & 0 \\\\ 0 & cos\\gamma & -sin\\gamma & 0 \\\\ 0 & sin\\gamma & cos\\gamma & 0 \\\\ 0 & 0 & 0& 1   \\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = y_1cos\\gamma - z_1sin\\gamma$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = y_1sin\\gamma + z_1cos\\gamma$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3309adfb",
   "metadata": {},
   "source": [
    "**3-D Counter Clockwise Rotation about Y-axis by an angle $\\beta$:**<br><br>\n",
    "$\\hspace{2 cm}   \\begin{bmatrix} x_2 \\\\ y_2 \\\\ z_2 \\\\1\\end{bmatrix} = \n",
    "   \\begin{bmatrix} cos\\beta & 0 & sin\\beta & 0 \\\\ 0 & 1  & 0 &1 \\\\ -sin\\beta & 0 & cos\\beta & 0 \\\\ 0&0&0&1\\end{bmatrix} \n",
    "    \\begin{bmatrix} x_1 \\\\ y_1 \\\\ z_1 \\\\1\\end{bmatrix}\n",
    "$\n",
    "\n",
    "$\\hspace{2 cm}x_2 = x_1cos\\beta + z_1sin\\beta$\n",
    "\n",
    "$\\hspace{2 cm}y_2 = y_1$\n",
    "\n",
    "$\\hspace{2 cm}z_2 = -x_1sin\\beta + z_1cos\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9380fd3",
   "metadata": {},
   "source": [
    "## Hierarchy of Transformations:\n",
    "- **Isometric Transformations:** After any of these transformations (rotation/turn, reflection/flip or translation/slide), the shape still has the same size, area, angles and line lengths.\n",
    "- **Similarity Transformation:** Includes above transformations plus scaling, so after this the object is resized. However, area, angles and line lengths remain same.\n",
    "- **Affine Transformation** is any transformation that preserves co-linearity (i.e., all points lying on a line initially still lie on a line after transformation) and preserves ratios of distances (e.g., the midpoint of a line segment remains the midpoint after transformation).\n",
    "- **Projective Transformation** is any transformation (camera image) in which parallelism, lengths and angles are not preserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1f32ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a58d844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73185a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5c6f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0435d7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04786eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8d6ed1f",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section V: (Eigen Decomposition and SVD) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520f41b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "import sklearn\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eee4a2",
   "metadata": {},
   "source": [
    "## 1. What is Matrix Decomposition?\n",
    "- We all have done factorization or prime factorization of integers:\n",
    "    - $ 18 = 9 * 2$\n",
    "    - $ 18 = 3 * 3 * 2$\n",
    "    - $ 18 = 6 * 3$\n",
    "    - $ 18 = 2 * 3 * 3$\n",
    "\n",
    "- Similar to factorizing an integer into its prime factors, Matrix decomposition is the process of **reducing a matrix to its constituent parts** in order to make certain subsequent matrix calculations simpler. \n",
    "- There are different types of matrix decompositions like:\n",
    "    - `Eigendecomposition`\n",
    "    - `Singular Value Decomposition`\n",
    "    - `LU Decomposition`\n",
    "    - `LR Decomposition`\n",
    "    - `QR Decomposition`\n",
    "    - `Cholesky Decomposition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92435f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a40822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e3fea2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "775c4dd6",
   "metadata": {},
   "source": [
    "## 2. Eigenvalues and Eigenvectors (An Abstract View) \n",
    "<h4 align=\"center\">\"Eigenvectors of a transformation matrix $A$ are the vectors that doesnot change their orientation, but just scales by a factor of its corresponding eigenvalues\"</h4>\n",
    "<h2>$$A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$$</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28448ebe",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen1.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562dd65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420002f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89086f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3249b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c693390c",
   "metadata": {},
   "source": [
    "<h4 align=\"center\">\"Eigenvectors of a transformation matrix $A$ are the vectors that doesnot change their orientation, but just scales by a factor of its corresponding eigenvalues\"</h4>\n",
    "<h2>$$A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$$</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123aba79",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen3.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6dd901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93cde5e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e231e71f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bf714e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7729ba84",
   "metadata": {},
   "source": [
    "<h4 align=\"center\">\"Eigenvectors of a transformation matrix $A$ are the vectors that doesnot change their orientation, but just scales by a factor of its corresponding eigenvalues\"</h4>\n",
    "<h2>$$A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$$</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c9936d",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"600\" height=\"500\"  src=\"images/LA/eigen4.png\"  >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3c1873",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2b9c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1e5ec2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b66039",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "843180ef",
   "metadata": {},
   "source": [
    "## 3. Eigenvectors and Eigenvalues of a Matrix A\n",
    "<h4 align=\"center\">\"Eigenvectors of a transformation matrix $A$ are the vectors that doesnot change their orientation, but just scales by a factor of its corresponding eigenvalues\"</h4>\n",
    "<h2>$$A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$$</h2>\n",
    "- When a transformation is applied, most of the vectors are knocked off their span, however, some stay on their span.\n",
    "$$A = \\begin{bmatrix}1 & 2 \\\\ 3 & -4 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "$$\\begin{bmatrix}1 & 2 \\\\ 3 & -4 \\end{bmatrix}\\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}\\hspace{.5 cm} = \\hspace{.5 cm}\\begin{bmatrix}4 \\\\ 2 \\end{bmatrix}\\hspace{.5 cm} = \\hspace{.5 cm}2\\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}$$\n",
    "\n",
    "$$\\begin{bmatrix}1 & 2 \\\\ 3 & -4 \\end{bmatrix}\\begin{bmatrix}-1 \\\\ 3 \\end{bmatrix}\\hspace{.5 cm} = \\hspace{.5 cm}\\begin{bmatrix}5 \\\\ -15 \\end{bmatrix}\\hspace{.5 cm} = \\hspace{.5 cm}-5\\begin{bmatrix}-1 \\\\ 3 \\end{bmatrix}$$\n",
    "\n",
    "- So the transformation matrix $A = \\begin{bmatrix}1 & 2 \\\\ 3 & -4 \\end{bmatrix}$ has two eigen vectors:\n",
    "    - $\\begin{bmatrix}2 \\\\ 1 \\end{bmatrix}$, with eigenvalue of 2.<br><br>\n",
    "    - $\\begin{bmatrix}-1 \\\\ 3 \\end{bmatrix}$, with eigenvalue of -5.\n",
    "    \n",
    "    \n",
    "- We can normalize the eigenvectors by dividing the elements by $L^2$ norm.:\n",
    "    - $\\begin{bmatrix}\\frac{2}{\\sqrt5} \\\\ \\frac{1}{\\sqrt5} \\end{bmatrix}$, with eigenvalue of 2.<br><br>\n",
    "    - $\\begin{bmatrix}\\frac{-1}{\\sqrt10} \\\\ \\frac{3}{\\sqrt10} \\end{bmatrix}$, with eigenvalue of -5.\n",
    "   \n",
    "- These two vectors are called eigenvectors, each having an associated eigenvalue, which is the factor by which it is stretched or squished. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0034a7a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786d1f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892fd097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8face1c7",
   "metadata": {},
   "source": [
    "## 4. How to Calculate Eigenvalues and Eigenvectors? (Paper Pencil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab6ead3",
   "metadata": {},
   "source": [
    "<h4 align=\"center\">\"Eigenvectors of a transformation matrix $A$ are the vectors that doesnot change their orientation, but just scales by a factor of its corresponding eigenvalues\"</h4>\n",
    "<h2>$$A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$$</h2>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3}& \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}& \\cdots & a_{2,n} \\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}&\\cdots & a_{3,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  \\\\\n",
    "a_{n,1} & a_{n,2} & a_{n,3}& \\cdots & a_{n,n} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}v_1\\\\v_2\\\\v_3\\\\ \\vdots \\\\v_n \\end{bmatrix}\n",
    "=\\lambda \\begin{bmatrix}v_1\\\\v_2\\\\v_3\\\\ \\vdots\\\\v_n \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- A vector is an **eigenvector** $\\overrightarrow{\\rm v}$ of a transformation matrix $A$, such that when it is transformed by the matrix, the product $A\\overrightarrow{\\rm v}$ has the exact same direction as $\\overrightarrow{\\rm v}$.\n",
    "- An **eigenvalue** is a scalar quantity (denoted by $\\lambda$) that simply scales the eigenvector $v$ such that the following equation is satisfied: \n",
    "$$A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$$\n",
    "\n",
    "- The expression means multiplying the matrix $A$, with vector $\\overrightarrow{\\rm v}$, is the same as multiplying the vector $\\overrightarrow{\\rm v}$ with scalar value $\\lambda$\n",
    "- The above equation says, that when we apply the transformation matrix $A$ to the eigenvector $v$, that is exactly equal to when we multiply the lambda scalar value to the vector $v$. On one side of equation we are applying a matrix to a vector, while on the other side we are applying a scalar to a vector.\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3}& \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}& \\cdots & a_{2,n} \\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}&\\cdots & a_{3,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  & \\vdots\\\\\n",
    "a_{n,1} & a_{n,2} & a_{n,3}& \\cdots & a_{n,n} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}v_1\\\\v_2\\\\v_3\\\\ \\vdots \\\\v_n \\end{bmatrix}=\n",
    "\\begin{bmatrix}\n",
    "\\lambda & 0       & 0      & \\cdots & 0 \\\\\n",
    "0       & \\lambda & 0      & \\cdots & 0 \\\\\n",
    "0      & 0        & \\lambda&\\cdots  & 0 \\\\\n",
    "\\vdots &\\vdots    & \\ddots & \\vdots & \\vdots \\\\\n",
    "0      & 0        & 0      & \\cdots  & \\lambda \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}v_1\\\\v_2\\\\v_3\\\\ \\vdots\\\\v_n \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3}& \\cdots & a_{1,n} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}& \\cdots & a_{2,n} \\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}&\\cdots & a_{3,n} \\\\\n",
    "\\vdots  & \\vdots  & \\ddots & \\vdots  & \\vdots\\\\\n",
    "a_{n,1} & a_{n,2} & a_{n,3}& \\cdots & a_{n,n} \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}v_1\\\\v_2\\\\v_3\\\\ \\vdots \\\\v_n \\end{bmatrix}=\\lambda\n",
    "\\begin{bmatrix}\n",
    "1 & 0       & 0      & \\cdots & 0 \\\\\n",
    "0       & 1 & 0      & \\cdots & 0 \\\\\n",
    "0      & 0        & 1&\\cdots  & 0 \\\\\n",
    "\\vdots &\\vdots    & \\ddots & \\vdots & \\vdots \\\\\n",
    "0      & 0        & 0      & \\cdots  & 1 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}v_1\\\\v_2\\\\v_3\\\\ \\vdots\\\\v_n \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "$$A\\overrightarrow{\\rm v} = (\\lambda I) \\overrightarrow{\\rm v}$$\n",
    "\n",
    "$$A\\overrightarrow{\\rm v} - (\\lambda I) \\overrightarrow{\\rm v} = 0$$\n",
    "\n",
    "$$(A-\\lambda I)\\overrightarrow{\\rm v} = 0$$\n",
    "\n",
    "- The above equation means that the matrix $M=(A-\\lambda I)$ has a non-zero vector $\\overrightarrow{\\rm v}$ in its null space. So when we apply this matrix $M$ on vector $\\overrightarrow{\\rm v}$, we get a zero vector. \n",
    "- Therefore, one can say that matrix $(A-\\lambda I)$ is non-invertible, i.e., its determinant is zero:\n",
    "\n",
    "$$det(A-\\lambda I) = 0$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a3d881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "14fe1a9b",
   "metadata": {},
   "source": [
    "**Example 1-A:** Use paper pencil to determine the Eigenvalues and Eigenvectors of a transformation matrix  $A = \\begin{bmatrix} 1 & 2 \\\\ 3 & -4\\end{bmatrix}_{2x2}$, and later verify that the eigenvalues and eigenvectors satisfies the equation $A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62e81b6",
   "metadata": {},
   "source": [
    ">- **`Step 1:` Calculate eigenvalues by solving $det(A-\\lambda I)=0$**\n",
    "\n",
    "$$\n",
    "(A-\\lambda I)\\hspace{.5 cm}=\\hspace{.5 cm}\n",
    "\\begin{bmatrix} 1 & 2 \\\\  3 & -4 \\end{bmatrix}\n",
    "- \\lambda \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\n",
    "\\begin{bmatrix} 1 & 2 \\\\  3 & -4 \\end{bmatrix}\n",
    "- \\begin{bmatrix} \\lambda & 0 \\\\ 0 & \\lambda \\end{bmatrix} \\hspace{.5 cm}=\\hspace{.5 cm}\n",
    "\\begin{bmatrix} 1-\\lambda & 2 \\\\  3 & -4-\\lambda \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$\\hspace{2 cm} det(A-\\lambda I)\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{vmatrix} 1-\\lambda & 2 \\\\  3 & -4-\\lambda \\end{vmatrix}\n",
    "\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} (1-\\lambda)(-4 - \\lambda)- (2)(3) \\hspace{.5 cm}=\\hspace{.5 cm}0$\n",
    "\n",
    "$\\hspace{2 cm} -4 - \\lambda + 4\\lambda + \\lambda^2 -6 \\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} \\lambda^2 +  3\\lambda - 10 \\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} \\lambda^2 +  5\\lambda -  2\\lambda - 10 \\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} \\lambda(\\lambda + 5) -  2(\\lambda + 5) \\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} (\\lambda + 5) (\\lambda - 2) \\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} \\lambda_1 = 2,\\hspace{2 cm} \\lambda_2 = -5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea40a3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb707318",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba03c40b",
   "metadata": {},
   "source": [
    ">- **`Step 2:` Calculate $1^{st}$ eigenvector by solving $(A-\\lambda I)\\overrightarrow{\\rm v} = 0$ for eigenvalue $\\lambda_1 = 2$**\n",
    "\n",
    "$\\hspace{2 cm} (A-\\lambda I)\\overrightarrow{\\rm v}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{bmatrix} 1-\\lambda_1 & 2 \\\\  3 & -4-\\lambda_1 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "- Substitute $\\lambda_1 = 2$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{bmatrix} 1-2 & 2 \\\\  3 & -4-2 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{bmatrix} -1 & 2 \\\\  3 & -6 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} -v_1 +2v_2\\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} 3v_1 -6v_2\\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "- Both the equations are same, so you can use any eigenvector such that $v_1 = 2v_2$.\n",
    "\n",
    "- So there is a whole family of eigen vectors that satisfies this, and some are: $\\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix},\\begin{bmatrix} 6 \\\\ 3 \\end{bmatrix}\\cdots$\n",
    "\n",
    "- You can verify by calculating $A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$, by plugging $A = \\begin{bmatrix} 1 & 2 \\\\ 3 & -4\\end{bmatrix}$, $\\lambda=2$, and using $\\overrightarrow{\\rm v}$ as any of the family of above eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be55b994",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9faad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40a9e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d6c41fd",
   "metadata": {},
   "source": [
    ">- **`Step 3:` Calculate $2^{nd}$ eigenvector by solving $(A-\\lambda I)\\overrightarrow{\\rm v} = 0$ for eigenvalue $\\lambda_1 = -5$**\n",
    "\n",
    "$\\hspace{2 cm} (A-\\lambda I)\\overrightarrow{\\rm v}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{bmatrix} 1-\\lambda_2 & 2 \\\\  3 & -4-\\lambda_2 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "- Substitute $\\lambda_2 = -5$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{bmatrix} 1+5 & 2 \\\\  3 & -4+5 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} \\begin{bmatrix} 6 & 2 \\\\  3 & 1 \\end{bmatrix}\\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}\\hspace{.5 cm}=\\hspace{.5 cm}\\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$\n",
    "\n",
    "$\\hspace{2 cm} 6v_1 +2v_2\\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "$\\hspace{2 cm} 3v_1 +v_2\\hspace{.5 cm}=\\hspace{.5 cm} 0$\n",
    "\n",
    "- Both the equations are same, so you can use any eigenvector such that $v_2 = -3v_1$.\n",
    "\n",
    "- So there is a whole family of eigen vectors that satisfies this, and some are: $\\begin{bmatrix} 1 \\\\ -3 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ -6 \\end{bmatrix},\\begin{bmatrix} 3 \\\\ -9 \\end{bmatrix}\\cdots$\n",
    "\n",
    "\n",
    "- You can verify by calculating $A\\overrightarrow{\\rm v} = \\lambda \\overrightarrow{\\rm v}$, by plugging $A = \\begin{bmatrix} 1 & 2 \\\\ 3 & -4\\end{bmatrix}$, $\\lambda=-5$, and using $\\overrightarrow{\\rm v}$ as any of the family of above eigenvectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588bde72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186b0d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5605ae89",
   "metadata": {},
   "source": [
    ">- **`Step 4:` Normalize the eigenvectors by dividing the elements by $L^2$ norm**\n",
    "    - $\\begin{bmatrix}\\frac{2}{\\sqrt5} \\\\ \\frac{1}{\\sqrt5} \\end{bmatrix}$, with eigenvalue of 2.<br><br>\n",
    "    - $\\begin{bmatrix}\\frac{-1}{\\sqrt10} \\\\ \\frac{3}{\\sqrt10} \\end{bmatrix}$, with eigenvalue of -5.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238772f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f98159",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b0d401",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886e60b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a05629d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eb11d59d",
   "metadata": {},
   "source": [
    "## 5. How to Calculate Eigenvalues and Eigenvectors? (Python Code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7c88f",
   "metadata": {},
   "source": [
    "**Example 1-B:** Write Python code to determine the Eigenvalues and Eigenvectors of a transformation matrix  $A = \\begin{bmatrix} 1 & 2 \\\\ 3 & -4\\end{bmatrix}_{2x2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a4ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, -4]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"Columns of matrix are eigenvectors:\\n\", V) \n",
    "print(\"\\nEigenvalues corresponding to each Eigenvector: \", lambdas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb28ccff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae2d991",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aaf90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5902d705",
   "metadata": {},
   "source": [
    "**Example 1-C:** Apply the transformation matrix  $A = \\begin{bmatrix} 1 & 2 \\\\ 3 & -4\\end{bmatrix}$ on any of the family of $1^{st}$ eigenvector you have computed above and plot the vector before and after transformation.\n",
    "$$\\begin{bmatrix}  0.894 \\\\ 0.447 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}, \\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix},\\begin{bmatrix} 6 \\\\ 3 \\end{bmatrix}\\cdots$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2413b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ev = V[:,0]          #slice the first column from matrix of eigenvectors\n",
    "first_ev = np.array([2,1])\n",
    "first_ev = np.array([4,2])\n",
    "new = np.dot(A, first_ev)\n",
    "print(\"First Eigenvector = \", first_ev)\n",
    "print(\"After Transformation = \", new)\n",
    "\n",
    "vectors = [first_ev, new]\n",
    "plot_vector(vectors)\n",
    "pyplot.title(\"$\\lambda = 2$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b65277",
   "metadata": {},
   "source": [
    "Note that once we apply the transformation matrix to eigenvector $v$, its direction remains the same. Moreover, it's length has increased two times, and that corresponds exactly to its eigenvalue and that is 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02a0289",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae19b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee103f82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e2922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ffc4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406694aa",
   "metadata": {},
   "source": [
    "**Example 1-D:** Apply the transformation matrix  $A = \\begin{bmatrix} 1 & 2 \\\\ 3 & -4\\end{bmatrix}$ on any of the family of $2^{nd}$ eigenvector you have computed above and plot the vector before and after transformation.\n",
    "$$\\begin{bmatrix}  0.316 \\\\ -0.948 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ -3 \\end{bmatrix}, \\begin{bmatrix} 2 \\\\ -6 \\end{bmatrix},\\begin{bmatrix} 3 \\\\ -9 \\end{bmatrix}\\cdots$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9422dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_ev = V[:,1]                #slice the second column from matrix of eigenvectors\n",
    "second_ev = np.array([2, -6])          # second_ev = np.array([-2, 6])\n",
    "second_ev = np.array([3, -9])          # second_ev = np.array([-3, 9])\n",
    "second_ev = np.array([1, -3])          # second_ev = np.array([-1, 3])\n",
    "second_ev = V[:,1]\n",
    "new = np.dot(A, second_ev)\n",
    "print(\"Second Eigenvector = \", second_ev)\n",
    "print(\"After Transformation = \", new)\n",
    "\n",
    "vectors = [second_ev, new]\n",
    "plot_vector(vectors)\n",
    "pyplot.title(\"$\\lambda = -5$\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2920d9d2",
   "metadata": {},
   "source": [
    "Note that once we apply the transformation matrix to vector $v$, its direction becomes exactly opposite. Moreover, it's length has increased five times, and that corresponds exactly to its eigenvalue and that is -5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0cb208",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4f30886",
   "metadata": {},
   "source": [
    "**Example 1-E:** Confirm that $Av = \\lambda v$ for the first eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4d2584",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_ev = V[:,0]   # slice the first column from matrix of eigenvectors\n",
    "lamb1 = lambdas[0]   # get the first scalar value from the vector of eigenvalues\n",
    "#lhs = np.dot(A, first_ev)\n",
    "lhs = A @ first_ev\n",
    "rhs = lamb1 * first_ev\n",
    "print(\"First Eigenvector: \", first_ev)\n",
    "print(\"First Eigenvalue: \", lamb1)\n",
    "print(\"Av = \", lhs)\n",
    "print(\"𝜆𝑣 = \", rhs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9300a9ee",
   "metadata": {},
   "source": [
    "**Example 1-F:** Confirm that $Av = \\lambda v$ for the second eigenvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d3b0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_ev = V[:,1]   # slice the first column from matrix of eigenvectors\n",
    "lamb2 = lambdas[1]   # get the first scalar value from the vector of eigenvalues\n",
    "#lhs = np.dot(A, second_ev)\n",
    "lhs = A @ second_ev\n",
    "rhs = lamb2 * second_ev\n",
    "print(\"Second Eigenvector: \", second_ev)\n",
    "print(\"Second Eigenvalue: \", lamb2)\n",
    "print(\"Av = \", lhs)\n",
    "print(\"𝜆𝑣 = \", rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b0f97a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed8468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238920a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1c8367",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a0c01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964517ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93cd803a",
   "metadata": {},
   "source": [
    "## 6. Some Points to Ponder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f94e86",
   "metadata": {
    "id": "d2MIHl4MLWw0"
   },
   "source": [
    "### a. Relationship between Determinant and Eigenvalues of a Matrix\n",
    "- There exist a very simple relationship between determinant of a matrix and its eigenvalues, and that is the determinant of a matrix $A$ is equal to the product of all its eigenvalues:\n",
    "\n",
    "<h4 align=\"center\">$det(A)\\hspace{.4 cm}=\\hspace{.4 cm}$ Product of all eigenvalues of $A$</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20f5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2, 4], [2, -1, 3], [0, 5, 1]])\n",
    "det = np.linalg.det(A)\n",
    "print(\"Matrix A :\\n\", A)\n",
    "print(\"\\ndet(A) = \", det)\n",
    "\n",
    "\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"\\nEigenvalues of matrix A:\", lambdas)\n",
    "rhs = np.product(lambdas)\n",
    "print(\"\\nProduct of eigenvalues of matrix A: \", rhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e75d0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fc2567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed3badb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc92201f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e85b92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bf6f3be",
   "metadata": {},
   "source": [
    "### b. Relationship between Trace and Eigenvalues of a Matrix\n",
    "- There exist a very simple relationship between trace of a matrix and its eigenvalues, and that is the trace of some matrix $A$ is equal to the sum of all eigenvalues of $A$:\n",
    "\n",
    "<h4 align=\"center\">Trace of a matrix $\\hspace{.4 cm}=\\hspace{.4 cm}$ Sum of eigenvalues</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 2], [3, -4]])\n",
    "det = np.linalg.det(A)\n",
    "print(\"Matrix A :\\n\", A)\n",
    "\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"\\nEigenvalues of matrix A:\", lambdas)\n",
    "print(\"\\nSum of eigenvalues of matrix A: \", np.sum(lambdas))\n",
    "print(\"\\nTrace if matrix A: \", np.trace(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37405701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78c106f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97afea07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ae2e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa0a1bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "beaf503b",
   "metadata": {},
   "source": [
    "### c. Not all Transformation Matrices has real Eigenvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bcb667",
   "metadata": {},
   "source": [
    "**Example:** Find the Eigenvalues and Eigenvectors of transformation matrix  $A = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0\\end{bmatrix}$. Verify that this matrix has no eigenvalues in the real domain, however, in the complex field has two eigenvalues: ±𝑖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2540258",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[0, -1], [1, 0]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"Eigenvectors:\\n\", V) \n",
    "print(\"\\nEigenvalues: \", lambdas) \n",
    "\n",
    "print(\"Product of eigenvalues = \", np.product(lambdas), \" and det(A)= \", np.linalg.det(A))\n",
    "print(\"\\nSum of eigenvalues = \", np.sum(lambdas), \" and trace(A) = \", np.trace(A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f8fb61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf222a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b82fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc9ece6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efc9bd9c",
   "metadata": {},
   "source": [
    "### d. Eigenvectors and Eigenvalues of a Diagonal Transformation Matrix\n",
    "- Eigenvectors of a diagonal transformation matrix are the basis vectors and the values along the diagonal are their eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3fa8a3",
   "metadata": {},
   "source": [
    "**Example :** Find the Eigenvalues and Eigenvectors of a diagonal transformation matrix  $A = \\begin{bmatrix} 2 & 0 \\\\ 0 & 2\\end{bmatrix}$. Verify that the eigenvectors of a diagonal transformation matrix are the basis vectors and the values along the diagonal are their eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f1649d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = np.array([[2, 0], [0, 2]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"Columns of matrix are eigenvectors:\\n\", V) \n",
    "print(\"\\nEigenvalues corresponding to each Eigenvector: \", lambdas) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9306e7b1",
   "metadata": {},
   "source": [
    "> So every vector in the plane is an eigenvector with an eigenvalue of 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe93229",
   "metadata": {},
   "source": [
    "**Example:** Find the Eigenvalues and Eigenvectors of a random transformation matrix  $A = \\begin{bmatrix} -1 & 0 \\\\ 0 & 2\\end{bmatrix}$. Verify that the eigenvectors of a diagonal transformation matrix are the basis vectors and the values along the diagonal are their eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27146a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 0], [0, 2]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"Columns of matrix are eigenvectors:\\n\", V) \n",
    "print(\"\\nEigenvalues corresponding to each Eigenvector: \", lambdas) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5068ecd3",
   "metadata": {},
   "source": [
    "**Example:** Find the Eigenvalues and Eigenvectors of a random transformation matrix  $A = \\begin{bmatrix} -5 & 0 & 0 \\\\ 0 & 2 & 0 \\\\ 0 & 0 & -4\\end{bmatrix}$. Verify that the eigenvectors of a diagonal transformation matrix are the basis vectors and the values along the diagonal are their eigenvalues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee53d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-5, 0, 0], [0, 2, 0],[0, 0, -4]])\n",
    "lambdas, V = np.linalg.eig(A)\n",
    "print(\"Columns of matrix are eigenvectors:\\n\", V) \n",
    "print(\"\\nEigenvalues corresponding to each Eigenvector: \", lambdas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e08ac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc6815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6191bc28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4cddd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd273f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cfc92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d82c3cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d7b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e65499f",
   "metadata": {},
   "source": [
    "## 7. Eigendecomposition\n",
    "- Eigendecomposition, is perhaps the most commonly used type of matrix decomposition.\n",
    "- To perform Eigendecomposition of a `square matrix` $A$, we first need to calculate its `eigenvalues` and `eigenvectors`. Then we write the matrix as a product of three matrices as shown below:\n",
    "<h3 align=\"center\">$A\\hspace{.4 cm}=\\hspace{.4 cm}V \\Lambda V^{-1}\\hspace{.4 cm}$</h3>\n",
    "\n",
    "- Where,\n",
    "    - $V$ is a matrix comprised of the `eigenvectors` of matrix $A$, \n",
    "    - Uppercase lambda (Λ) is the diagonal matrix comprised of the `eigenvalues` of matrix $A$\n",
    "    - $V^{-1}$ is the inverse of the matrix comprised of the eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d20e12d",
   "metadata": {},
   "source": [
    "- For a $3\\times 3$ matrix, it can be written as:\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}\\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3}\\\\\n",
    "\\end{bmatrix}=\n",
    "\\begin{bmatrix}v_1 & v_2 & v_3\\\\ v_1 & v_2 & v_3 \\\\ v_1 & v_2 & v_3\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\lambda_1 & 0       & 0\\\\\n",
    "0       & \\lambda_2 & 0\\\\\n",
    "0      & 0        & \\lambda_3\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}v_1 & v_2 & v_3\\\\ v_1 & v_2 & v_3 \\\\ v_1 & v_2 & v_3\\end{bmatrix}^{-1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d61c2fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae5b9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eaebf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6df830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "67bcc68b",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A = \\begin{bmatrix} 4 & 2\\\\ -5 & -3\\end{bmatrix}$, decompose it using eigendecomposition, and later prove that the equation $A = V \\Lambda V^{-1}$ holds true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8b57a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 2], [-5, -3]]) \n",
    "lambdas, V = np.linalg.eig(A)  # Calculate eigenvalues and eigenvectors of matrix A\n",
    "Lambda = np.diag(lambdas)      # Calculate the matrix Λ, which is the diagonal matrix of eigenvalues\n",
    "Vinv = np.linalg.inv(V)        # Calculate inverse of matrix V\n",
    "\n",
    "print(\"Matrix A: \\n\", A) \n",
    "print(\"\\nMatrix 𝑉:\\n\", V, end=' ') \n",
    "print(\"\\nMatrix Λ:\\n\", Lambda, end=' ') \n",
    "print(\"\\nMatrix 𝑉inv:\\n\", Vinv) \n",
    "\n",
    "# Now we have all the components of R.H.S of the equation. So we can confirm   𝐴=𝑉Λ𝑉−1: \n",
    "print(\"\\nMatrix 𝑉Λ𝑉−1: \\n\", V @ Lambda @ Vinv) #np.dot(V, np.dot(Lambda, Vinv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4691911",
   "metadata": {},
   "source": [
    ">This is the original matrix $A$, and this is what eigendecomposition is :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2d0e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7c6eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697b75a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620ce1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99662483",
   "metadata": {},
   "source": [
    "**Example:** A very common operation that we perform in data science is taking the power of a matrix, i.e., $A^n$. Given the matrix $A = \\begin{bmatrix} 4 & 2\\\\ -5 & -3\\end{bmatrix}$. Compute the power of this matrix $A^{16}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd128f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 2], [-5, -3]]) \n",
    "a2 = np.dot(A,A)\n",
    "a4 = np.dot(a2,a2)\n",
    "a8 = np.dot(a4,a4)\n",
    "a16 = np.dot(a8,a8)\n",
    "a16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5496b77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c170d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b574300f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550941e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1673dfc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d392271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88b31596",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A = \\begin{bmatrix} 4 & 2\\\\ -5 & -3\\end{bmatrix}$. Compute the power of this matrix $A^{16}$, by using eigendecomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db9da4",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">$A.A.A\\cdots \\cdots A $</h3>\n",
    "\n",
    "<h3 align=\"center\">$V\\Lambda V^{-1}.V\\Lambda V^{-1}.V\\Lambda V^{-1}....V\\Lambda V^{-1}$ </h3>\n",
    "\n",
    "- We know that $V.V^{-1} = I$, therefore, we can reduce above expression to:\n",
    "<h3 align=\"center\">$V\\Lambda^{16} V^{-1}$</h3>\n",
    "\n",
    "\n",
    "- Where, $\\Lambda^{16}$, in this case will be a $2\\times 2$ diagonal matrix $\n",
    "\\Lambda^{16}=\\begin{bmatrix}\n",
    "\\lambda_1^{16} & 0\\\\\n",
    "0       & \\lambda_2^{16} \n",
    "\\end{bmatrix}\n",
    "$\n",
    "\n",
    "- Now $\\Lambda^{16}$ is extremely easy to compute because it is a diagonal matrix and only non-zero elements are along the diagonal. We just take 16 numbers along the diagonal and then take their power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3c1cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[4, 2], [-5, -3]]) \n",
    "lambdas, V = np.linalg.eig(A)\n",
    "lambdas16 = lambdas**16\n",
    "Lambdas16 = np.diag(lambdas16)\n",
    "Vinv = np.linalg.inv(V)\n",
    "result = V @ Lambdas16 @ Vinv # np.dot(V,np.dot(Lambdas16,Vinv))\n",
    "print(\"\\nlambdas: \", lambdas)\n",
    "print(\"Lambdas16: \\n\", Lambdas16)\n",
    "print(\"Result: \\n\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371fbd70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33dc320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99b8b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d040554a",
   "metadata": {},
   "source": [
    "## 8. Eigendecomposition for Symmetric Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc7fc0d",
   "metadata": {},
   "source": [
    "- If matrix $A$ is a real symmetric matrix (a matrix having $A = A^T$), then you can use the tranpose instead of inverse.\n",
    "\n",
    "- To perform eigendecomposition using $A = V \\Lambda V^{-1}$, we have to calculate the inverse of a matrix $V$, which is a complex operation. (However for matrices involving complex numbers that is the only option)\n",
    "- In machine learning, most of the times, we are typically working with real symmetric matrices, which can be conveniently and efficiently decomposed into real-only eigenvectors and real-only eigenvalues using the following formula, that use transpose instead of inverse:\n",
    "<h3 align=\"center\">$A\\hspace{.4 cm}=\\hspace{.4 cm}Q \\Lambda Q^T$</h3>\n",
    "\n",
    "- Where,\n",
    "    - $Q$ is a matrix comprised of the `eigenvectors` of matrix $A$, \n",
    "    - Uppercase lambda (Λ) is the diagonal matrix comprised of the `eigenvalues` of matrix $A$\n",
    "    - $Q^T$ is the `transpose` of the matrix comprised of the eigenvectors\n",
    "\n",
    "- The only requirement is that the matrix $A$ need to be a real symmetric matrix (a matrix having $A = A^T$).\n",
    "- For a symmetric matrix $A$:\n",
    "    - The eigenvalues are real\n",
    "    - The eigenvectors are perpendicular"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d44d30",
   "metadata": {},
   "source": [
    "**Example:** Given a symmetric matrix $A = \\begin{bmatrix} 2 & 1\\\\ 1 & 2\\end{bmatrix}$, prove that the equation $A = Q \\Lambda Q^T$ holds true. Finally, also prove that Q is an orthogonal matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf709e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 1], [1, 2]]) \n",
    "lambdas, Q = np.linalg.eig(A)  # Calculate eigenvalues and eigenvectors of matrix A\n",
    "Lambda = np.diag(lambdas)      # Calculate the matrix Λ, which is the diagonal matrix of eigenvalues\n",
    "Qt = Q.T                      # Calculate transpose of matrix Q\n",
    "print(\"Matrix A: \\n\", A) \n",
    "print(\"\\nMatrix Q:\\n\", Q, end=' ') \n",
    "print(\"\\nMatrix Λ:\\n\", Lambda, end=' ') \n",
    "print(\"\\nMatrix QT:\\n\", Qt) \n",
    "# Now we have all the components of R.H.S of the equation. So we can confirm   𝐴=QΛQt: \n",
    "print(\"\\nMatrix QΛQT: \\n\", Q @ Lambda @ Qt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c0527d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29c15f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e9a92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ca05995",
   "metadata": {},
   "source": [
    "## 9. What is Singular Value Decomposition (SVD)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf9c8b",
   "metadata": {},
   "source": [
    "- Singular Value Decomposition (SVD) is a matrix decomposition technique that decomposes a matrix into a product of three matrices. \n",
    "- Unlike eigendecomposition, which is applicable to square matrix only, SVD works for rectangular matrices as well. So, unlike eigendecomposition, all matrices have an SVD, which makes it more stable. \n",
    "- SVD decomposes a matrix into:\n",
    "    - Singular vectors (analogous to eigenvectors)\n",
    "    - Singular values (analogous to eigenvalues)\n",
    "<h2 align=\"center\">$A_{m\\times n}\\hspace{.4 cm}=\\hspace{.4 cm}U_{m\\times m}\\hspace{.2 cm}\\sum _{n\\times n}\\hspace{.2 cm}V^{T}_{n\\times n}$</h2>\n",
    "<img src=\"images/LA/svd_first2.png\" style=\"width: 700px;\"/>\n",
    "Where: \n",
    "\n",
    "* $A$ is the real $m \\times n$ matrix that we wish to decompose.\n",
    "* **Left Singular Vectors:** $U$ is a $m \\times m$ orthogonal matrix, whose columns are equal to unit eigen vectors of $AA^T$.\n",
    "* **Right Singular Vectors:** $V^T$ is a $n \\times n$ orthogonal matrix, whose rows are equal to unit eigen vectors of $A^TA$.\n",
    "* **Singular Values:** $\\sum$ is a $n \\times n$ diagonal matrix, with singular values of $A$ on the main diagonal and all other values are zero. The singular values of $A$ are the square roots of the positive eigen values of $A^TA$ or $AA^T$. The singular values are arranged in decreasing order, such that $\\sigma_1 \\geq \\sigma_2 \\geq \\sigma_3 \\geq 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa869e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d8abdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af72d495",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c9e13a7a",
   "metadata": {},
   "source": [
    "<h2 align=\"center\">$A_{5\\times 3}\\hspace{.4 cm}=\\hspace{.4 cm}U_{5\\times 5}\\hspace{.2 cm}\\sum _{3\\times 3}\\hspace{.2 cm}V^{T}_{3\\times 3}$</h2>\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a_{1,1} & a_{1,2} & a_{1,3} \\\\\n",
    "a_{2,1} & a_{2,2} & a_{2,3}\\\\\n",
    "a_{3,1} & a_{3,2} & a_{3,3} \\\\\n",
    "a_{4,1} & a_{4,2} & a_{4,3}\\\\\n",
    "a_{5,1} & a_{5,2} & a_{5,3}\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "\\vdots & \\vdots & \\vdots \\\\\n",
    "\\overrightarrow{\\rm u_1} & \\overrightarrow{\\rm u_2} & \\overrightarrow{\\rm u_3}\\\\\n",
    "\\vdots & \\vdots & \\vdots \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\sigma_1 & 0         & 0  \\\\\n",
    "  0      & \\sigma_2  & 0 \\\\\n",
    "  0      & 0         & \\sigma_3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\cdots & \\overrightarrow{\\rm v_1} & \\cdots \\\\\n",
    "\\cdots & \\overrightarrow{\\rm v_2} & \\cdots \\\\\n",
    "\\cdots & \\overrightarrow{\\rm v_3} & \\cdots \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ab1e32",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/svd_first1.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75d2ea8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d908be19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee1fabc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08096aea",
   "metadata": {},
   "source": [
    "## 10. Calculating SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189bd2e0",
   "metadata": {},
   "source": [
    "### a. Determine SVD using NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd827b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 5, 3], [4, 2, 1], [9,7,6], [3,4,8], [7,5,2]])\n",
    "U, s, VT = np.linalg.svd(A)# V is already transposed and s is a vector of singular values\n",
    "S = np.diag(s)\n",
    "print(\"A:\\n\", A)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"S:\\n\", S)\n",
    "print(\"VT:\\n\", VT)\n",
    "\n",
    "\n",
    "print(\"A:\\n\",U[:, 0:3] @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28493f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84ba82b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d4e134",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f0c5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad93825",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1, 5, 3], [4, 2, 1], [9,7,6], [3,4,8], [7,5,2]])\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"S:\\n\", S)\n",
    "print(\"VT:\\n\", VT)\n",
    "print(\"U @ S @ VT:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce618f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf12774",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d59fa16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17ef438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5866ae0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39abc924",
   "metadata": {},
   "source": [
    "### b. Determine SVD using Scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05251f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "A = np.array([[1, 5, 3], [4, 2, 1], [9,7,6], [3,4,8], [7,5,2]])\n",
    "U, s, VT = scipy.linalg.svd(A, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"S:\\n\", S)\n",
    "print(\"VT:\\n\", VT)\n",
    "print(\"U @ S @ VT:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa407b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea971f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f6db16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4429c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a9b337",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bbb5ff5",
   "metadata": {},
   "source": [
    "### c. Determine SVD using Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f682762",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "A = np.array([[1, 5, 3], [4, 2, 1], [9,7,6], [3,4,8], [7,5,2]])\n",
    "U, s, VT = randomized_svd(A, n_components = 3)\n",
    "S = np.diag(s)\n",
    "\n",
    "print(\"A:\\n\", A)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"S:\\n\", S)\n",
    "print(\"VT:\\n\", VT)\n",
    "print(\"U @ S @ VT:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0883980d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea166642",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b70ceb",
   "metadata": {},
   "source": [
    "# <span style='background :lightgreen' > Section VI: (Applications of SVD and Eigendecomposition) </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f2219e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import image\n",
    "import sklearn\n",
    "from plot_helper import * # Helper functions: plot_vector, plot_linear_transformation, plot_linear_transformations\n",
    "np.set_printoptions(suppress=True, precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f27c6",
   "metadata": {},
   "source": [
    "- **Image Compression**\n",
    "- **Principal Component Analysis**\n",
    "    - Dimensionality reduction\n",
    "    - Visualization\n",
    "- **Moore Penrose Pseudo-Inverse** \n",
    "- **Recommender Systems**\n",
    "- **Latent Semantic Analysis & Document clustering**\n",
    "- **Google PageRank Algorithm**\n",
    "- **Facial Recognition Algorithms like eigenfaces**\n",
    "- **Interest point detection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caba0f88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be9ae83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661b20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27265553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1097595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d47d01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d95d5fae",
   "metadata": {},
   "source": [
    "## 1. Image Compression with SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0e79f8",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/zero.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4909fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34e88a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c172268c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "361112a2",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/svd_imgcomp1.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306601f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49d7d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f813f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f8162f4",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/svd_imgcomp2.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dff7c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8efb12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5596b9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0184a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a488e38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc7e047f",
   "metadata": {},
   "source": [
    "**Example:** Given the matrix $A$, decompose it using SVD, and later prove that the equation $A = U\\sum V^T$ holds true by reconstructing the matrix $A$ from its SVD constituent parts (step by step).\n",
    "\n",
    "<img src=\"images/LA/svd_imgcomp3.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bd8ff8",
   "metadata": {},
   "source": [
    "<h3 align=\"center\">Original Size $\\hspace{.4 cm}=\\hspace{.4 cm}m × n$</h3>\n",
    "\n",
    "<h3 align=\"center\">Compressed Size $\\hspace{.4 cm}=\\hspace{.4 cm}(m × k) + k + (k × n)$</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0767b7e6",
   "metadata": {},
   "source": [
    ">**Decompose matrix $A$ to its component matrices using SVD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41d8803",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1,4,1], [5,9,2,6], [5,3,5,8], [9,7,9,3]])\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=False)# V is already transposed and s is a vector of singular values\n",
    "S = np.diag(s)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"S:\\n\", S)\n",
    "print(\"VT:\\n\", VT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d33228",
   "metadata": {},
   "source": [
    ">**Generate matrix $A$ from its component matrices: $A = USV^T$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d0d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "U @ S @ VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f264b0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c532ebfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d6347a2",
   "metadata": {},
   "source": [
    ">**Create matrix $rv1$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1720a3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "A = np.array([[3,1,4,1], [5,9,2,6], [5,3,5,8], [9,7,9,3]])\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "rv1 = S[0,0] * U[:,0].reshape(4,1) @ VT[0,:].reshape(1,4)\n",
    "print(\"First component:\\n\", rv1)\n",
    "\n",
    "\n",
    "U, s, VT = randomized_svd(A, n_components = 1)\n",
    "S = np.diag(s)\n",
    "print(\"First component:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204c87d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e96d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc27f787",
   "metadata": {},
   "source": [
    ">**Create matrix $rv1 + rv2$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eee424",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1,4,1], [5,9,2,6], [5,3,5,8], [9,7,9,3]])\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "rv2 = S[1,1] * U[:,1].reshape(4,1) @ VT[1,:].reshape(1,4)\n",
    "print(\"First two components:\\n\", rv1 + rv2)\n",
    "\n",
    "\n",
    "U, s, VT = randomized_svd(A, n_components = 2)\n",
    "S = np.diag(s)\n",
    "print(\"First two component:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10eca11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c553d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57a850f3",
   "metadata": {},
   "source": [
    ">**Create matrix $rv1 + rv2 + rv3$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561f2949",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1,4,1], [5,9,2,6], [5,3,5,8], [9,7,9,3]])\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "rv3 = S[2,2] * U[:,2].reshape(4,1) @ VT[2,:].reshape(1,4)\n",
    "print(\"First three components:\\n\", rv1 + rv2 + rv3)\n",
    "\n",
    "\n",
    "U, s, VT = randomized_svd(A, n_components = 3)\n",
    "S = np.diag(s)\n",
    "print(\"First three component:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4721fa9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78913418",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "251ff068",
   "metadata": {},
   "source": [
    ">**Create matrix $rv1 + rv2 + rv3 + rv4$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d942918",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[3,1,4,1], [5,9,2,6], [5,3,5,8], [9,7,9,3]])\n",
    "U, s, VT = np.linalg.svd(A, full_matrices=False)# V is already transposed and s is a vector of singular values\n",
    "S = np.diag(s)\n",
    "rv4 = S[3,3] * U[:,3].reshape(4,1) @ VT[3,:].reshape(1,4)\n",
    "print(\"First four components:\\n\", rv1 + rv2 + rv3 + rv4)\n",
    "\n",
    "\n",
    "U, s, VT = randomized_svd(A, n_components = 4)\n",
    "S = np.diag(s)\n",
    "print(\"First four component:\\n\", U @ S @ VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e307510d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c277a83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b11c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f8ab27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa59c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "512c3bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e364dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78e2cef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40c1257b",
   "metadata": {},
   "source": [
    "**Example (Image Compression using SVD):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52305c3",
   "metadata": {},
   "source": [
    ">**Read a color image into a NumPy 3-D array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf8d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "imread(), reads an image from a file into an array. The returned array has shape\n",
    "    - (M, N) for grayscale images.\n",
    "    - (M, N, 3) for RGB images.\n",
    "    - (M, N, 4) for RGBA images.\n",
    "'''\n",
    "rgb_img = image.imread(\"datasets/img.jpg\")\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(rgb_img)\n",
    "print(rgb_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2b1850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2110ec3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca5d2e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cffd23c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3ced6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c932d58e",
   "metadata": {},
   "source": [
    ">**Convert to gray scale and store in a NumPy 2-D array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71c0752",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = np.mean(rgb_img, -1)\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "print(gray_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7409bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80567b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b0efac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17b0fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd84851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd4844d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4afabf25",
   "metadata": {
    "id": "x8VCD3lyj3Y-"
   },
   "source": [
    ">**Decompose using SVD:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ec2e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(gray_img, full_matrices=False)\n",
    "S = np.diag(s)\n",
    "print(\"U:\\n\", U)\n",
    "print(\"S:\\n\", S)\n",
    "print(\"VT:\\n\", VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ad9eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a53e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84beea9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021a1f37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d7b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7979b572",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16bba0d4",
   "metadata": {
    "id": "ApybkCdLj3Y-"
   },
   "source": [
    ">**Compress by taking the first `k` components:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd0867b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "compressed_img = U[:, :k] @ S[0:k, 0:k] @ VT[0:k, :]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.imshow(compressed_img, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c767e1f2",
   "metadata": {
    "id": "IjfUJ4wNj3ZA"
   },
   "source": [
    "With 100 singular vectors, the image is reconstructed quite well, however the data footprint is much smaller than the original image\n",
    "\n",
    "$$= (m × k) + k + (k × n)$$\n",
    "\n",
    "$$= (1786 × 100) + 100 + (100 × 2880)$$\n",
    "\n",
    "$$= 466700$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8b6ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SXJtpYGeLWxz",
    "outputId": "7e994526-5509-4ab4-bd1c-0b6f4c2b318c"
   },
   "outputs": [],
   "source": [
    "original_size = 1786*2880\n",
    "original_size/(2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154a2de8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vOHZXITLLWx1",
    "outputId": "6780de62-ccfd-4936-f0cb-172c2e178db4"
   },
   "outputs": [],
   "source": [
    "compressed_size = 1786*100 + 100 + 100*2880\n",
    "compressed_size/(2**20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679b8469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a406e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4852ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450987d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a52d1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f504e5af",
   "metadata": {},
   "source": [
    "# 2.  Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cededd7",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Housing Dataset</h1>\n",
    "<img src=\"images/LA/pca5.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997e9d2c",
   "metadata": {},
   "source": [
    "**Curse of Dimensionality:** \n",
    "- The `dimension` of a dataset corresponds to the number of attributes/features that exist in a dataset. \n",
    "- A dataset with a large number of attributes, generally of the order of a hundred or more, is referred to as high dimensional data.\n",
    "- The difficulties related to training machine learning models due to high dimensional data is referred to as `Curse of Dimensionality`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691e6346",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f41a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdaaa4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0c2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82278191",
   "metadata": {},
   "source": [
    "**Techniques to Reduce the Dimensionality of your dataset:** \n",
    "- The solution of the curse of dimensionality is ofcourse Dimensionality reduction, which is a way to  eliminate some features of the dataset and creates a restricted set of features that contains all of the information needed to predict the target variables more efficiently and accurately. \n",
    "- Some of the techniques of reducing the dimensionality of your dataset are:\n",
    "    - Principal Component Analysis (PCA)\n",
    "    - Linear discriminant analysis (LDA)\n",
    "    - Generalized discriminant analysis (GDA)\n",
    "    - Low Variance Filter\n",
    "    - High Correlation Filter\n",
    "    - Backward Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ee181d",
   "metadata": {},
   "source": [
    "**What is Principal Component Analysis (PCA):** \n",
    "- PCA, is a statistical procedure that allows you to summarize the information content in large data tables by means of a smaller set of “summary indices” that can be more easily visualized and analyzed.\n",
    "- PCA is an unsupervised learning algorithm, meaning that the outcome classes are not considered while doing the calculations.\n",
    "- It is a technique that transforms high-dimensions data into lower-dimensions while retaining as much information as possible.\n",
    "- It somehow extract information (feature extraction) from a high-dimensional space by projecting it into a lower-dimensional sub-space. \n",
    "- It tries to preserve the essential parts that have more variation of the data and remove the non-essential parts with fewer variation. \n",
    "- The essential parts/columns are called the Principal Components. \n",
    "- There are two applications of PCA:\n",
    "    - Speeding the Machine Learning algorithm's training and testing time.\n",
    "    - Data Visualization by projecting the dataset into two/three dimensions, which are nothing but the two/three Principal Components that holds most of the variance (information) of your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366fcc8",
   "metadata": {},
   "source": [
    "> **Note:**\n",
    ">- PCA and SVD are closely related approaches and can be both applied to decompose any rectangular matrix, and thus both can beused for dimensionality reduction. \n",
    ">- The main difference between The Singular value decomposition and principal component analysis is that the SVD is a data-driven Fourier transform generalization, whereas PCA allows us to represent statistical variations in our data sets using a hierarchical coordinate system based on data.\n",
    ">- One caveat of using the covariance matrix to calculate the PCA is that it can be hard to compute when there are many features. For this reason, it is usually preferred to use the Singular Value Decomposition (SVD) to calculate the PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6380e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8857252",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8863c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923d0d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc9e9bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "197b6b23",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/pca1.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c7111e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a021b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a699f797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b587c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883dc88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469109d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad268c20",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/pca2.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09577ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b720cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e1cca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd8d39fe",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/pca3.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bfc4e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db983c84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40237e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65add597",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/pca4.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bfe606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771513c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750adf01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fa92f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d0d40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "022e4d5d",
   "metadata": {},
   "source": [
    "<img src=\"https://builtin.com/sites/www.builtin.com/files/inline-images/national/Principal%2520Component%2520Analysis%2520second%2520principal.gif\"  style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7465d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a077d2ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e507ed2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b1d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a6b962c",
   "metadata": {},
   "source": [
    "#### Steps to Perform PCA on a Dataset\n",
    "- Suppose we have an ‘n’ dimensional data and we want to reduce it to ‘k’ dimensions. But cutting off features means loss of information. This loss of information can be minimized by keeping the maximum variance. So, we want to find out the directions in which variance is maximum. This is done using `eigenvectors of the dataset`. This process of PCA is described in the following five steps:\n",
    "    - **Step 1:** Normalize/Standardize your data to avoid biasness towards specific features.\n",
    "    - **Step 2:** Determine Covariance Matrix to identify the relationship among features.\n",
    "    - **Step 3:** Perform Eigendecomposition of Covariance Matrix to get eigenvectors and eigenvalues.\n",
    "    - **Step 4:** Select `k` eigenvectors corresponding to `k` highest eigenvalues, and create Feature/Projection Matrix containing top `k` Principal Components.\n",
    "    - **Step 5:** Transform the input dataset by multiplying it with the Projection/Feature matrix to obtain the new k-dimensional feature subspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9b8561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabe6e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68efa7db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d6a9998b",
   "metadata": {},
   "source": [
    "## Example 1: Dimensionality Reduction of  a dataset for House Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7101b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/pca_housingdata.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2f5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = df.to_numpy()\n",
    "A = A[:, 0:6]\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ad90ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7bbd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf9213e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca950d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f4caf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a44552f8",
   "metadata": {},
   "source": [
    ">**Step 1: Normalize/Standardize your data to avoid biasness towards specific features**\n",
    ">- Compute mean and stndard deviation of every column.\n",
    ">- The standardized data value can be computed by using following formula:\n",
    "$$ z = \\frac{value - mean}{stdev}$$\n",
    ">- `Standard deviation` tells us how much a (single) quantity varies w.r.t. its mean 'OR' how spread out the data is around the center of the distribution (the mean).\n",
    ">- Standard deviation of a sample can be calculated using the formula $\\sqrt{\\frac{\\sum(x_i-\\bar{x})^2}{n}}$, or by using `np.std(data)` \n",
    ">- Once the standardization is done, all the variables will be transformed to the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6832fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_vector = np.mean(A, axis=0)\n",
    "std_vector = np.std(A, axis=0)\n",
    "N = (A - mean_vector)/std_vector\n",
    "print(\"Mean of each column is: \", mean_vector)\n",
    "print(\"Standard Deviation of each column is: \", std_vector)\n",
    "print(\"Normalize data N:\\n\", N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0982c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056cfe36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21857790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa4d5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639be125",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cbd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b895292a",
   "metadata": {},
   "source": [
    ">**Step 2: Determine Covariance Matrix to identify the relationship among features.**\n",
    ">- The aim of this step is to understand how the variables of the input data set are varying from the mean with respect to each other, or in other words, to see if there is any relationship between them. Because sometimes, variables are highly correlated in such a way that they contain redundant information. So, in order to identify these correlations, we compute the covariance matrix.\n",
    ">- Covariance is a statistical measure that is used to measure as to how the mean values of two random variables move together. It measures the direction of the relationship between two features or variables. \n",
    "    - `Positive covariance`: Indicates that two variables tend to move in the same direction.\n",
    "    - `Negative covariance`: Reveals that two variables tend to move in inverse directions.\n",
    "    - `Zero covarince`: Indicates that two variables have no relationship between each other.\n",
    ">- For multi-dimensional data, we use covariance matrix also called variance-covariance matrix, as its diagonal values show variances and the other values are the covariances.\n",
    ">- Covariance can be calculated using the formula $ \\text{cov}(x, y) = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y}) }{n} $, or by using `np.cov(data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71a5cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = np.cov(N.T)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0add0f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f559b5a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8162cda8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d676069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f2d357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7ea8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7853fb0",
   "metadata": {},
   "source": [
    ">**Step 3: Perform Eigendecomposition of Covariance Matrix to get eigenvectors and eigenvalues.**\n",
    ">- In this example, you get a 6x6 matrix, because we have six features.\n",
    ">- The six columns of the resulting matrix are the six Principal Components.\n",
    ">- The eigenvector having the maximum corresponding eigenvalue is called the Principal Component 1, that holds the maximum possible information.\n",
    ">- Computing the eigenvectors and ordering them by their eigenvalues in descending order, allow us to find the principal components in order of significance\n",
    ">- An important thing to realize here is that, the principal components are less interpretable and don’t have any real meaning since they are constructed as linear combinations of the initial variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dc8d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas, vectors = np.linalg.eig(V)\n",
    "print(\"Eigenvectors = \\n\", vectors)\n",
    "print(\"\\nEigenvalues = \", lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bb2421",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173dd36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dfafca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d0517a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d2b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60560a2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a31b99d9",
   "metadata": {},
   "source": [
    ">**Step 4: Select `k` eigenvectors corresponding to `k` highest eigenvalues, and create Feature Matrix**\n",
    ">- Featue Vectors is a matrix that has eigenvectors of the components that we decide to keep as columns.\n",
    ">- For this we sort the eigenvalues and select the first `n` corresponding eigenvectors. \n",
    ">- For example, if you want to decrease the dimension to two from six, then take the first two eigenvectors which are corresponding to the two highest eigenvalues, i.e., 2.87 and 1.46\n",
    ">- If all eigenvalues have a similar value, that means the existing representation is already reasonably compressed or dense and that the projection may offer little. \n",
    ">- If there are eigenvalues close to zero, they represent components or axes that may be discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4678c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FM = vectors[:,0:5:3]\n",
    "FM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2e94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c05d299",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce7dec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dbb27e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236d879e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4134fce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3f742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19eaf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da803c0",
   "metadata": {},
   "source": [
    ">**Step 5: Create the Final Dataset with reduced dimensions by multiplying normalized matrix with feature matrix**\n",
    ">- Note the shape of the normalized data matrix is 9x6, while the shape of the Feature matrix having two Principal Components is 6x2, and ofcourse we can take their dot product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99300bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"N.shape: \", N.shape)\n",
    "print(\"FM.shape: \", FM.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3306e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCs = N @ FM\n",
    "print(\"\\nProjected Data = \\n\", PCs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1f8bba",
   "metadata": {},
   "source": [
    "PCA is in fact a method for doing feature extraction. In PCA, derived features are also called composite features or principal components. Moreover, these principal components are linearly independent from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = pd.DataFrame(data = PCs, columns = ['PC1', 'PC2'])\n",
    "principal_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806547c0",
   "metadata": {},
   "source": [
    "Now we can always create a new data set having just two feature columns and the output column and perform predictions on it . But this will be done in our ML module where we will be covering lot more InshaAllah."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c210d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([principal_df, df[['Price']]], axis = 1)\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873771ec",
   "metadata": {},
   "source": [
    "> Now you can use this new dataframe having just two features instead of six to run the Linear Regression or whatever machine learning model we want to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5ee87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95702a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba9fc13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b540992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61571ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e15630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bc65ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed3499da",
   "metadata": {},
   "source": [
    "## Example 2: Dimensionality Reduction using `scikit-learn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13d6cf2",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Digit Classification</h1>\n",
    "<img src=\"images/LA/pca_digits.png\" style=\"width: 900px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234ad92",
   "metadata": {},
   "source": [
    "#### Toy Datasets of Scikit-Learn Library\n",
    "\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439f3541",
   "metadata": {},
   "source": [
    ">**Step 1: Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa799886",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits_dict = sklearn.datasets.load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3215625b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922bc1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d7723c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e626c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa10e89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c30755",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fa3bf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c214bbe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2653f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3b4e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55760614",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3e047",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b0e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f952fd9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "digits_dict.data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7889914f",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.target[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a97217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c46e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46305871",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df033d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_dict.data[100].reshape(8,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c546a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(digits_dict.data[100].reshape(8,8),cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc04fc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa22866d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a065958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52193478",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame(digits_dict.data, columns=digits_dict.feature_names)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d620a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402cce50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa4f039",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(digits_dict.target, columns=['Digit'])\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca98a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b517c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e42031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a5bd76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02db215f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a7cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8833e0ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdee75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18989727",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = df1.to_numpy()\n",
    "A = digits_dict.data\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b3d3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c2117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e703294a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc6b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f773a1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ea50b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce53bc54",
   "metadata": {},
   "source": [
    ">**Step 2: Standardize Dataset**\n",
    "- If the values of dataset are not equally scaled, we need to standardize our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d113dbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create the object\n",
    "scalar = StandardScaler()\n",
    "# Calculate the mean and standard deviation\n",
    "scalar.fit(A)\n",
    "# Transform the values\n",
    "N = scalar.transform(A)\n",
    "#N = scalar.fit_transform(A)\n",
    "print(\"Normalize data N:\\n\", N)\n",
    "print(\"N.shape: \", N.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fea450",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f4cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c78832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6119d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a883c281",
   "metadata": {},
   "source": [
    ">**Step 3: Conduct PCA**\n",
    "- We first create an object of PCA() class, which is there in the decomposition module of sklearn library. We can pass following arguments to this method:\n",
    "    - None: This is the default value. If we do not specify the value, all components are kept. In our example, this exactly the same as n_components=64\n",
    "    - int: If this is a positive integer like 1, 2, 30, 100, etc, the algorithm will return that number of principal components. The integer value should be less than or equal to the original number of features in the dataset.\n",
    "    - float: If 0 < n_components < 1, PCA will select the number of components such that the amount of variance that needs to be explained. For example, if n_components=0.90, the algorithm will select the number of components while preserving 90% of the variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#pca = sklearn.decomposition.PCA()\n",
    "#pca = sklearn.decomposition.PCA(n_components=20)\n",
    "pca = sklearn.decomposition.PCA(n_components=0.9)\n",
    "\n",
    "\n",
    "#pca.fit(N)\n",
    "#PCs = pca.transform(N)\n",
    "PCs = pca.fit_transform(N)\n",
    "\n",
    "\n",
    "print(\"PCs:\\n\", PCs)\n",
    "print(\"PCs.shape: \", PCs.shape)\n",
    "print(\"A.shape: \", A.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b444738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18854e45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3425f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d7feb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12615e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.explained_variance_ratio_*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c386600",
   "metadata": {},
   "source": [
    "- PC1 is capturing 12.03% of information\n",
    "- PC2 is capturing 9.56% of information\n",
    "- ....\n",
    "- PC31 is capturing 0.73% of information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8769188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd279d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca7f0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance explained by first PC: \", np.cumsum(pca.explained_variance_ratio_*100)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce62912",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance explained by first ten PCs: \", np.cumsum(pca.explained_variance_ratio_*100)[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30322cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance explained by first twenty PCs: \", np.cumsum(pca.explained_variance_ratio_*100)[19])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variance explained by all the 31 PCs: \", np.cumsum(pca.explained_variance_ratio_*100)[30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aaabce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b9cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e2cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315ce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1982c991",
   "metadata": {},
   "source": [
    ">**Step 4: Create new Dataframe having Principal Components and the output variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f1ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "principal_df = pd.DataFrame(data = PCs)\n",
    "principal_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee02bcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([principal_df,df2], axis=1)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70dee420",
   "metadata": {},
   "source": [
    "> Now you can use this new dataframe having just 31 features instead of 64 to run whatever classification machine learning model we want to apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ccb833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b2c348",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc789475",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9c1cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e176dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5380832e",
   "metadata": {},
   "source": [
    "## Example 3: Dimensionality Reduction for Data Visualization\n",
    "- Considering that there are a large number of variables or dimensions along which the data is distributed, visualization can be a challenge and almost impossible. \n",
    "- PCA can help us project the data to two or three dimensions, thereby allowing you to visualize the data in a 2D or 3D space with a naked eye."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9e6a85",
   "metadata": {},
   "source": [
    "<img src=\"images/LA/pca6.png\" style=\"width: 1000px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94a6ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893d1b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79856c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "084b0b3d",
   "metadata": {},
   "source": [
    "<img align=\"right\" width=\"500\" height=\"500\"  src=\"images/iris.png\"  >\n",
    "\n",
    "#### Toy Datasets of Scikit-Learn Library\n",
    "https://scikit-learn.org/stable/datasets/toy_dataset.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb11d7b",
   "metadata": {},
   "source": [
    ">**Step 1: Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bd009dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris_dict = sklearn.datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da453ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ca98df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26011e49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d700b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c83459",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48992b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "803cba0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# contains 150 rows and 4 columns \n",
    "iris_dict.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8c0bb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 4)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ede4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605ccd68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40be52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66237ddd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132384c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84a94d08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9f70636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a645a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b483cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138888b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712192d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2410c4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f184b97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915e0478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "75423f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sepal length (cm)',\n",
       " 'sepal width (cm)',\n",
       " 'petal length (cm)',\n",
       " 'petal width (cm)']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00db1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211944a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f09182b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_dict.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6bca3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d47375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba2e1401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = iris_dict.data\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56056b5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e273881",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b8cbf7",
   "metadata": {},
   "source": [
    ">**Step 2: Standardize Dataset**\n",
    "- If the values of dataset are equally scaled (all measurements are in cm), you really dont have to standardize the dataset this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d61eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88d3f32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc8b527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50879b42",
   "metadata": {},
   "source": [
    ">**Step 3: Conduct PCA**\n",
    "- We first create an object of PCA() class, which is there in the decomposition module of sklearn library. We can pass following arguments to this method:\n",
    "    - None: This is the default value. If we do not specify the value, all components are kept. In our example, this exactly the same as n_components=64\n",
    "    - int: If this is a positive integer like 1, 2, 30, 100, etc, the algorithm will return that number of principal components. The integer value should be less than or equal to the original number of features in the dataset.\n",
    "    - float: If 0 < n_components < 1, PCA will select the number of components such that the amount of variance that needs to be explained. For example, if n_components=0.90, the algorithm will select the number of components while preserving 90% of the variability in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6449590c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First ten rows:\n",
      " [[-2.68  0.32]\n",
      " [-2.71 -0.18]\n",
      " [-2.89 -0.14]\n",
      " [-2.75 -0.32]\n",
      " [-2.73  0.33]\n",
      " [-2.28  0.74]\n",
      " [-2.82 -0.09]\n",
      " [-2.63  0.16]\n",
      " [-2.89 -0.58]]\n",
      "PCs.shape:  (150, 2)\n",
      "A.shape:  (150, 4)\n",
      "A.shape:  (150, 4)\n",
      "Variance explained by first PC:  92.46187232017272\n",
      "Variance explained by second PC:  5.306648311706782\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "''' \n",
    "we are asking for two principal component because we want to plot this. Compress four features of the dataset\n",
    "to just two features so that we can visualize our dataset using a 2-D plot\n",
    "four column worth of information down to two principal components\n",
    "'''\n",
    "#pca = sklearn.decomposition.PCA()\n",
    "#pca = sklearn.decomposition.PCA(n_components=0.9)\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "\n",
    "#pca.fit(A)\n",
    "#PCs = pca.transform(A)\n",
    "PCs = pca.fit_transform(A)\n",
    "\n",
    "print(\"First ten rows:\\n\", PCs[0:9, :])\n",
    "print(\"PCs.shape: \", PCs.shape)\n",
    "print(\"A.shape: \", A.shape)\n",
    "print(\"A.shape: \", A.shape)\n",
    "print(\"Variance explained by first PC: \", (pca.explained_variance_ratio_*100)[0])\n",
    "print(\"Variance explained by second PC: \",(pca.explained_variance_ratio_*100)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c00b28a",
   "metadata": {},
   "source": [
    "Now we have two principal components instead for four different features for each flower.\n",
    "- Now we can plot the two principal components using the matplotlib scatter() plot method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab9a19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8004aef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf292d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5297a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661f304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79289c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae31e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e894f018",
   "metadata": {},
   "source": [
    ">**Step 4: Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "932755df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(PCs[:, 0], PCs[:, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b3a3e4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(PCs[:, 0], PCs[:, 1], c=iris_dict.target);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c19438",
   "metadata": {},
   "source": [
    "- You can observe we have the first principal component along the x-axis and the second principal component along the y-axis\n",
    "- There are 150 data points each representing a flower in our dataset\n",
    "- You can observe there is a clear structure here, the cluster on the left shows that these flowers are different from the other group of flowers over here in some unknown way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc03e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a097a3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ee53a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6633c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f805e15",
   "metadata": {},
   "source": [
    "## 3. Calculate Pseudoinverse of a non-Square Matrix\n",
    "\n",
    "### a. Consistent and Inconsistent Systems of Linear Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178b8110",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"900\" height=\"900\"  src=\"images/LA/consistentequations1.png\"  >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370ec653",
   "metadata": {},
   "source": [
    "### b. Overdetermined Systems of Linear Equations\n",
    "- An overdetermined system of equations is a system in which the number of equations is greater than the number of unknowns. \n",
    "- Such a system cannot be solved using simple matrix inversion method, as the coefficient matrix is not square and thus cannot be inverted. \n",
    "- In machine learning many a times we have overdetermined systems that we need to solve. For example, a dataset having thousands of houses but only a few features.\n",
    "    - Consistent Overdetermined System having `Unique` Solution\n",
    "    - Consistent Overdetermined System having `Infinite` Solution\n",
    "    - In-Consistent Overdetermined System having `No` Solution\n",
    "    \n",
    "    \n",
    " <h3 align=\"center\">$ A_{n\\times m}\\hspace{.2 cm}x_{m\\times 1}\\hspace{.3 cm}=\\hspace{.3 cm}b_{n\\times 1} \\hspace{1 cm}$ and $ \\hspace{.3 cm}n\\hspace{.3 cm}\\gt\\hspace{.3 cm}m$ </h3>\n",
    " \n",
    "- Consider a system of four linear equations with two unknowns:\n",
    "\n",
    "$$ a_{1,1}x_1 + a_{1,2}x_2  = b_1 $$\n",
    "$$ a_{2,1}x_1 + a_{2,2}x_2  = b_2 $$\n",
    "$$ a_{3,1}x_1 + a_{3,2}x_2  = b_3 $$\n",
    "$$ a_{4,1}x_1 + a_{4,2}x_2  = b_4 $$\n",
    "\n",
    "\n",
    "- These three equations can be written in matrix form as:\n",
    "$$\n",
    "\\begin{bmatrix} a_{1,1} & a_{1,2} \\\\ a_{2,1} & a_{2,2} \\\\a_{3,1} & a_{3,2}\\\\a_{4,1} & a_{4,2} \\end{bmatrix}_{4\\times 2}\\hspace{.5 cm}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2  \\end{bmatrix}_{2\\times 1}\\hspace{.5 cm}=\\hspace{.5 cm} \n",
    "\\begin{bmatrix} b_1 \\\\ b_2 \\\\ b_3 \\\\ b_4 \\end{bmatrix}_{4\\times 1}\n",
    "$$\n",
    "\n",
    "$$ Ax = b$$\n",
    "\n",
    "$$  x = A^{-1}b $$\n",
    "\n",
    "- Since, $A$ is a not a square matrix, so simple inverse is not possible. However, **SVD** allows us to approximately invert a rectangular matrix $A$ to compute what is known as the **Pseudo Inverse** and then find a best fit for x.\n",
    "\n",
    "$$   x \\approx A^\\dagger b $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e09f555",
   "metadata": {},
   "source": [
    "### c. The Moore-Penrose Pseudoinverse (empower us to invert non square matrices)\n",
    "\n",
    "**Option 1:** If $A$ is a small rectangular matrix, you can make it square by multiplying it with its Transpose\n",
    "\n",
    "$\\hspace{3 cm}Ax = b$\n",
    "\n",
    "$\\hspace{3 cm}A^TAx = A^Tb$\n",
    "\n",
    "- Furthermore, when the columns of A are linearly independent, it turns out that ($A^TA$) is invertible, and so x is unique and given by:\n",
    "\n",
    "$\\hspace{3 cm}(A^TA)^{-1}(A^TA)x = (A^TA)^{-1}A^Tb$\n",
    "\n",
    "$\\hspace{3 cm}x = (A^TA)^{-1}A^Tb$\n",
    "\n",
    "- Therefore, pseudoinverse of matrix $A$ is given by:\n",
    "\n",
    "$\\hspace{3 cm} A^\\dagger = (A^TA)^{-1}A^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49073d9d",
   "metadata": {},
   "source": [
    "**Option 2:**\n",
    "- Moore-Penrose Pseudo-inverse use SVD to calculate the pseudo-inverse of a non-square matrix, and thus find the approximate solution to an overdetermined system of linear equations\n",
    "\n",
    "$\\hspace{3 cm}Ax = b$\n",
    "\n",
    "- Plug $A = USV^T$, in above equation:\n",
    "\n",
    "$\\hspace{3 cm}USV^Tx = b$\n",
    "\n",
    "- Since, $U$ is orthogonal, and we know that when an Orthogonal matrix is multiplied with its transpose, it will return an identity matrix, therefore:\n",
    "\n",
    "$\\hspace{3 cm}U^TUSV^Tx = U^Tb$\n",
    "\n",
    "$\\hspace{3 cm}SV^Tx = U^Tb$\n",
    "\n",
    "- Since, $S$ is a diagonal matrix, therefore, $SS^+ = I$, where, $S^+ = $($S$ with reciprocal of all non-zero elements)$^T$:\n",
    "\n",
    "$\\hspace{3 cm}S^+SV^Tx = S^+U^Tb$\n",
    "\n",
    "$\\hspace{3 cm}V^Tx = S^+U^Tb$\n",
    "\n",
    "\n",
    "- Since, $V$ is orthogonal, and we know that when an Orthogonal matrix is multiplied with its transpose, it will return an identity matrix, therefore:\n",
    "\n",
    "$\\hspace{3 cm}VV^Tx = VS^{-1}U^Tb$\n",
    "\n",
    "$\\hspace{3 cm}x = VS^{-1}U^Tb$\n",
    "\n",
    "\n",
    "- Therefore, pseudoinverse of matrix $A$ is given by:\n",
    "\n",
    "$\\hspace{3 cm} A^\\dagger = VS^+U^T $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0fb9e9",
   "metadata": {},
   "source": [
    "**Example:** Given a non-square matrix $A = \\begin{bmatrix} -1 & 2\\\\ 3 & -2\\\\5 & 7\\end{bmatrix}$. See if you can calculate its inverse. If not why not? Then compute its Pseudoinverse:\n",
    "- Use `pinv()` method\n",
    "- Use $A^\\dagger = (A^TA)^{-1}A^T$\n",
    "- Use $A^\\dagger = VS^+U^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e7b54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[-1, 2], [3, -2], [5, 7]])\n",
    "#np.linalg.det(A) # Error: Cannot calculate determinant of a non-square matrix\n",
    "#np.linalg.inv(A) # Error: Cannot calculate inverse of a non-square matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da24bf2",
   "metadata": {},
   "source": [
    "**Option A:** $\\hspace{2 cm}A^\\dagger = VS^+U^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b2b67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices=False) # NumPy SVD method returns U, s, and transpose of V\n",
    "V = VT.T\n",
    "Splus = np.diag(1/s,0)\n",
    "Aplus = V @ Splus @ U.T \n",
    "Aplus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57341351",
   "metadata": {},
   "source": [
    "**Option B:** $\\hspace{2 cm}A^\\dagger = (A^TA)^{-1}A^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10edfd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplus = (np.linalg.inv(A.T @ A)) @ A.T \n",
    "Aplus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f03dd9",
   "metadata": {},
   "source": [
    "**Option C:** $\\hspace{2 cm}A^\\dagger = np.linalg.pinv() $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51077c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplus = np.linalg.pinv(A)\n",
    "Aplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24b3d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ae7a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ce3a5af",
   "metadata": {},
   "source": [
    "**Example:** Given a square matrix $A = \\begin{bmatrix} 2 & 4\\\\ 6 & 12\\end{bmatrix}$. See if you can calculate its inverse. If not why not? Then compute its Pseudoinverse:\n",
    "- Use `pinv()` method\n",
    "- Use $A^\\dagger = (A^TA)^{-1}A^T$\n",
    "- Use $A^\\dagger = VS^+U^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa8308",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[2, 4], [6, 12]])\n",
    "np.linalg.det(A)\n",
    "#Ainv = np.linalg.inv(A) # Error: Cannot calculate inverse of a singular matrix having det(A) = 0\n",
    "                        # We can get the second column by multiplying the first column by 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf911d",
   "metadata": {},
   "source": [
    "**Option A:** $\\hspace{2 cm}A^\\dagger = VS^+U^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014077e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices=False) # NumPy SVD method returns U, s, and transpose of V\n",
    "V = VT.T\n",
    "Splus = np.diag(1/s,0)\n",
    "Aplus = V @ Splus @ U.T \n",
    "Aplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830bd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.diag(s)\n",
    "U @ S @ VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a088f83a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1abe2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f24ffc95",
   "metadata": {},
   "source": [
    "**Option B:** $\\hspace{2 cm}A^\\dagger = (A^TA)^{-1}A^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3148f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This option does not work, since inverse of A.T does not exist\n",
    "#Aplus = (np.linalg.inv(A.T @ A)) @ A.T \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d5475f",
   "metadata": {},
   "source": [
    "**Option C:** $\\hspace{2 cm}A^\\dagger = np.linalg.pinv() $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e01763",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplus = np.linalg.pinv(A)\n",
    "Aplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7f8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "S = np.diag(s)\n",
    "U @ S @ VT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059b70ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89a4bac5",
   "metadata": {},
   "source": [
    "### d. Solving Overdetermined System of Linear Equations using Moore-Penrose Pseudoinverse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b978563",
   "metadata": {},
   "source": [
    "**Example:**\n",
    "- Consider that a teacher has collected a sample data of seven students, their GPA and the number of hours they have studied on daily basis in the entire semester.\n",
    "- Suppose, a teacher want to determine the relationship between the two variables `GPA` and `study hours` is positive or negative.\n",
    "- The teacher also wants to determine how much impact the dependent variable `study hours` has on the independent variable `GPA`\n",
    "- For this she has collected a sample data of seven students as tupple containing (`daily study hours` and `acquired GPA`):\n",
    " $$(1,\\hspace{.2 cm}1.4), \\hspace{.5 cm}(2,\\hspace{.2 cm}1.6),\\hspace{.5 cm}(3,\\hspace{.2 cm}2.5),\\hspace{.5 cm}(4,\\hspace{.2 cm}2.6), \\hspace{.5 cm}(5,\\hspace{.2 cm}3.5),\\hspace{.5 cm}(6,\\hspace{.2 cm}3.7),\\hspace{.5 cm}(7,\\hspace{.2 cm}4.0) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218e4441",
   "metadata": {},
   "source": [
    ">- **`Step 1:` Plot the seven observations using a scatter chart:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = np.array([1, 2, 3, 4, 5, 6, 7.])               # study hours \n",
    "gpa = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])   # gpa\n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Study Hours vs GPA of Students\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"GPA\")\n",
    "ax.scatter(sh,gpa)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e645a1",
   "metadata": {},
   "source": [
    "- From the graph, we can note that if a student study 2 hours daily, he/she gets a GPA of 1.6. Similarly, if a student studies 7 hours daily, he or she gets a GPA of 4.0\n",
    "- So, it appears that there exist a positive relationship between the study hours and GPA achieved.\n",
    "- However, by just seeing the graph it appears that there exist no straight line or in other words no single equation that passes through all the seven points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9312b",
   "metadata": {},
   "source": [
    ">- **`Step 2:` Write down seven linear equations, one for each observation/point:**\n",
    "\n",
    "$$(1,1.4), \\hspace{.5 cm} (2,1.6), \\hspace{.5 cm}(3,2.5), \\hspace{.5 cm}(4,2.6),  \\hspace{.5 cm}(5,3.5), \\hspace{.5 cm}(6,3.7), \\hspace{.5 cm}(7,4.0) $$\n",
    "$$y=c+mx$$ \n",
    "$$y = \\beta_0 + \\beta_1x + \\epsilon$$\n",
    "- Where,\n",
    "    - $\\beta_0$ is the y-intercept\n",
    "    - $\\beta_1$ is the slope of the line \n",
    "    - $\\epsilon_i = \\hat{y}_i - y_i$, For a given instance $i$, $\\epsilon_i$ is a measure of the difference between the true $y_i$ and the model's estimate, $\\hat{y}_i$. If the model predicts $y_i$ perfectly, then the error is zero\n",
    "\n",
    "   \n",
    "- Together, $\\beta_0$ and $\\beta_1$ are called the **model coefficients**.  Our objective is to find the parameters $\\beta_0$ and $\\beta_1$ that minimize $\\epsilon$ across all the available data points. \n",
    "\n",
    "- Mention the seven equations for the seven points, having two unknowns: y-intercept ($\\beta_0$) and slope ($\\beta_1$)\n",
    "\n",
    "$$f(1):\\hspace{1 cm}\\beta_0 + \\beta_1 = 1.4$$\n",
    "$$f(2):\\hspace{1 cm}\\beta_0 + 2\\beta_1 = 1.6$$\n",
    "$$f(3):\\hspace{1 cm}\\beta_0 + 3\\beta_1 = 2.5$$\n",
    "$$f(4):\\hspace{1 cm}\\beta_0 + 4\\beta_1 = 2.6$$\n",
    "$$f(5):\\hspace{1 cm}\\beta_0 + 5\\beta_1 = 3.5$$\n",
    "$$f(6):\\hspace{1 cm}\\beta_0 + 6\\beta_1 = 3.7$$\n",
    "$$f(7):\\hspace{1 cm}\\beta_0 + 7\\beta_1 = 4.0$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9dc4194",
   "metadata": {},
   "source": [
    ">- **Step 3: Create matrix equation from above seven equations: $Ax=b$**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38baa981",
   "metadata": {},
   "source": [
    "- Let us write the above `Inconsistent Overdetermined System` of seven linear equations having two unknowns in matrix form.\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 1 \\\\  1 & 2 \\\\  1 & 3 \\\\ 1 & 4 \\\\  1 & 5 \\\\  1 & 6 \\\\ 1 & 7  \\end{bmatrix}\n",
    "\\begin{bmatrix} \\beta_0 \\\\ \\beta_1  \\end{bmatrix} =  \n",
    "\\begin{bmatrix} 1.4 \\\\ 1.6 \\\\ 2.5 \\\\ 2.6\\\\ 3.5 \\\\ 3.7 \\\\ 4.0  \\end{bmatrix}\n",
    "$$\n",
    "- Since the y-intercept is constant, so we have set it equal to `1` across the board\n",
    "\n",
    "- So the above equations can be written as:\n",
    "$$Ax = b$$\n",
    "\n",
    "- Where,\n",
    "    - $A$ is a $7\\times 2$ matrix of known coefficients.\n",
    "    - $x$ is a $2\\times 1$ vector of unknowns (y-intercept and slope)\n",
    "    - $b$ is a $7\\times 1$ vector of known independent or output variable values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3c23a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = np.array([1, 2, 3, 4, 5, 6, 7.])     # is a row vector having 7 elements\n",
    "sh.shape= (sh.size, 1)           # make sh a matrix of size 7x1\n",
    "ones = np.ones((sh.size,1))\n",
    "A = np.hstack((sh, ones)) # stack arrays horizontally or column-wise\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0cbf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = gpa\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb61a6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7c8903f",
   "metadata": {},
   "source": [
    ">- **`Step 4:` Solve the system of linear equations using Moore Penrose Pseudoinverse:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b7004",
   "metadata": {},
   "source": [
    "**Option A:** $\\hspace{2 cm}x \\approx A^\\dagger b \\hspace{2 cm}$ where, $\\hspace{.5 cm}A^\\dagger = VS^+U^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ca2222",
   "metadata": {},
   "outputs": [],
   "source": [
    "U, s, VT = np.linalg.svd(A, full_matrices=False) # NumPy SVD method returns U, s, and transpose of V\n",
    "V = VT.T\n",
    "Splus = np.diag(1/s,0)\n",
    "Aplus = V @ Splus @ U.T \n",
    "x = Aplus @ b\n",
    "print(\"Slope: \", x[0])\n",
    "print(\"Y-intercept: \", x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ddf221",
   "metadata": {},
   "source": [
    "**Option B:** $\\hspace{2 cm}x \\approx A^\\dagger b \\hspace{2 cm}$ where, $\\hspace{.5 cm}A^\\dagger = (A^TA)^{-1}A^T $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75382a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplus = (np.linalg.inv(A.T @ A)) @ A.T \n",
    "x = Aplus @ b\n",
    "print(\"Slope: \", x[0])\n",
    "print(\"Y-intercept: \", x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb7e1372",
   "metadata": {},
   "source": [
    "**Option C:** $\\hspace{2 cm}x \\approx A^\\dagger b \\hspace{2 cm}$ where, $\\hspace{.5 cm}A^\\dagger = np.linalg.pinv() $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838f91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aplus = np.linalg.pinv(A)\n",
    "result = Aplus @ b\n",
    "print(\"Slope: \", result[0])\n",
    "print(\"Y-intercept: \", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a699444",
   "metadata": {},
   "source": [
    ">- **`Step 5:`Draw the regression line using the computed slope and y-intercept, which is the best fit line**\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x $$\n",
    "$$gpa = 0.9 + 0.464*sh $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9598e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sh = np.array([1, 2, 3, 4, 5, 6, 7])       \n",
    "gpa = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])  \n",
    "fig, ax = plt.subplots()\n",
    "plt.title(\"Study Hours vs GPA of Students\")\n",
    "plt.xlabel(\"Study Hours\")\n",
    "plt.ylabel(\"GPA\")\n",
    "ax.scatter(sh,gpa);\n",
    "\n",
    "x2 = np.linspace(0,8, 10)\n",
    "b0 = 0.9\n",
    "b1 = 0.464\n",
    "y2 = b0 + b1*x2\n",
    "ax.plot(x2, y2)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af95350c",
   "metadata": {},
   "source": [
    ">- **`Step 6:`Perform prediction**\n",
    "- You can perform prediction from the graph. Given a x value you predict the value from the line and the actual data point. Note the difference between the predicted value and the actual value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826deba1",
   "metadata": {},
   "source": [
    ">- **`Step 7:` Finally calculate the least square errors to determine how well the regression line actually fits the data:**\n",
    "\n",
    "- **R-squared Error/Coefficient of Determination**. Tells us how well the regression line fit the data.  can range from 0 to 1. A value of 0 indicates that the response variable cannot be explained by the predictor variable at all. A value of 1 indicates that the response variable can be perfectly explained without error by the predictor variable.\n",
    "$$R^2 = \\frac{SSR}{SST}$$\n",
    "- **Sum of Squares due to Regression (SSR)** is calculated as the sum of the squares deviations of each predicted value of y, i.e., $\\hat{y}$, and subtract the avarage y, i.e., $\\bar{y}$. So it measures the difference between the predicted values and its average.\n",
    "$$SSR = \\sum(\\hat{y}_i - \\bar{y})^2$$ \n",
    "- **Sum of Squares Total (SST)** is the total variation squared.\n",
    "$$SST = SSR + SSE$$\n",
    "- **Sum of Squares Error (SSE)** is the unexplained deviation:\n",
    "$$SSE = \\sum(\\hat{y}_i - y_i)^2$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c585107",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3, 4, 5, 6, 7])       \n",
    "y = np.array([1.4, 1.6, 2.5, 2.6, 3.5, 3.7, 4.0])  \n",
    "yhat = b0 + b1*x \n",
    "sse = sum((yhat - y)**2)\n",
    "ssr = sum((yhat- np.mean(y))**2)\n",
    "sst = ssr + sse\n",
    "r2 = ssr/sst\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb2baff",
   "metadata": {},
   "source": [
    "This tells us that 96.4% of the variation in GPA can be explained by the number of hours studied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f02a268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc21e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac036d1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8c991d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
